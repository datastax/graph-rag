---
title: "Getting Started"
jupyter: python3
---

This page is an executable notebook demonstrating how to combine Graph Traversal and Vector Search using `langchain-graph-retriever` with `langchain`.

## Pre-requisites

We assume you already have a working `langchain` installation, including an LLM and embedding model as well as a [supported vector store](/reference/Adapter.qmd).

In that case, you only need to isntall `langchain-graph-retriever`:

```{python}
#| eval: False
%pip install langchain langchain-graph-retriever
```

## Preparing Data

Loading data is exactly the same as for whichever vector store you use.
The main thing to consider is what structured information you wish to include in the metadata to support traversal.

For this guide, I have a JSON file with information about animals. Several example entries are shown below. The actual file has one entry per line, making it easy to load into `Document`s.

```json
{
    "id": "alpaca",
    "text": "alpacas are domesticated mammals valued for their soft wool and friendly demeanor.",
    "metadata": {
        "type": "mammal",
        "number_of_legs": 4,
        "keywords": ["wool", "domesticated", "friendly"],
        "origin": "south america"
    }
}
{
    "id": "caribou",
    "text": "caribou, also known as reindeer, are migratory mammals found in arctic regions.",
    "metadata": {
        "type": "mammal",
        "number_of_legs": 4,
        "keywords": ["migratory", "arctic", "herbivore", "tundra"],
        "diet": "herbivorous"
    }
}
{
    "id": "cassowary",
    "text": "cassowaries are flightless birds known for their colorful necks and powerful legs.",
    "metadata": {
        "type": "bird",
        "number_of_legs": 2,
        "keywords": ["flightless", "colorful", "powerful"],
        "habitat": "rainforest"
    }
}
```

```{python}
import json
from langchain_core.documents import Document
animals = []
with open("../data/animals.jsonl", "r") as file:
    for line in file:
        data = json.loads(line.strip())
        animals.append(Document(
            id=data["id"],
            page_content=data["text"],
            metadata=data["metadata"],
        ))
```

## Populating the Vector Store

```{python}
from langchain_astradb import AstraDBVectorStore
from langchain_openai import OpenAIEmbeddings

vector_store = AstraDBVectorStore.from_documents(
    collection_name="animals",
    documents=animals,
    embedding=OpenAIEmbeddings(),
)
```

## Simple Traversal

For our first retrieval and graph traversal, we're going to start with a single animal best matching the query, and then traverse to other animals with the same `habitat` and/or `origin`.

```{python}
from langchain_graph_retriever import GraphRetriever
from langchain_graph_retriever.strategies import Eager
from langchain_graph_retriever.adapters.astra import AstraAdapter

simple = GraphRetriever(
    # Adapt AstraDBVectorStore for use with Graph Retrievers.
    store = AstraAdapter(vector_store),
    # Define the relationships to navigate:
    edges = ["habitat", "origin"],
    strategy = Eager(k=10, start_k=1, depth=2),
)
```

The above creates a graph traversing retriever with starts with the nearest animal (`start_k=1`), retrieves 10 documents (`k=10`) and limits the search to docuemnts that are at most 2 steps away from the first animal (`depth=2`).

The edges define how metadata values can be used for traversal. In this case, every animal is connected to other animals with the same habitat and/or same origin.

```{python}
simple_results = simple.invoke("what mammals come from the same region as the cassowary")

for doc in simple_results:
    print(doc.page_content)
```

## Visualizing

`langchain-graph-retrievers` includes code for converting the document graph into a `networkx` graph, for rendering and other analysis.
See @fig-document-graph

```{python}
#| code-fold: True
#| label: fig-document-graph
#| fig-cap: "Graph of retrieved documents"
import networkx as nx
import matplotlib.pyplot as plt
from langchain_graph_retriever.document_graph import create_graph

document_graph = create_graph(
    documents=simple_results,
    edges = simple.edges,
)

nx.draw(document_graph, with_labels=True)
plt.show()
```