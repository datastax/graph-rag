{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# ruff: noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Code Generation with GraphRAG\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will show how GraphRAG can be used to traverse through python library documentation in order to provide help to an LLM that is generating code.\n",
    "\n",
    "We'll use a custom Strategy to traverse through the documents and select nodes that contain code examples and/or descriptive text.\n",
    "\n",
    "The query we will be sending to the LLM is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Generate a function for connecting to an AstraDB cluster using the AstraPy library,\n",
    "and retrieve some rows from a collection. The number of rows to return should be a\n",
    "parameter on the method. Use Token Authentication. Assume the cluster is hosted on\n",
    "AstraDB. Include the necessary imports and any other necessary setup. The following\n",
    "environment variables are available for your use:\n",
    "\n",
    "- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n",
    "- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n",
    "- `ASTRA_DB_KEYSPACE`: The Astra DB keyspace.\n",
    "- `ASTRA_DB_COLLECTION`: The Astra DB collection.\" \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "The following block will configure the environment from the Colab Secrets.\n",
    "To run it, you should have the following Colab Secrets defined and accessible to this notebook:\n",
    "\n",
    "- `OPENAI_API_KEY`: The OpenAI key.\n",
    "- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n",
    "- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n",
    "- `LANGCHAIN_API_KEY`: Optional. If defined, will enable LangSmith tracing.\n",
    "- `ASTRA_DB_KEYSPACE`: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install modules.\n",
    "\n",
    "%pip install \\\n",
    "    langchain-core \\\n",
    "    langchain-astradb \\\n",
    "    langchain-openai \\\n",
    "    langchain-graph-retriever \\\n",
    "    graph-rag-example-helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last package -- `graph-rag-example-helpers` -- includes the helpers and example documents that we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure import paths.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Initialize environment variables.\n",
    "from graph_rag_example_helpers.env import Environment, initialize_environment\n",
    "\n",
    "initialize_environment(Environment.ASTRAPY)\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"code-generation\"\n",
    "os.environ[\"ASTRA_DB_COLLECTION\"] = \"code_generation\"\n",
    "\n",
    "\n",
    "def print_doc_ids(docs: list[Document]):\n",
    "    [print(f\"`{doc.id}` has example: {'example' in doc.metadata}\") for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data\n",
    "\n",
    "First, we'll demonstrate how to load the example AstraPy documentation into `AstraDBVectorStore`. We will be creating a LangChain Document for every module, class, attribute, and function in the package. \n",
    "\n",
    "We will use the pydoc description field for the `page_content` field in the document. Note that not every item in the package has a description. Because of this, there will be many documents that have no page content. \n",
    "\n",
    "Besides the description, we will also include a bunch of extra information related to the item in the `metadata` field. This info can include the item's name, kind, parameters, return type, base class, etc.\n",
    "\n",
    "The item's `id` will be the items path in the package.\n",
    "\n",
    "Below are two example documents... One with page content and one without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example doc with page content\n",
    "\n",
    "<details markdown><summary>Click to expand</summary>\n",
    "\n",
    "```yaml\n",
    "id: astrapy.client.DataAPIClient\n",
    "\n",
    "page_content: |\n",
    "    A client for using the Data API. This is the main entry point and sits\n",
    "    at the top of the conceptual \"client -> database -> collection\" hierarchy.\n",
    "\n",
    "    A client is created first, optionally passing it a suitable Access Token.\n",
    "    Starting from the client, then:\n",
    "        - databases (Database and AsyncDatabase) are created for working with data\n",
    "        - AstraDBAdmin objects can be created for admin-level work\n",
    "\n",
    "metadata:\n",
    "    name: DataAPIClient\n",
    "    kind: class\n",
    "    path: astrapy.client.DataAPIClient\n",
    "    parameters: \n",
    "        token: |\n",
    "            str | TokenProvider | None = None\n",
    "            an Access Token to the database. Example: `\"AstraCS:xyz...\"`.\n",
    "            This can be either a literal token string or a subclass of\n",
    "            `astrapy.authentication.TokenProvider`.\n",
    "        \n",
    "        environment: |\n",
    "            str | None = None\n",
    "            a string representing the target Data API environment.\n",
    "            It can be left unspecified for the default value of `Environment.PROD`;\n",
    "            other values include `Environment.OTHER`, `Environment.DSE`.\n",
    "        \n",
    "        callers: |\n",
    "            Sequence[CallerType] = []\n",
    "            a list of caller identities, i.e. applications, or frameworks,\n",
    "            on behalf of which Data API and DevOps API calls are performed.\n",
    "            These end up in the request user-agent.\n",
    "            Each caller identity is a (\"caller_name\", \"caller_version\") pair.\n",
    "\n",
    "    example: |\n",
    "        >>> from astrapy import DataAPIClient\n",
    "        >>> my_client = DataAPIClient(\"AstraCS:...\")\n",
    "        >>> my_db0 = my_client.get_database(\n",
    "        ...     \"https://01234567-....apps.astra.datastax.com\"\n",
    "        ... )\n",
    "        >>> my_coll = my_db0.create_collection(\"movies\", dimension=2)\n",
    "        >>> my_coll.insert_one({\"title\": \"The Title\", \"$vector\": [0.1, 0.3]})\n",
    "        >>> my_db1 = my_client.get_database(\"01234567-...\")\n",
    "        >>> my_db2 = my_client.get_database(\"01234567-...\", region=\"us-east1\")\n",
    "        >>> my_adm0 = my_client.get_admin()\n",
    "        >>> my_adm1 = my_client.get_admin(token=more_powerful_token_override)\n",
    "        >>> database_list = my_adm0.list_databases()\n",
    "\n",
    "    references: \n",
    "        astrapy.client.DataAPIClient\n",
    "\n",
    "    gathered_types: \n",
    "        astrapy.constants.CallerType\n",
    "        astrapy.authentication.TokenProvider\n",
    "```\n",
    "</details>\n",
    "\n",
    "This is the documentation for [`astrapy.client.DataAPIClient`](https://github.com/datastax/astrapy/blob/v1.5.2/astrapy/client.py#L50) class. The `page_content` field contains the description of the class, and the `metadata` field contains the rest of the details, including example code of how to use the class.\n",
    "\n",
    "The `references` metadata field contains the list of related items used in the example code block. The `gathered_types` field contains the list of types from the parameters section. In GraphRAG, we can use these fields to link to other documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example doc without page content\n",
    "\n",
    "<details markdown><summary>Click to expand</summary>\n",
    "\n",
    "```yaml\n",
    "id: astrapy.admin.AstraDBAdmin.callers\n",
    "\n",
    "page_content: \"\"\n",
    "\n",
    "metadata:\n",
    "  name: callers\n",
    "  path: astrapy.admin.AstraDBAdmin.callers\n",
    "  kind: attribute\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "This is the documentation for `astrapy.admin.AstraDBAdmin.callers`. The `page_content` field is empty, and the `metadata` field contains the details.\n",
    "\n",
    "Despite having no page content, this document can still be useful for Graph RAG.  We'll add a `parent` field to the metadata at vector store insertion time to link it to the parent document: `astrapy.admin.AstraDBAdmin`, and we can use this for traversal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the AstraDBVectorStore\n",
    "Next, we'll create the Vector Store we're going to load these documents into.\n",
    "In our case, we'll use DataStax Astra DB with Open AI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "store = AstraDBVectorStore(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=os.getenv(\"ASTRA_DB_COLLECTION\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Now its time to load the data into our Vector Store. We'll use a helper method to download already prepared documents from the `graph-rag-example-helpers` package. If you want to see how these documents were created from the AstraPy package, see details in the Appendix.\n",
    "\n",
    "We will use the [`ParentTransformer`](../../guide/transformers/#parenttransformer) to add a parent field to the metadata document field. This will allow us to traverse the graph from a child to its parent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_rag_example_helpers.datasets.astrapy import fetch_documents\n",
    "from langchain_graph_retriever.transformers import ParentTransformer\n",
    "\n",
    "transformer = ParentTransformer(path_delimiter=\".\")\n",
    "doc_ids = store.add_documents(transformer.transform_documents(fetch_documents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve a sample document to check if the parent field was added correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callers (attribute)\n",
      "\n",
      "path: \n",
      "\tastrapy.admin.AstraDBAdmin.callers\n",
      "\n",
      "callers = callers_param\n",
      "\n",
      "parent: astrapy.admin.AstraDBAdmin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from graph_rag_example_helpers.examples.code_generation import format_document\n",
    "\n",
    "print(\n",
    "    format_document(\n",
    "        store.get_by_document_id(\"astrapy.admin.AstraDBAdmin.callers\"), debug=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've created a Vector Store with all the documents from the AstraPy documentation. Each document contains metadata about the module, class, attribute, or function, and the page content contains the description of the item.\n",
    "\n",
    "In the next section we'll see how to build relationships from the metadata in order to traverse through the documentation in a similar way to how a human would."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Graph Traversal\n",
    "\n",
    "The GraphRAG library allows us to traverse through the documents in the Vector Store.  By changing the [`Strategy`](../../guide/strategies/), we can control how the traversal is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Traversal\n",
    "\n",
    "We'll start with the default [`Eager`](../../guide/strategies/#eager) strategy, which will traverse the graph in a breadth-first manner. In order to do this we need to set up the relationships between the documents. This is done by defining the \"edges\" between the documents.\n",
    "\n",
    "In our case we will connect the \"references\", \"gathered_types\", \"parent\", \"implemented_by\", and \"bases\" fields in the metadata to the \"id\" field of the document they reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (\"gathered_types\", \"$id\"),\n",
    "    (\"references\", \"$id\"),\n",
    "    (\"parent\", \"$id\"),\n",
    "    (\"implemented_by\", \"$id\"),\n",
    "    (\"bases\", \"$id\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that edges are directional, and indicate metadata fields by default.  The magic string `$id` is used to indicate the document's id.\n",
    "\n",
    "In the above `edges` list, any document id found in `gathered_types` will be connected to documents with the corresponding id. The other edges will work in a similar way.\n",
    "\n",
    "Lets use these edges to create a LangChain retriever and documents for our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`astrapy.core.db.AsyncAstraDB.collection` has example: False\n",
      "`astrapy.core.db.AstraDB.collection` has example: False\n",
      "`astrapy.admin.DataAPIDatabaseAdmin.list_keyspaces` has example: True\n",
      "`astrapy.admin.DataAPIDatabaseAdmin` has example: True\n",
      "`astrapy.core.db.AsyncAstraDB` has example: False\n",
      "`astrapy.core.db.AstraDBCollection` has example: False\n"
     ]
    }
   ],
   "source": [
    "from langchain_graph_retriever import GraphRetriever\n",
    "\n",
    "default_retriever = GraphRetriever(store=store, edges=edges)\n",
    "\n",
    "print_doc_ids(default_retriever.invoke(query, select_k=6, start_k=3, max_depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the extra keyword args:\n",
    "- `select_k` in GraphRAG is equivalent to `k` in LangChain. It specifies the number of nodes to select during retrieval.\n",
    "- `start_k` indicates the number of nodes to select using standard vector retrieval before moving onto graph traversal. \n",
    "- `max_depth` is the maximum depth to traverse in the graph.\n",
    "\n",
    "With this configuration, we were only able to find 2 documents with example code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Strategy\n",
    "\n",
    "Now we will create a custom strategy that will traverse a larger portion of the graph and return the documents that contain code examples or descriptive text. \n",
    "\n",
    "To do this, we need to implement a class that inherits from the base [`Strategy`](../../reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy) class and overrides [`iteration`](../../reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy.iteration) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from graph_retriever.strategies import NodeTracker, Strategy\n",
    "from graph_retriever.types import Node\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class CodeExamples(Strategy):\n",
    "    # internal dictionary to store all nodes found during the traversal\n",
    "    _nodes: dict[str, Node] = dataclasses.field(default_factory=dict)\n",
    "\n",
    "    def iteration(self, *, nodes: Iterable[Node], tracker: NodeTracker) -> None:\n",
    "        # save all newly found nodes to the internal node dictionary for later use\n",
    "        self._nodes.update({n.id: n for n in nodes})\n",
    "        # traverse the newly found nodes\n",
    "        new_count = tracker.traverse(nodes=nodes)\n",
    "\n",
    "        # if no new nodes were found, we have reached the end of the traversal\n",
    "        if new_count == 0:\n",
    "            example_nodes = []\n",
    "            description_nodes = []\n",
    "\n",
    "            # iterate over all nodes and separate nodes with examples from nodes with\n",
    "            # descriptions\n",
    "            for node in self._nodes.values():\n",
    "                if \"example\" in node.metadata:\n",
    "                    example_nodes.append(node)\n",
    "                elif node.content != \"\":\n",
    "                    description_nodes.append(node)\n",
    "\n",
    "            # select the nodes with examples first and descriptions second\n",
    "            # note: the base `finalize_nodes` method will truncate the list to the\n",
    "            #   `select_k` number of nodes\n",
    "            tracker.select(example_nodes)\n",
    "            tracker.select(description_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the comments above, this custom strategy will first try to select documents that contain code examples, and then will use documents that contain descriptive text.\n",
    "\n",
    "We can now use this custom strategy to build a custom retriever, and ask the query again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`astrapy.admin.DataAPIDatabaseAdmin.list_keyspaces` has example: True\n",
      "`astrapy.admin.DataAPIDatabaseAdmin` has example: True\n",
      "`astrapy.client.DataAPIClient` has example: True\n",
      "`astrapy.database.AsyncDatabase` has example: True\n",
      "`astrapy.database.Database` has example: True\n",
      "`astrapy.authentication.UsernamePasswordTokenProvider` has example: True\n"
     ]
    }
   ],
   "source": [
    "custom_retriever = GraphRetriever(store=store, edges=edges, strategy=CodeExamples())\n",
    "\n",
    "print_doc_ids(custom_retriever.invoke(query, select_k=6, start_k=3, max_depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have found 6 documents with code examples! That is a significant improvement over the default strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using GraphRAG to Generate Code\n",
    "\n",
    "We now use the `CodeExamples` strategy inside a Langchain pipeline to generate code snippets.\n",
    "\n",
    "We will also use a custom document formatter, which will format the document in a way that makes it look like standard documentation. In particular, it will format all the extra details stored in the metadata in a way that is easy to read.  This will help the LLM use the information in the documents to generate code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import os\n",
      "from astrapy.client import DataAPIClient\n",
      "from astrapy.collection import Collection\n",
      "\n",
      "def connect_and_retrieve_rows(num_rows):\n",
      "    api_endpoint = os.getenv('ASTRA_DB_API_ENDPOINT')\n",
      "    application_token = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n",
      "    keyspace = os.getenv('ASTRA_DB_KEYSPACE')\n",
      "    collection_name = os.getenv('ASTRA_DB_COLLECTION')\n",
      "\n",
      "    client = DataAPIClient(token=application_token)\n",
      "    database = client.get_database(api_endpoint)\n",
      "    collection = Collection(database=database, name=collection_name, keyspace=keyspace)\n",
      "\n",
      "    rows = collection.find(limit=num_rows)\n",
      "    return list(rows)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from graph_rag_example_helpers.examples.code_generation import format_docs\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate a block of runnable python code using the following documentation as\n",
    "    guidance. Return only the code. Don't include any example usage.\n",
    "\n",
    "    Each documentation page is separated by three dashes (---) on its own line.\n",
    "    If certain pages of the provided documentation aren't useful for answering the\n",
    "    question, feel free to ignore them.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Related Documentation:\n",
    "\n",
    "    {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "graph_chain = (\n",
    "    {\"context\": custom_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(graph_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try running this generated code to see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astrapy.client import DataAPIClient\n",
    "from astrapy.collection import Collection\n",
    "\n",
    "\n",
    "def connect_and_retrieve_rows(num_rows):\n",
    "    api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "    application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "    keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")\n",
    "    collection_name = os.getenv(\"ASTRA_DB_COLLECTION\")\n",
    "\n",
    "    client = DataAPIClient(token=application_token)\n",
    "    database = client.get_database(api_endpoint)\n",
    "    collection = Collection(database=database, name=collection_name, keyspace=keyspace)\n",
    "\n",
    "    rows = collection.find(limit=num_rows)\n",
    "    return list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'astrapy.info.EmbeddingProviderAuthentication', 'content': 'A representation of an authentication mode for using an embedding model,\\nmodeling the corresponding part of the response returned by the\\n\\'findEmbeddingProviders\\' Data API endpoint (namely \"supportedAuthentication\").', 'metadata': {'kind': 'class', 'name': 'EmbeddingProviderAuthentication', 'path': 'astrapy.info.EmbeddingProviderAuthentication', 'parameters': [{'name': 'enabled', 'type': 'bool'}, {'name': 'tokens', 'type': 'list[EmbeddingProviderToken]'}], 'attributes': [{'name': 'enabled', 'type': 'bool', 'description': 'whether this authentication mode is available for a given model.'}, {'name': 'tokens', 'type': 'list[EmbeddingProviderToken]', 'description': 'a list of `EmbeddingProviderToken` objects,\\ndetailing the secrets required for the authentication mode.'}], 'gathered_types': ['EmbeddingProviderToken'], 'parent': 'astrapy.info'}}\n",
      "{'_id': 'astrapy.defaults.DEV_OPS_RESPONSE_HTTP_CREATED', 'content': '', 'metadata': {'kind': 'attribute', 'name': 'DEV_OPS_RESPONSE_HTTP_CREATED', 'path': 'astrapy.defaults.DEV_OPS_RESPONSE_HTTP_CREATED', 'value': 'DEV_OPS_RESPONSE_HTTP_CREATED = 201', 'parent': 'astrapy.defaults'}}\n",
      "{'_id': 'astrapy.info.CollectionInfo.full_name', 'content': '', 'metadata': {'kind': 'attribute', 'name': 'full_name', 'path': 'astrapy.info.CollectionInfo.full_name', 'value': 'full_name: str', 'parent': 'astrapy.info.CollectionInfo'}}\n",
      "{'_id': 'astrapy.collection.Collection.full_name', 'content': 'The fully-qualified collection name within the database,\\nin the form \"keyspace.collection_name\".', 'metadata': {'kind': 'attribute', 'name': 'full_name', 'path': 'astrapy.collection.Collection.full_name', 'value': 'full_name: str', 'example': \">>> my_coll.full_name\\n'default_keyspace.my_v_collection'\", 'parent': 'astrapy.collection.Collection'}}\n",
      "{'_id': 'astrapy.exceptions.DataAPIErrorDescriptor', 'content': 'An object representing a single error returned from the Data API,\\ntypically with an error code and a text message.\\nAn API request would return with an HTTP 200 success error code,\\nbut contain a nonzero amount of these.\\n\\nA single response from the Data API may return zero, one or more of these.\\nMoreover, some operations, such as an insert_many, may partally succeed\\nyet return these errors about the rest of the operation (such as,\\nsome of the input documents could not be inserted).', 'metadata': {'kind': 'class', 'name': 'DataAPIErrorDescriptor', 'path': 'astrapy.exceptions.DataAPIErrorDescriptor', 'parameters': [{'name': 'error_dict', 'type': 'dict[str, str]'}], 'attributes': [{'name': 'error_code', 'type': 'str | None', 'description': 'a string code as found in the API \"error\" item.'}, {'name': 'message', 'type': 'str | None', 'description': 'the text found in the API \"error\" item.'}, {'name': 'attributes', 'type': 'dict[str, Any]', 'description': 'a dict with any further key-value pairs returned by the API.'}], 'parent': 'astrapy.exceptions'}}\n"
     ]
    }
   ],
   "source": [
    "for row in connect_and_retrieve_rows(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The code generated by GraphRAG isn't perfect, but it works. It's a good starting point for the LLM to generate code. The LLM used the information in the documentation and code examples to generate functional code.\n",
    "\n",
    "In the Appendix, you can see examples of attempting this query with just an LLM and with Standard (non-graph) RAG. In both cases, the LLM was unable to generate usable code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Alone\n",
    "\n",
    "Here we show how to use the LLM alone to generate code for the query. We will use the same query as before, but modify the prompt to not include any context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import os\n",
      "from astra import AstraClient\n",
      "\n",
      "def fetch_rows_from_astra_db(num_rows):\n",
      "    # Retrieve environment variables\n",
      "    api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
      "    application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
      "    keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")\n",
      "    collection = os.getenv(\"ASTRA_DB_COLLECTION\")\n",
      "    \n",
      "    # Initialize the Astra DB client\n",
      "    client = AstraClient(api_endpoint, application_token)\n",
      "    \n",
      "    # Retrieve rows from the specified collection\n",
      "    query = f'SELECT * FROM {keyspace}.{collection} LIMIT {num_rows}'\n",
      "    response = client.execute_statement(query)\n",
      "    \n",
      "    # Return the rows retrieved\n",
      "    return response['rows']\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "llm_only_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate a block of runnable python code. Return only the code.\n",
    "    Don't include any example usage.\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm_only_chain = (\n",
    "    {\"question\": RunnablePassthrough()} | llm_only_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(llm_only_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is not functional. The package `astra` and the class `AstraClient` do not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard RAG\n",
    "\n",
    "Here we show how to use the LLM with standard RAG to generate code for the query. We will use the same query and prompt as we did with GraphRAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import os\n",
      "from astra import AstraClient\n",
      "\n",
      "def fetch_rows_from_astradb(num_rows):\n",
      "    endpoint = os.getenv('ASTRA_DB_API_ENDPOINT')\n",
      "    token = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n",
      "    keyspace = os.getenv('ASTRA_DB_KEYSPACE')\n",
      "    collection = os.getenv('ASTRA_DB_COLLECTION')\n",
      "\n",
      "    client = AstraClient(\n",
      "        endpoint=endpoint,\n",
      "        token=token\n",
      "    )\n",
      "\n",
      "    query = f'SELECT * FROM {keyspace}.{collection} LIMIT {num_rows}'\n",
      "    response = client.execute(query)\n",
      "    return response['data']\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": store.as_retriever(k=6) | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is also not functional. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting AstraPy Documentation\n",
    "\n",
    "The AstraPy documentation was converted into a JSONL format via some custom code that is not included in this notebook. However, the code is available in the `graph-rag-example-helpers` package [here](https://github.com/datastax/graph-rag/blob/main/packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/converter.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
