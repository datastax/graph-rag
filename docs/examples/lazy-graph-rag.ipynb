{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqhMgAGwmLXc"
   },
   "source": [
    "# LazyGraphRAG in LangChain\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In [LazyGraphRAG](https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/), Microsoft demonstrates significant cost and performance benefits to delaying the construction of a knowledge graph.\n",
    "This is largely because not all documents need to be analyzed.\n",
    "However, it is also benefical that documents by the time documents are analyzed the question is already known, allowing irrelevant information to be ignored. \n",
    "\n",
    "We've noticed similar cost benefits to building a document graph linking content based on simple properties such as extracted keywords compared to building a complete knowledge graph.\n",
    "For the Wikipedia dataset used in this notebook, we estimated it would have taken $70k to build a knowledege graph using the [example from LangChain](https://python.langchain.com/docs/how_to/graph_constructing/#llm-graph-transformer), while the document graph was basically free.\n",
    "\n",
    "In this notebook we demonstrate how to populate a document graph with Wikipedia articles linked based on mentions in the articles and extracted keywords.\n",
    "Keyword extraction uses a local [KeyBERT](https://maartengr.github.io/KeyBERT/) model, making it fast and cost-effective to construct these graphs.\n",
    "We'll then show how to build out a chain which does the steps of Lazy GraphRAG -- retrieving articles, extracting claims from each community, ranking and selecting the top claims, and generating an answer based on those claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6dFtwI_xmFW"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "The following block will configure the environment from the Colab Secrets.\n",
    "To run it, you should have the following Colab Secrets defined and accessible to this notebook:\n",
    "\n",
    "- `OPENAI_API_KEY`: The OpenAI key.\n",
    "- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n",
    "- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n",
    "- `LANGCHAIN_API_KEY`: Optional. If defined, will enable LangSmith tracing.\n",
    "- `ASTRA_DB_KEYSPACE`: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "r0-5VJWGsBM3",
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain-astradb in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: langchain-openai in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-graph-retriever in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: graph-rag-example-helpers in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Collecting spacy[apple]\n",
      "  Using cached spacy-3.8.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: astrapy<2.0.0,>=1.5.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (1.5.2)\n",
      "Requirement already satisfied: langchain-community>=0.3.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (0.3.14)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-openai) (1.60.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: backoff>=2.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-graph-retriever) (2.2.1)\n",
      "Requirement already satisfied: graph-retriever in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-graph-retriever) (0.1.0)\n",
      "Requirement already satisfied: networkx>=3.4.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-graph-retriever) (3.4.2)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy[apple])\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy[apple])\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy[apple])\n",
      "  Using cached murmurhash-1.0.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy[apple])\n",
      "  Using cached cymem-2.0.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy[apple])\n",
      "  Using cached preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy[apple])\n",
      "  Using cached thinc-8.3.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy[apple])\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy[apple])\n",
      "  Using cached srsly-2.5.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy[apple])\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy[apple])\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (75.8.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy[apple])\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting thinc-apple-ops<2.0.0,>=1.0.0 (from spacy[apple])\n",
      "  Using cached thinc_apple_ops-1.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (0.28.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (1.0.1)\n",
      "Requirement already satisfied: simsimd>=6.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (6.2.1)\n",
      "Requirement already satisfied: deprecation<2.2.0,>=2.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (2.1.0)\n",
      "Requirement already satisfied: pymongo>=3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.10.1)\n",
      "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (0.10.2)\n",
      "Requirement already satisfied: uuid6>=2024.1.12 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (2024.7.10)\n",
      "Requirement already satisfied: anyio in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->graph-rag-example-helpers) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.3.14)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (2.7.1)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy[apple])\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2.3.0)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy[apple])\n",
      "  Using cached blis-1.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy[apple])\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc-apple-ops to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community>=0.3.1 (from langchain-astradb)\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.16 (from langchain-community>=0.3.1->langchain-astradb)\n",
      "  Using cached langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-community>=0.3.1 (from langchain-astradb)\n",
      "  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: pip is still looking at multiple versions of thinc-apple-ops to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community>=0.3.1 (from langchain-astradb)\n",
      "  Using cached langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community>=0.3.1->langchain-astradb)\n",
      "  Using cached SQLAlchemy-2.0.35-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting langchain-community>=0.3.1 (from langchain-astradb)\n",
      "  Using cached langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langchain-community>=0.3.1 (from langchain-astradb)\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy[apple]\n",
      "  Using cached spacy-3.8.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy[apple])\n",
      "  Using cached thinc-8.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting blis<1.2.0,>=1.1.0 (from thinc<8.4.0,>=8.3.0->spacy[apple])\n",
      "  Using cached blis-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy[apple])\n",
      "  Using cached thinc-8.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy[apple])\n",
      "  Using cached blis-1.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy[apple])\n",
      "  Using cached thinc-8.3.1.tar.gz (193 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached thinc-8.3.0.tar.gz (193 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting spacy[apple]\n",
      "  Using cached spacy-3.8.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "  Using cached spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy[apple])\n",
      "  Using cached thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting thinc-apple-ops<1.0.0,>=0.1.0.dev0 (from spacy[apple])\n",
      "  Using cached thinc_apple_ops-0.1.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy[apple])\n",
      "  Using cached blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy[apple])\n",
      "  Using cached cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy[apple])\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pytest>=8.3.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pytest[testing]>=8.3.4->graph-retriever->langchain-graph-retriever) (8.3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jinja2->spacy[apple]) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (3.24.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (0.9.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.1.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.14->langchain-community>=0.3.1->langchain-astradb) (0.3.5)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[apple])\n",
      "  Using cached marisa_trie-1.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pymongo>=3->astrapy<2.0.0,>=1.5.2->langchain-astradb) (2.7.0)\n",
      "Requirement already satisfied: iniconfig in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pytest>=8.3.4->pytest[testing]>=8.3.4->graph-retriever->langchain-graph-retriever) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pytest>=8.3.4->pytest[testing]>=8.3.4->graph-retriever->langchain-graph-retriever) (1.5.0)\n",
      "\u001b[33mWARNING: pytest 8.3.4 does not provide the extra 'testing'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: markdown-it-py>=2.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy[apple]) (1.17.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (1.0.0)\n",
      "Using cached thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl (760 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp312-cp312-macosx_11_0_arm64.whl (42 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp312-cp312-macosx_11_0_arm64.whl (27 kB)\n",
      "Using cached preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl (128 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp312-cp312-macosx_11_0_arm64.whl (634 kB)\n",
      "Using cached thinc_apple_ops-0.1.5-cp312-cp312-macosx_11_0_arm64.whl (156 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl (6.1 MB)\n",
      "Using cached blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Using cached cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached marisa_trie-1.2.1-cp312-cp312-macosx_11_0_arm64.whl (174 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, thinc-apple-ops, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 smart-open-7.1.0 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.2.5 thinc-apple-ops-0.1.5 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# @ Install modules.\n",
    "%pip install \\\n",
    "    langchain-core \\\n",
    "    langchain-astradb \\\n",
    "    langchain-openai \\\n",
    "    langchain-graph-retriever \\\n",
    "    \"spacy[apple]\" \\\n",
    "    graph-rag-example-helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last package -- `graph-rag-example-helpers` -- includes some helpers for setting up environment helpers and allowing the loading of wikipedia data to be restarted if it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Configure import paths.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Initialize environment variables.\n",
    "from graph_rag_example_helpers.env import Environment, initialize_environment\n",
    "\n",
    "initialize_environment(Environment.ASTRAPY)\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"lazy-graph-rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data\n",
    "\n",
    "First, we'll demonstrate how to load Wikipedia data into an `AstraDBVectorStore`, using the mentioned articles and keywords as metadata fields.\n",
    "In this section, we're not actually doing anything special for the graph -- we're just populating the metadata with fields that useful describe our content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Documents from Wikipedia Articles\n",
    "The first thing we need to do is create the `LangChain` `Document`s we'll import.\n",
    "\n",
    "To do this, we write some code to convert lines from a JSON file downloaded from [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021) and create a `Document`.\n",
    "We populate the `id` and `metadata[\"mentions\"]` from information in this file.\n",
    "\n",
    "Then, we run those documents through the `SpacyNERTransformer` to populate `metadata[\"entities\"]` with entities named in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8u4lD-AqDMMs"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_graph_retriever.document_transformers.spacy import (\n",
    "    SpacyNERTransformer,\n",
    ")\n",
    "\n",
    "\n",
    "def parse_document(line: bytes) -> Document:\n",
    "    \"\"\"Reads one JSON line from the wikimultihop dump.\"\"\"\n",
    "    para = json.loads(line)\n",
    "\n",
    "    id = para[\"id\"]\n",
    "    title = para[\"title\"]\n",
    "\n",
    "    # Use structured information (mentioned Wikipedia IDs) as metadata.\n",
    "    mentioned_ids = [id for m in para[\"mentions\"] for m in m[\"ref_ids\"] or []]\n",
    "\n",
    "    return Document(\n",
    "        id=id,\n",
    "        page_content=\" \".join(para[\"sentences\"]),\n",
    "        metadata={\n",
    "            \"mentions\": mentioned_ids,\n",
    "            \"title\": title,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "NER_TRANSFORMER = SpacyNERTransformer(\n",
    "    limit=1000,\n",
    "    exclude_labels={\"CARDINAL\", \"MONEY\", \"QUANTITY\", \"TIME\", \"PERCENT\", \"ORDINAL\"},\n",
    ")\n",
    "\n",
    "\n",
    "# Load data in batches, using GLiNER to extract entities.\n",
    "def prepare_batch(lines: Iterator[str]) -> Iterator[Document]:\n",
    "    # Parse documents from the batch of lines.\n",
    "    docs = [parse_document(line) for line in lines]\n",
    "\n",
    "    docs = NER_TRANSFORMER.transform_documents(docs)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the AstraDBVectorStore\n",
    "Next, we create the Vector Store we're going to load these documents into.\n",
    "In our case, we use DataStax Astra DB with Open AI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Create the AstraDBVectorStore\n",
    "\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION = \"lazy_graph_rag\"\n",
    "store = AstraDBVectorStore(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=COLLECTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into the Store\n",
    "Next, we perform the actual loading.\n",
    "This takes a while, so we use a helper utility to persist which batches have been written so we can resume if there are any failures.\n",
    "\n",
    "On OS X, it is useful to run `caffeinate -dis` in a shell to prevent the machine from going to sleep and seems to reduce errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Path to the file `para_with_hyperlink.zip`.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# See instructions here to download from\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\u001b[39;00m\n\u001b[1;32m      9\u001b[0m PARA_WITH_HYPERLINK_ZIP \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpara_with_hyperlink.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m aload_2wikimultihop(PARA_WITH_HYPERLINK_ZIP, store, prepare_batch)\n",
      "File \u001b[0;32m~/code/graph-pancake/packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/wikimultihop/load.py:73\u001b[0m, in \u001b[0;36maload_2wikimultihop\u001b[0;34m(para_with_hyperlink_zip_path, store, batch_prepare)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maload_2wikimultihop\u001b[39m(\n\u001b[1;32m     57\u001b[0m     para_with_hyperlink_zip_path: \u001b[38;5;28mstr\u001b[39m, store: VectorStore, batch_prepare: BatchPreparer\n\u001b[1;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Load 2wikimultihop data into the given `VectorStore`.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        Function to apply to batches of lines to produce the document.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(para_with_hyperlink_zip_path)\n\u001b[1;32m     74\u001b[0m     persistence \u001b[38;5;241m=\u001b[39m PersistentIteration(\n\u001b[1;32m     75\u001b[0m         journal_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_2wikimultihop.jrnl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m         iterator\u001b[38;5;241m=\u001b[39mbatched(wikipedia_lines(para_with_hyperlink_zip_path), BATCH_SIZE),\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m     total_batches \u001b[38;5;241m=\u001b[39m ceil(LINES_IN_FILE \u001b[38;5;241m/\u001b[39m BATCH_SIZE) \u001b[38;5;241m-\u001b[39m persistence\u001b[38;5;241m.\u001b[39mcompleted_count()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "from graph_rag_example_helpers.datasets.wikimultihop import aload_2wikimultihop\n",
    "\n",
    "# Path to the file `para_with_hyperlink.zip`.\n",
    "# See instructions here to download from\n",
    "# [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\n",
    "PARA_WITH_HYPERLINK_ZIP = os.path.join(os.getcwd(), \"para_with_hyperlink.zip\")\n",
    "\n",
    "await aload_2wikimultihop(PARA_WITH_HYPERLINK_ZIP, store, prepare_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've created a `VectorStore` with the Wikipedia articles.\n",
    "Each article is associated with metadata identifying other articles it mentions and entities from the article.\n",
    "\n",
    "As is, this is useful for performing a vector search filtered to articles mentioning a specific term or performing an entity seach on the documents.\n",
    "The library `langchain-graph-retriever` makes this even more useful by allowing articles to be traversed based on relationships such as articles mentioned in the current article (or mentioning the current article) or articles providing more information on the entities mentioned in the current article.\n",
    "\n",
    "In the next section we'll see not just how we can use the relationships in the metadata to retrieve more articles, but we'll go a step further and perform Lazy GraphRAG to extract relevant claims from both the similar and related articles and use the most relevant claims to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Lazy Graph RAG via Hierarchical Summarization\n",
    "\n",
    "As we've noted before, eagerly building a knowledge graph is prohibitively expensive.\n",
    "Microsoft seems to agree, and recently introduced LazyGraphRAG, which enables GraphRAG to be performed late -- after a query is retrieved.\n",
    "\n",
    "We implement the LazyGraphRAG technique using the traversing retrievers as follows:\n",
    "\n",
    "1. Retrieve a good number of nodes using a traversing retrieval.\n",
    "2. Identify communities in the retrieved sub-graph.\n",
    "3. Extract claims from each community relevant to the query using an LLM.\n",
    "4. Rank each of the claims based on the relevance to the question and select the top claims.\n",
    "5. Generate an answer to the question based on the extracted claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain for Extracting Claims\n",
    "\n",
    "The first thing we do is create a chain that produces the claims. Given an input containing the question and the retrieved communities, it applies an LLM in parallel extracting claims from each community.\n",
    "\n",
    "A claim is just a string representing the statement and the `source_id` of the document. We request structured output so we get a list of claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "from operator import itemgetter\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"Representation of an individual claim from a source document(s).\"\"\"\n",
    "\n",
    "    claim: str = Field(description=\"The claim from the original document(s).\")\n",
    "    source_id: str = Field(description=\"Document ID containing the claim.\")\n",
    "\n",
    "\n",
    "class Claims(BaseModel):\n",
    "    \"\"\"Claims extracted from a set of source document(s).\"\"\"\n",
    "\n",
    "    claims: list[Claim] = Field(description=\"The extracted claims.\")\n",
    "\n",
    "\n",
    "MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "CLAIMS_MODEL = MODEL.with_structured_output(Claims)\n",
    "\n",
    "CLAIMS_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract claims from the following related documents.\n",
    "\n",
    "Only return claims appearing within the specified documents.\n",
    "If no documents are provided, do not make up claims or documents.\n",
    "\n",
    "Claims (and scores) should be relevant to the question.\n",
    "Don't include claims from the documents if they are not directly or indirectly\n",
    "relevant to the question.\n",
    "\n",
    "If none of the documents make any claims relevant to the question, return an\n",
    "empty list of claims.\n",
    "\n",
    "If multiple documents make similar claims, include the original text of each as\n",
    "separate claims. Score the most useful and authoritative claim higher than\n",
    "similar, lower-quality claims.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "{formatted_documents}\n",
    "\"\"\")\n",
    "\n",
    "# TODO: Few-shot examples? Possibly with a selector?\n",
    "\n",
    "\n",
    "def format_documents_with_ids(documents: Iterable[Document]) -> str:\n",
    "    formatted_docs = \"\\n\\n\".join(\n",
    "        f\"Document ID: {doc.id}\\nContent: {doc.page_content}\" for doc in documents\n",
    "    )\n",
    "    return formatted_docs\n",
    "\n",
    "\n",
    "CLAIM_CHAIN = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"formatted_documents\": itemgetter(\"documents\")\n",
    "            | RunnableLambda(format_documents_with_ids),\n",
    "        }\n",
    "    )\n",
    "    | CLAIMS_PROMPT\n",
    "    | CLAIMS_MODEL\n",
    ")\n",
    "\n",
    "\n",
    "class ClaimsChainInput(TypedDict):\n",
    "    question: str\n",
    "    communities: Iterable[Iterable[Document]]\n",
    "\n",
    "\n",
    "@chain\n",
    "async def claims_chain(input: ClaimsChainInput) -> Iterable[Claim]:\n",
    "    question = input[\"question\"]\n",
    "    communities = input[\"communities\"]\n",
    "\n",
    "    # TODO: Use openai directly so this can use the batch API for performance/cost?\n",
    "    community_claims = await CLAIM_CHAIN.abatch(\n",
    "        [{\"question\": question, \"documents\": community} for community in communities]\n",
    "    )\n",
    "    return [claim for community in community_claims for claim in community.claims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain for Ranking Claims\n",
    "\n",
    "The next chain is used for ranking the claims so we can select the most relevant to the question.\n",
    "\n",
    "This is based on ideas from [RankRAG](https://arxiv.org/abs/2407.02485).\n",
    "Specifically, the prompt is constructed so that the next token should be `True` if the content is relevant and `False` if not.\n",
    "The probability of the token is used to determine the relevance -- `True` with a higher probability is more relevant than `True` with a lesser probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "RANK_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "Rank the relevance of the following claim to the question.\n",
    "Output \"True\" if the claim is relevant and \"False\" if it is not.\n",
    "Only output True or False.\n",
    "\n",
    "Question: Where is Seattle?\n",
    "\n",
    "Claim: Seattle is in Washington State.\n",
    "\n",
    "Relevant: True\n",
    "\n",
    "Question: Where is LA?\n",
    "\n",
    "Claim: New York City is in New York State.\n",
    "\n",
    "Relevant: False\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Relevant:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def compute_rank(msg):\n",
    "    logprob = msg.response_metadata[\"logprobs\"][\"content\"][0]\n",
    "    prob = math.exp(logprob[\"logprob\"])\n",
    "    token = logprob[\"token\"]\n",
    "    if token == \"True\":\n",
    "        return prob\n",
    "    elif token == \"False\":\n",
    "        return 1.0 - prob\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logprob: {logprob}\")\n",
    "\n",
    "\n",
    "RANK_CHAIN = RANK_PROMPT | MODEL.bind(logprobs=True) | RunnableLambda(compute_rank)\n",
    "\n",
    "\n",
    "class RankChainInput(TypedDict):\n",
    "    question: str\n",
    "    claims: Iterable[Claim]\n",
    "\n",
    "\n",
    "@chain\n",
    "async def rank_chain(input: RankChainInput) -> Iterable[Claim]:\n",
    "    # TODO: Use openai directly so this can use the batch API for performance/cost?\n",
    "    claims = input[\"claims\"]\n",
    "    ranks = await RANK_CHAIN.abatch(\n",
    "        [{\"question\": input[\"question\"], \"claim\": claim} for claim in claims]\n",
    "    )\n",
    "    rank_claims = sorted(\n",
    "        zip(ranks, claims, strict=True), key=lambda rank_claim: rank_claim[0]\n",
    "    )\n",
    "\n",
    "    return [claim for _, claim in rank_claims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could extend this by using an MMR-like strategy for selecting claims.\n",
    "Specifically, we could combine the relevance of the claim to the question and the diversity compared to already selected claims to select the best variety of claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyGraphRAG in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we produce a chain that puts everything together.\n",
    "Given a `GraphRetriever` it retrieves documents, creates communities using edges amongst the retrieved documents, extracts claims from those communities, ranks and selects the best claims, and then answers the question using those claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from graph_retriever.edges import EdgeSpec, MetadataEdgeFunction\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "from langchain_graph_retriever.document_graph import create_graph, group_by_community\n",
    "\n",
    "\n",
    "@chain\n",
    "async def lazy_graph_rag(\n",
    "    question: str,\n",
    "    *,\n",
    "    retriever: GraphRetriever,\n",
    "    model: BaseLanguageModel,\n",
    "    edges: Iterable[EdgeSpec] | MetadataEdgeFunction | None = None,\n",
    "    max_tokens: int = 1000,\n",
    "    **kwargs: Any,\n",
    ") -> str:\n",
    "    \"\"\"Retrieve claims relating to the question using LazyGraphRAG.\n",
    "\n",
    "    Returns the top claims up to the given `max_tokens` as a markdown list.\n",
    "\n",
    "    \"\"\"\n",
    "    edges = edges or retriever.edges\n",
    "    if edges is None:\n",
    "        raise ValueError(\"Must specify 'edges' in invocation or retriever\")\n",
    "\n",
    "    # 1. Retrieve documents using the (traversing) retriever.\n",
    "    documents = await retriever.ainvoke(question, edges=edges, **kwargs)\n",
    "\n",
    "    # 2. Create a graph and extract communities.\n",
    "    document_graph = create_graph(documents, edges=edges)\n",
    "    communities = group_by_community(document_graph)\n",
    "\n",
    "    # 3. Extract claims from the communities.\n",
    "    claims = await claims_chain.ainvoke(\n",
    "        {\"question\": question, \"communities\": communities}\n",
    "    )\n",
    "\n",
    "    # 4. Rank the claims and select claims up to the given token limit.\n",
    "    result_claims = []\n",
    "    tokens = 0\n",
    "\n",
    "    for claim in await rank_chain.ainvoke({\"question\": question, \"claims\": claims}):\n",
    "        claim_str = f\"- {claim.claim} (Source: {claim.source_id})\"\n",
    "\n",
    "        tokens += model.get_num_tokens(claim_str)\n",
    "        if tokens > max_tokens:\n",
    "            break\n",
    "        result_claims.append(claim_str)\n",
    "\n",
    "    return \"\\n\".join(result_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Lazy GraphRAG in LangChain\n",
    "\n",
    "Finally, we sue the Lazy GraphRAG chain we created on the store we populated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_retriever.edges import Id\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "\n",
    "RETRIEVER = GraphRetriever(\n",
    "    store=store,\n",
    "    edges=[(\"mentions\", Id()), (\"entities\", \"entities\")],\n",
    "    k=100,\n",
    "    start_k=30,\n",
    "    adjacent_k=20,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the supporting claims.\n",
    "\n",
    "Only use information from the claims. Do not guess or make up any information.\n",
    "\n",
    "Where possible, reference and quote the supporting claims.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Claims:\n",
    "{claims}\n",
    "\"\"\")\n",
    "\n",
    "LAZY_GRAPH_RAG_CHAIN = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"claims\": RunnablePassthrough()\n",
    "        | lazy_graph_rag.bind(\n",
    "            retriever=RETRIEVER,\n",
    "            model=MODEL,\n",
    "            max_tokens=1000,\n",
    "        ),\n",
    "    }\n",
    "    | ANSWER_PROMPT\n",
    "    | MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Bermudan sloop ships are widely prized for several reasons. Firstly, they feature the Bermuda rig, which is popular because it is easier to sail with a smaller crew or even single-handed, is cheaper due to having less hardware, and performs well when sailing into the wind (Source: 48520). Additionally, Bermuda sloops were constructed using Bermuda cedar, a material valued for its durability and resistance to rot, contributing to the ships' longevity and performance (Source: 17186373). These factors combined make Bermudan sloops highly valued compared to other ships.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 270, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-856efdbd-9ec1-4419-b2db-b9c972cad71e-0', usage_metadata={'input_tokens': 270, 'output_tokens': 116, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUESTION = \"Why are Bermudan sloop ships widely prized compared to other ships?\"\n",
    "await LAZY_GRAPH_RAG_CHAIN.ainvoke(QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, below are the results to the same question using a basic RAG pattern with just vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The documents do not provide specific reasons why Bermudan sloop ships are widely prized compared to other ships. They describe the development and characteristics of the Bermuda sloop, such as its fore-and-aft rigged single-masted design and the use of the Bermuda rig with triangular sails, but do not explicitly state why these ships are particularly valued over others.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 286, 'total_tokens': 358, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-8653ffdc-a7e4-457f-93e6-5e24560b522d-0', usage_metadata={'input_tokens': 286, 'output_tokens': 72, 'total_tokens': 358, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: False\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "VECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the provided documents.\n",
    "\n",
    "Only use information from the documents. Do not guess or make up any information.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Documents:\n",
    "{documents}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "VECTOR_CHAIN = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"documents\": (store.as_retriever() | format_docs),\n",
    "    }\n",
    "    | VECTOR_ANSWER_PROMPT\n",
    "    | MODEL\n",
    ")\n",
    "\n",
    "VECTOR_CHAIN.invoke(QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LazyGraphRAG chain is great when a question needs to consider a large amount of relevant information in order to produce a thorough answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This post demonstrated how easy it is to implement Lazy GraphRAG on top of a document graph.\n",
    "\n",
    "It used `langchain-graph-retriever` from the [graph-rag project](datastax.github.io/graph-rag) to implement the document graph and graph-based retrieval on top of an existing LangChain `VectorStore`.\n",
    "This means you can focus on populating and using your `VectorStore` with useful metadata and add graph-based retrieval and even Lazy GraphRAG when you need it.\n",
    "\n",
    "**Any LangChain `VectorStore` can be used with Lazy GraphRAG without needing to change or re-ingest the stored documents.**\n",
    "Knowledge Graphs and GraphRAG shouldn't be hard or scary.\n",
    "Start simple and easily overlay edges when you need them.\n",
    "\n",
    "Graph retrievers and LazyGraph RAG work well with agents.\n",
    "You can allow the agent to retrieve differently depending on the question -- doing a vector only search for simple questions, traversing to mentioned articles for a deeper question or traversing to articles that cite this to see if there is newer information available.\n",
    "We'll show how to combine these techniques with agents in a future post.\n",
    "Until then, give `langchain-graph-retriever` a try and let us know how it goes!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
