{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Retrieval Beyond Similarity: Lazy GraphRAG in LangChain\"\n",
    "author: Ben Chambers\n",
    "execute:\n",
    "    output: false\n",
    "    warning: false\n",
    "    error: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqhMgAGwmLXc"
   },
   "source": [
    "# Retrieval Beyond Similarity: LazyGraphRAG in LangChain\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In [LazyGraphRAG](https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/), Microsoft demonstrates significant cost and performance benefits to delaying the construction of a knowledge graph.\n",
    "This is largely because not all documents need to be analyzed.\n",
    "However, it is also benefical that documents by the time documents are analyzed the question is already known, allowing irrelevant information to be ignored. \n",
    "\n",
    "We've noticed similar cost benefits to building a document graph linking content based on simple properties such as extracted keywords compared to building a complete knowledge graph.\n",
    "For the Wikipedia dataset used in this notebook, we estimated it would have taken $70k to build a knowledege graph using the [example from LangChain](https://python.langchain.com/docs/how_to/graph_constructing/#llm-graph-transformer), while the document graph was basically free.\n",
    "\n",
    "In this notebook we demonstrate how to populate a document graph with Wikipedia articles linked based on mentions in the articles and extracted keywords.\n",
    "Keyword extraction uses a local [KeyBERT](https://maartengr.github.io/KeyBERT/) model, making it fast and cost-effective to construct these graphs.\n",
    "We'll then show how to build out a chain which does the steps of Lazy GraphRAG -- retrieving articles, extracting claims from each community, ranking and selecting the top claims, and generating an answer based on those claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6dFtwI_xmFW"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "The following block will configure the environment from the Colab Secrets.\n",
    "To run it, you should have the following Colab Secrets defined and accessible to this notebook:\n",
    "\n",
    "- `OPENAI_API_KEY`: The OpenAI key.\n",
    "- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n",
    "- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n",
    "- `LANGCHAIN_API_KEY`: Optional. If defined, will enable LangSmith tracing.\n",
    "- `ASTRA_DB_KEYSPACE`: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "r0-5VJWGsBM3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain-astradb in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: langchain-openai in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-graph-retriever in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: graph-rag-example-helpers in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: spacy[apple] in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (3.7.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: astrapy<2.0.0,>=1.5.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (1.5.2)\n",
      "Requirement already satisfied: langchain-community>=0.3.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (0.3.14)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-astradb) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-openai) (1.60.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: backoff>=2.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-graph-retriever) (2.2.1)\n",
      "Requirement already satisfied: networkx>=3.4.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-graph-retriever) (3.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (75.8.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (3.5.0)\n",
      "Requirement already satisfied: thinc-apple-ops<1.0.0,>=0.1.0.dev0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy[apple]) (0.1.5)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (0.28.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (1.0.1)\n",
      "Requirement already satisfied: simsimd>=6.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from graph-rag-example-helpers) (6.2.1)\n",
      "Requirement already satisfied: deprecation<2.2.0,>=2.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (2.1.0)\n",
      "Requirement already satisfied: pymongo>=3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.10.1)\n",
      "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (0.10.2)\n",
      "Requirement already satisfied: uuid6>=2024.1.12 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from astrapy<2.0.0,>=1.5.2->langchain-astradb) (2024.7.10)\n",
      "Requirement already satisfied: anyio in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->graph-rag-example-helpers) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->graph-rag-example-helpers) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (0.3.14)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.1->langchain-astradb) (2.7.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy[apple]) (1.3.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy[apple]) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy[apple]) (0.1.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy[apple]) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy[apple]) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jinja2->spacy[apple]) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.1->langchain-astradb) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (3.24.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (0.9.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.1.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.14->langchain-community>=0.3.1->langchain-astradb) (0.3.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[apple]) (1.2.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pymongo>=3->astrapy<2.0.0,>=1.5.2->langchain-astradb) (2.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy[apple]) (1.17.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain-astradb) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain-astradb) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# @ Install modules.\n",
    "%pip install \\\n",
    "    langchain-core \\\n",
    "    langchain-astradb \\\n",
    "    langchain-openai \\\n",
    "    langchain-graph-retriever \\\n",
    "    \"spacy[apple]\" \\\n",
    "    graph-rag-example-helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/benjamin.chambers/code/graph-pancake/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last package -- `graph-rag-example-helpers` -- includes some helpers for setting up environment helpers and allowing the loading of wikipedia data to be restarted if it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure import paths.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Initialize environment variables.\n",
    "from graph_rag_example_helpers.env import Environment, initialize_environment\n",
    "\n",
    "initialize_environment(Environment.ASTRAPY)\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"lazy-graph-rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data\n",
    "\n",
    "First, we'll demonstrate how to load Wikipedia data into an `AstraDBVectorStore`, using the mentioned articles and keywords as metadata fields.\n",
    "In this section, we're not actually doing anything special for the graph -- we're just populating the metadata with fields that useful describe our content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Documents from Wikipedia Articles\n",
    "The first thing we need to do is create the `LangChain` `Document`s we'll import.\n",
    "\n",
    "To do this, we write some code to convert lines from a JSON file downloaded from [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021) and create a `Document`.\n",
    "We populate the `id` and `metadata[\"mentions\"]` from information in this file.\n",
    "\n",
    "Then, we run those documents through the `SpacyNERTransformer` to populate `metadata[\"entities\"]` with entities named in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8u4lD-AqDMMs"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Iterator\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_graph_retriever.document_transformers.spacy import (\n",
    "    SpacyNERTransformer,\n",
    ")\n",
    "\n",
    "\n",
    "def parse_document(line: bytes) -> Document:\n",
    "    \"\"\"Reads one JSON line from the wikimultihop dump.\"\"\"\n",
    "    para = json.loads(line)\n",
    "\n",
    "    id = para[\"id\"]\n",
    "    title = para[\"title\"]\n",
    "\n",
    "    # Use structured information (mentioned Wikipedia IDs) as metadata.\n",
    "    mentioned_ids = [id for m in para[\"mentions\"] for m in m[\"ref_ids\"] or []]\n",
    "\n",
    "    return Document(\n",
    "        id=id,\n",
    "        page_content=\" \".join(para[\"sentences\"]),\n",
    "        metadata={\n",
    "            \"mentions\": mentioned_ids,\n",
    "            \"title\": title,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "NER_TRANSFORMER = SpacyNERTransformer(\n",
    "    limit=1000,\n",
    "    exclude_labels={\"CARDINAL\", \"MONEY\", \"QUANTITY\", \"TIME\", \"PERCENT\", \"ORDINAL\"},\n",
    ")\n",
    "\n",
    "\n",
    "# Load data in batches, using GLiNER to extract entities.\n",
    "def prepare_batch(lines: Iterator[str]) -> Iterator[Document]:\n",
    "    # Parse documents from the batch of lines.\n",
    "    docs = [parse_document(line) for line in lines]\n",
    "\n",
    "    docs = NER_TRANSFORMER.transform_documents(docs)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the AstraDBVectorStore\n",
    "Next, we create the Vector Store we're going to load these documents into.\n",
    "In our case, we use DataStax Astra DB with Open AI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Create the AstraDBVectorStore\n",
    "\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION = \"lazy_graph_rag\"\n",
    "store = AstraDBVectorStore(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=COLLECTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into the Store\n",
    "Next, we perform the actual loading.\n",
    "This takes a while, so we use a helper utility to persist which batches have been written so we can resume if there are any failures.\n",
    "\n",
    "On OS X, it is useful to run `caffeinate -dis` in a shell to prevent the machine from going to sleep and seems to reduce errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming loading with 11699 completed, 0 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:32, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks: 0, Pending Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "from graph_rag_example_helpers.datasets.wikimultihop import aload_2wikimultihop\n",
    "\n",
    "# Path to the file `para_with_hyperlink.zip`.\n",
    "# See instructions here to download from\n",
    "# [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\n",
    "PARA_WITH_HYPERLINK_ZIP = os.path.join(os.getcwd(), \"para_with_hyperlink.zip\")\n",
    "\n",
    "await aload_2wikimultihop(PARA_WITH_HYPERLINK_ZIP, store, prepare_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've created a `VectorStore` with the Wikipedia articles.\n",
    "Each article is associated with metadata identifying other articles it mentions and entities from the article.\n",
    "\n",
    "As is, this is useful for performing a vector search filtered to articles mentioning a specific term or performing an entity seach on the documents.\n",
    "The library `langchain-graph-retriever` makes this even more useful by allowing articles to be traversed based on relationships such as articles mentioned in the current article (or mentioning the current article) or articles providing more information on the entities mentioned in the current article.\n",
    "\n",
    "In the next section we'll see not just how we can use the relationships in the metadata to retrieve more articles, but we'll go a step further and perform Lazy GraphRAG to extract relevant claims from both the similar and related articles and use the most relevant claims to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Lazy Graph RAG via Hierarchical Summarization\n",
    "\n",
    "As we've noted before, eagerly building a knowledge graph is prohibitively expensive.\n",
    "Microsoft seems to agree, and recently introduced LazyGraphRAG, which enables GraphRAG to be performed late -- after a query is retrieved.\n",
    "\n",
    "We implement the LazyGraphRAG technique using the traversing retrievers as follows:\n",
    "\n",
    "1. Retrieve a good number of nodes using a traversing retrieval.\n",
    "2. Identify communities in the retrieved sub-graph.\n",
    "3. Extract claims from each community relevant to the query using an LLM.\n",
    "4. Rank each of the claims based on the relevance to the question and select the top claims.\n",
    "5. Generate an answer to the question based on the extracted claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain for Extracting Claims\n",
    "\n",
    "The first thing we do is create a chain that produces the claims. Given an input containing the question and the retrieved communities, it applies an LLM in parallel extracting claims from each community.\n",
    "\n",
    "A claim is just a string representing the statement and the `source_id` of the document. We request structured output so we get a list of claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "from operator import itemgetter\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"Representation of an individual claim from a source document(s).\"\"\"\n",
    "\n",
    "    claim: str = Field(description=\"The claim from the original document(s).\")\n",
    "    source_id: str = Field(description=\"Document ID containing the claim.\")\n",
    "\n",
    "\n",
    "class Claims(BaseModel):\n",
    "    \"\"\"Claims extracted from a set of source document(s).\"\"\"\n",
    "\n",
    "    claims: list[Claim] = Field(description=\"The extracted claims.\")\n",
    "\n",
    "\n",
    "MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "CLAIMS_MODEL = MODEL.with_structured_output(Claims)\n",
    "\n",
    "CLAIMS_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract claims from the following related documents.\n",
    "\n",
    "Only return claims appearing within the specified documents.\n",
    "If no documents are provided, do not make up claims or documents.\n",
    "\n",
    "Claims (and scores) should be relevant to the question.\n",
    "Don't include claims from the documents if they are not directly or indirectly\n",
    "relevant to the question.\n",
    "\n",
    "If none of the documents make any claims relevant to the question, return an\n",
    "empty list of claims.\n",
    "\n",
    "If multiple documents make similar claims, include the original text of each as\n",
    "separate claims. Score the most useful and authoritative claim higher than\n",
    "similar, lower-quality claims.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "{formatted_documents}\n",
    "\"\"\")\n",
    "\n",
    "# TODO: Few-shot examples? Possibly with a selector?\n",
    "\n",
    "\n",
    "def format_documents_with_ids(documents: Iterable[Document]) -> str:\n",
    "    formatted_docs = \"\\n\\n\".join(\n",
    "        f\"Document ID: {doc.id}\\nContent: {doc.page_content}\" for doc in documents\n",
    "    )\n",
    "    return formatted_docs\n",
    "\n",
    "\n",
    "CLAIM_CHAIN = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"formatted_documents\": itemgetter(\"documents\")\n",
    "            | RunnableLambda(format_documents_with_ids),\n",
    "        }\n",
    "    )\n",
    "    | CLAIMS_PROMPT\n",
    "    | CLAIMS_MODEL\n",
    ")\n",
    "\n",
    "\n",
    "class ClaimsChainInput(TypedDict):\n",
    "    question: str\n",
    "    communities: Iterable[Iterable[Document]]\n",
    "\n",
    "\n",
    "@chain\n",
    "async def claims_chain(input: ClaimsChainInput) -> Iterable[Claim]:\n",
    "    question = input[\"question\"]\n",
    "    communities = input[\"communities\"]\n",
    "\n",
    "    # TODO: Use openai directly so this can use the batch API for performance/cost?\n",
    "    community_claims = await CLAIM_CHAIN.abatch(\n",
    "        [{\"question\": question, \"documents\": community} for community in communities]\n",
    "    )\n",
    "    return [claim for community in community_claims for claim in community.claims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain for Ranking Claims\n",
    "\n",
    "The next chain is used for ranking the claims so we can select the most relevant to the question.\n",
    "\n",
    "This is based on ideas from [RankRAG](https://arxiv.org/abs/2407.02485).\n",
    "Specifically, the prompt is constructed so that the next token should be `True` if the content is relevant and `False` if not.\n",
    "The probability of the token is used to determine the relevance -- `True` with a higher probability is more relevant than `True` with a lesser probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "RANK_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "Rank the relevance of the following claim to the question.\n",
    "Output \"True\" if the claim is relevant and \"False\" if it is not.\n",
    "Only output True or False.\n",
    "\n",
    "Question: Where is Seattle?\n",
    "\n",
    "Claim: Seattle is in Washington State.\n",
    "\n",
    "Relevant: True\n",
    "\n",
    "Question: Where is LA?\n",
    "\n",
    "Claim: New York City is in New York State.\n",
    "\n",
    "Relevant: False\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Relevant:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def compute_rank(msg):\n",
    "    logprob = msg.response_metadata[\"logprobs\"][\"content\"][0]\n",
    "    prob = math.exp(logprob[\"logprob\"])\n",
    "    token = logprob[\"token\"]\n",
    "    if token == \"True\":\n",
    "        return prob\n",
    "    elif token == \"False\":\n",
    "        return 1.0 - prob\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logprob: {logprob}\")\n",
    "\n",
    "\n",
    "RANK_CHAIN = RANK_PROMPT | MODEL.bind(logprobs=True) | RunnableLambda(compute_rank)\n",
    "\n",
    "\n",
    "class RankChainInput(TypedDict):\n",
    "    question: str\n",
    "    claims: Iterable[Claim]\n",
    "\n",
    "\n",
    "@chain\n",
    "async def rank_chain(input: RankChainInput) -> Iterable[Claim]:\n",
    "    # TODO: Use openai directly so this can use the batch API for performance/cost?\n",
    "    claims = input[\"claims\"]\n",
    "    ranks = await RANK_CHAIN.abatch(\n",
    "        [{\"question\": input[\"question\"], \"claim\": claim} for claim in claims]\n",
    "    )\n",
    "    rank_claims = sorted(\n",
    "        zip(ranks, claims, strict=True), key=lambda rank_claim: rank_claim[0]\n",
    "    )\n",
    "\n",
    "    return [claim for _, claim in rank_claims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could extend this by using an MMR-like strategy for selecting claims.\n",
    "Specifically, we could combine the relevance of the claim to the question and the diversity compared to already selected claims to select the best variety of claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyGraphRAG in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we produce a chain that puts everything together.\n",
    "Given a `GraphRetriever` it retrieves documents, creates communities using edges amongst the retrieved documents, extracts claims from those communities, ranks and selects the best claims, and then answers the question using those claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "from langchain_graph_retriever.document_graph import create_graph, group_by_community\n",
    "from langchain_graph_retriever.edges.metadata import EdgeSpec, MetadataEdgeFunction\n",
    "\n",
    "\n",
    "@chain\n",
    "async def lazy_graph_rag(\n",
    "    question: str,\n",
    "    *,\n",
    "    retriever: GraphRetriever,\n",
    "    model: BaseLanguageModel,\n",
    "    edges: Iterable[EdgeSpec] | MetadataEdgeFunction | None = None,\n",
    "    max_tokens: int = 1000,\n",
    "    **kwargs: Any,\n",
    ") -> str:\n",
    "    \"\"\"Retrieve claims relating to the question using LazyGraphRAG.\n",
    "\n",
    "    Returns the top claims up to the given `max_tokens` as a markdown list.\n",
    "\n",
    "    \"\"\"\n",
    "    edges = edges or retriever.edges\n",
    "    if edges is None:\n",
    "        raise ValueError(\"Must specify 'edges' in invocation or retriever\")\n",
    "\n",
    "    # 1. Retrieve documents using the (traversing) retriever.\n",
    "    documents = await retriever.ainvoke(question, edges=edges, **kwargs)\n",
    "\n",
    "    # 2. Create a graph and extract communities.\n",
    "    document_graph = create_graph(documents, edges=edges)\n",
    "    communities = group_by_community(document_graph)\n",
    "\n",
    "    # 3. Extract claims from the communities.\n",
    "    claims = await claims_chain.ainvoke(\n",
    "        {\"question\": question, \"communities\": communities}\n",
    "    )\n",
    "\n",
    "    # 4. Rank the claims and select claims up to the given token limit.\n",
    "    result_claims = []\n",
    "    tokens = 0\n",
    "\n",
    "    for claim in await rank_chain.ainvoke({\"question\": question, \"claims\": claims}):\n",
    "        claim_str = f\"- {claim.claim} (Source: {claim.source_id})\"\n",
    "\n",
    "        tokens += model.get_num_tokens(claim_str)\n",
    "        if tokens > max_tokens:\n",
    "            break\n",
    "        result_claims.append(claim_str)\n",
    "\n",
    "    return \"\\n\".join(result_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Lazy GraphRAG in LangChain\n",
    "\n",
    "Finally, we sue the Lazy GraphRAG chain we created on the store we populated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "\n",
    "RETRIEVER = GraphRetriever(\n",
    "    store=store,\n",
    "    edges=[(\"mentions\", \"id\"), (\"entities\", \"entities\")],\n",
    "    k=100,\n",
    "    start_k=30,\n",
    "    adjacent_k=20,\n",
    "    max_depth=3,\n",
    ")\n",
    "\n",
    "ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the supporting claims.\n",
    "\n",
    "Only use information from the claims. Do not guess or make up any information.\n",
    "\n",
    "Where possible, reference and quote the supporting claims.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Claims:\n",
    "{claims}\n",
    "\"\"\")\n",
    "\n",
    "LAZY_GRAPH_RAG_CHAIN = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"claims\": RunnablePassthrough()\n",
    "        | lazy_graph_rag.bind(\n",
    "            retriever=RETRIEVER,\n",
    "            model=MODEL,\n",
    "            max_tokens=1000,\n",
    "        ),\n",
    "    }\n",
    "    | ANSWER_PROMPT\n",
    "    | MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities: 8\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Why are Bermudan sloop ships widely prized compared to other ships?\"\n",
    "result = await LAZY_GRAPH_RAG_CHAIN.ainvoke(QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Bermudan sloop ships are widely prized due to their historical significance and unique design. They are a type of fore-and-aft rigged single-masted sailing vessel that evolved on the islands of Bermuda in the 17th century. The Bermuda sloop uses the Bermuda rig with triangular sails, which is part of a long-standing tradition of Bermudian boat design dating back to the early 17th century (Source: 196264). This historical and design heritage contributes to their esteemed reputation.\n"
     ]
    }
   ],
   "source": [
    "# | echo: False\n",
    "# | output: asis\n",
    "for line in result.content.splitlines():\n",
    "    print(f\"> {line}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, below are the results to the same question using a basic RAG pattern with just vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: False\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "VECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the provided documents.\n",
    "\n",
    "Only use information from the documents. Do not guess or make up any information.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Documents:\n",
    "{documents}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "VECTOR_CHAIN = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"documents\": (store.as_retriever() | format_docs),\n",
    "    }\n",
    "    | VECTOR_ANSWER_PROMPT\n",
    "    | MODEL\n",
    ")\n",
    "\n",
    "vector_result = VECTOR_CHAIN.invoke(QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The documents do not provide specific reasons why Bermudan sloop ships are widely prized compared to other ships. They describe the development and characteristics of the Bermuda sloop, such as its fore-and-aft rig, single mast, and evolution to the Bermuda rig with triangular sails, but do not explicitly state why these ships are particularly valued over others.\n"
     ]
    }
   ],
   "source": [
    "# | echo: False\n",
    "# | output: asis\n",
    "for line in vector_result.content.splitlines():\n",
    "    print(f\"> {line}\")  # noqa: T201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LazyGraphRAG chain is great when a question needs to consider a large amount of relevant information in order to produce a thorough answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This post demonstrated how easy it is to implement Lazy GraphRAG on top of a document graph.\n",
    "\n",
    "It used langchain-graph-retriever` from the [graph-rag project](datastax.github.io/graph-rag) to implement the document graph and graph-based retrieval on top of an existing LangChain `VectorStore`.\n",
    "This means you can focus on populating and using your `VectorStore` with useful metadata and add graph-based retrieval and even Lazy GraphRAG when you need it.\n",
    "\n",
    "**Any LangChain `VectorStore` can be used with Lazy GraphRAG without needing to change or re-ingest the stored documents.**\n",
    "Knowledge Graphs and GraphRAG shouldn't be hard or scary.\n",
    "Start simple and easily overlay edges when you need them.\n",
    "\n",
    "Graph retrievers and LazyGraph RAG work well with agents.\n",
    "You can allow the agent to retrieve differently depending on the question -- doing a vector only search for simple questions, traversing to mentioned articles for a deeper question or traversing to articles that cite this to see if there is newer information available.\n",
    "We'll show how to combine these techniques with agents in a future post.\n",
    "Until then, give `langchain-graph-retriever` a try and let us know how it goes!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
