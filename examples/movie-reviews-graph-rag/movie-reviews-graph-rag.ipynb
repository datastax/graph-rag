{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ruff: noqa: I001, E501, T201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph RAG on Movie Reviews from Rotten Tomatoes\n",
    "\n",
    "This notebook presents a basic case study for using graph RAG techniques to\n",
    "combine the power of retrieval-augmented generation (RAG) with knowledge graphs\n",
    "based on datasets that are linked to one another in a natural way.\n",
    "\n",
    "In particular, we use the `GraphRetriever` implementation in LangChain. For more\n",
    "information, see the open-source [Graph RAG project on\n",
    "GitHub](https://datastax.github.io/graph-rag)\n",
    "\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The website Rotten Tomatoes has published a [large dataset of movie\n",
    "reviews](https://www.kaggle.com/datasets/andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews).\n",
    "The dataset includes two CSV files containing:\n",
    "\n",
    "1. the movie reviews, and\n",
    "2. information about the movies referenced in those reviews\n",
    "\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "In this case study, the challenge is to build a system that allows users to\n",
    "search movie review content using arbitrary prompts, and then return the top\n",
    "reviews together with the full information about the reviewed movies.\n",
    "\n",
    "\n",
    "## The Strategy\n",
    "\n",
    "First, we build a standard RAG system for querying the movie reviews, which are\n",
    "embedded and stored in a vector database. It is important to note that in this\n",
    "step, **we store the embedded reviews together with metadata that is necessary\n",
    "for traversing the knowledge graph and linking reviews with the movie data.**\n",
    "\n",
    "Second, we use a `GraphRetriever` that is configured specifically to:\n",
    "\n",
    "1. retrieve relevant movie reviews via standard RAG,\n",
    "2. traverse the knowledge graph edges to the relevant movies, and\n",
    "3. return the full movie data together with each movie review.\n",
    "\n",
    "In this implementation, the metadata is the basis for the knowledge graph, and\n",
    "the mechanics of graph traversal is specified as part of the `GraphRetriever`.\n",
    "In this way, a change in the configuration of the `GraphRetriever` changes the\n",
    "way that graph edges are defined and how the implied knowledge graph is\n",
    "traversed. There is no need to modify the data set or re-build the knoweledge\n",
    "graph beyond specifying a new `GraphRetriever` configuration.\n",
    "\n",
    "See below for how to build this graph RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "%pip install \\\n",
    "        dotenv \\\n",
    "        pandas \\\n",
    "        langchain_openai \\\n",
    "        langchain-graph-retriever \\\n",
    "        langchain-astradb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "\n",
    "This notebook uses the APIs for OpenAI and Astra DB\n",
    "\n",
    "**NOTE:** the environment variables for Astra DB are not required if running\n",
    "only the code with the small data sample below, but are required for the code\n",
    "below that works with the full dataset.\n",
    "\n",
    "You can [get an OpenAI API key here](https://platform.openai.com/settings/organization/api-keys). \n",
    "And, more information about using the OpenAI API in Python \n",
    "[can be found here](https://github.com/openai/openai-python/blob/main/README.md).\n",
    "\n",
    "Here are the [instructions to set up a free Astra serverless database](https://docs.datastax.com/en/astra-db-serverless/databases/create-database.html#create-vector-database).\n",
    "\n",
    "To connect to these services within this notebook, the following environment\n",
    "variables are required (or optional, as noted):\n",
    "\n",
    "- `OPENAI_API_KEY`: Your OpenAI API key.\n",
    "- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n",
    "- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n",
    "- `ASTRA_DB_KEYSPACE`: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default.\n",
    "- `LANGCHAIN_API_KEY`: Optional. If defined, will enable LangSmith tracing.\n",
    "\n",
    "\n",
    "If running this notebook in Colab, configure these environment variables as\n",
    "Colab Secrets.\n",
    "\n",
    "If running this notebook locally, make sure you have a `.env` file containing\n",
    "all of the required variables, and then use the `dotenv` package as below to\n",
    "load environment variables from that file. More details on `dotenv` \n",
    "[can be found here](https://pypi.org/project/python-dotenv/#getting-started).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "The website Rotten Tomatoes has published a [large dataset of movie\n",
    "reviews](https://www.kaggle.com/datasets/andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews).\n",
    "containing:\n",
    "\n",
    "1. `rotten_tomatoes_movie_reviews.csv` -- the movie reviews\n",
    "2. `rotten_tomatoes_movies.csv` -- information about the movies referenced in those reviews\n",
    "\n",
    "Below, we first give a small sample dataset contained in this notebook, so that\n",
    "you can try this implementation of graph RAG without needing to download and\n",
    "process the full dataset from files.\n",
    "\n",
    "Or, you can skip loading this data sample and proceed directly to \"Loading the\n",
    "full dataset from file\" below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a small data sample\n",
    "\n",
    "Below is a sample dataset that is coded into this notebook as string objects and then read into `pandas` dataframes using `StringIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "reviews_data_string = \"\"\"\n",
    "id,reviewId,creationDate,criticName,isTopCritic,originalScore,reviewState,publicatioName,reviewText,scoreSentiment,reviewUrl\n",
    "addams_family,2644238,2019-11-10,James Kendrick,False,3/4,fresh,Q Network Film Desk,captures the family's droll humor with just the right mixture of morbidity and genuine care,POSITIVE,http://www.qnetwork.com/review/4178\n",
    "addams_family,2509777,2018-09-12,John Ferguson,False,4/5,fresh,Radio Times,A witty family comedy that has enough sly humour to keep adults chuckling throughout.,POSITIVE,https://www.radiotimes.com/film/fj8hmt/the-addams-family/\n",
    "addams_family,26216,2000-01-01,Rita Kempley,True,,fresh,Washington Post,\"More than merely a sequel of the TV series, the film is a compendium of paterfamilias Charles Addams's macabre drawings, a resurrection of the cartoonist's body of work. For family friends, it would seem a viewing is de rigueur mortis.\",POSITIVE,http://www.washingtonpost.com/wp-srv/style/longterm/movies/videos/theaddamsfamilypg13kempley_a0a280.htm\n",
    "the_addams_family_2019,2699537,2020-06-27,Damond Fudge,False,,fresh,\"KCCI (Des Moines, IA)\",\"As was proven by the 1992-93 cartoon series, animation is the perfect medium for this creepy, kooky family, allowing more outlandish escapades\",POSITIVE,https://www.kcci.com/article/movie-review-the-addams-family/29443537\n",
    "the_addams_family_2019,2662133,2020-01-21,Ryan Silberstein,False,,fresh,Cinema76,\"This origin casts the Addams family as an immigrant story, and the film leans so hard into the theme of accepting those different from us and valuing diversity over conformity,\",POSITIVE,https://www.cinema76.com/home/2019/10/11/the-addams-family-is-a-fun-update-to-an-iconic-american-clan\n",
    "the_addams_family_2019,2661356,2020-01-17,Jennifer Heaton,False,5.5/10,rotten,Alternative Lens,...The film's simplistic and episodic plot put a major dampener on what could have been a welcome breath of fresh air for family animation.,NEGATIVE,https://altfilmlens.wordpress.com/2020/01/17/my-end-of-year-surplus-review-extravaganza-thing-2019/\n",
    "the_addams_family_2,102657551,2022-02-16,Mat Brunet,False,4/10,rotten,AniMat's Review (YouTube),The Addams Family 2 repeats what the first movie accomplished by taking the popular family and turning them into one of the most boringly generic kids films in recent years.,NEGATIVE,https://www.youtube.com/watch?v=G9deslxPDwI\n",
    "the_addams_family_2,2832101,2021-10-15,Sandie Angulo Chen,False,3/5,fresh,Common Sense Media,This serviceable animated sequel focuses on Wednesday's feelings of alienation and benefits from the family's kid-friendly jokes and road trip adventures.,POSITIVE,https://www.commonsensemedia.org/movie-reviews/the-addams-family-2\n",
    "the_addams_family_2,2829939,2021-10-08,Emily Breen,False,2/5,rotten,HeyUGuys,\"Lifeless and flat, doing a disservice to the family name and the talent who voice them. WIthout glamour, wit or a hint of a soul. A void. Avoid.\",NEGATIVE,https://www.heyuguys.com/the-addams-family-2-review/\n",
    "addams_family_values,102735159,2022-09-22,Sean P. Means,False,3/4,fresh,Salt Lake Tribune,Addams Family Values is a ghoulishly fun time. It would have been a real howl if the producers weren't too scared to go out on a limb in this twisted family tree.,POSITIVE,https://www.newspapers.com/clip/110004014/addams-family-values/\n",
    "addams_family_values,102734540,2022-09-21,Jami Bernard,True,3.5/4,fresh,New York Daily News,\"The title is apt. Using those morbidly sensual cartoon characters as pawns, the new movie Addams Family Values launches a witty assault on those with fixed ideas about what constitutes a loving family. \",POSITIVE,https://www.newspapers.com/clip/109964753/addams-family-values/\n",
    "addams_family_values,102734521,2022-09-21,Jeff Simon,False,3/4,fresh,Buffalo News,\"Addams Family Values has its moments -- rather a lot of them, in fact. You knew that just from the title, which is a nice way of turning Charles Addams' family of ghouls, monsters and vampires loose on Dan Quayle.\",POSITIVE,https://buffalonews.com/news/quirky-values-the-addams-family-returns-with-a-bouncing-baby/article_2aafde74-da6c-5fa7-924a-76bb1a906d9c.html\n",
    "\"\"\"\n",
    "\n",
    "movies_data_string = \"\"\"\n",
    "id,title,audienceScore,tomatoMeter,rating,ratingContents,releaseDateTheaters,releaseDateStreaming,runtimeMinutes,genre,originalLanguage,director,writer,boxOffice,distributor,soundMix\n",
    "addams_family,The Addams Family,66,67,,,1991-11-22,2005-08-18,99,Comedy,English,Barry Sonnenfeld,\"Charles Addams,Caroline Thompson,Larry Wilson\",$111.3M,Paramount Pictures,\"Surround, Dolby SR\"\n",
    "the_addams_family_2019,The Addams Family,69,45,PG,\"['Some Action', 'Macabre and Suggestive Humor']\",2019-10-11,2019-10-11,87,\"Kids & family, Comedy, Animation\",English,\"Conrad Vernon,Greg Tiernan\",\"Matt Lieberman,Erica Rivinoja\",$673.0K,Metro-Goldwyn-Mayer,Dolby Atmos\n",
    "the_addams_family_2,The Addams Family 2,69,28,PG,\"['Macabre and Rude Humor', 'Language', 'Violence']\",2021-10-01,2021-10-01,93,\"Kids & family, Comedy, Adventure, Animation\",English,\"Greg Tiernan,Conrad Vernon\",\"Dan Hernandez,Benji Samit,Ben Queen,Susanna Fogel\",$56.5M,Metro-Goldwyn-Mayer,\n",
    "addams_family_reunion,Addams Family Reunion,33,,,,,,92,Comedy,English,Dave Payne,,,,\n",
    "addams_family_values,Addams Family Values,63,75,,,1993-11-19,2003-08-05,93,Comedy,English,Barry Sonnenfeld,Paul Rudnick,$45.7M,\"Argentina Video Home, Paramount Pictures\",\"Surround, Dolby Digital\"\n",
    "\"\"\"\n",
    "\n",
    "reviews_all = pd.read_csv(StringIO(reviews_data_string))\n",
    "movies_all = pd.read_csv(StringIO(movies_data_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data\n",
    "\n",
    "First, we rename one column in each of the two dataframes so that we can use\n",
    "them later to build a knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the id columns to more informative and useful names\n",
    "reviews_data = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"})\n",
    "movies_data = movies_all.rename(columns={\"id\": \"movie_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the vector store, with embedding\n",
    "\n",
    "Next, for the small data sample, we create an `InMemoryVectorStore` from\n",
    "LangChain using `OpenAIEmbeddings()` to embed the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# create the vector store\n",
    "vectorstore = InMemoryVectorStore(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the full dataset from file\n",
    "\n",
    "Before running this code, make sure you have downloaded (and extracted) the\n",
    "dataset from the link provided above. The date files should be in your working\n",
    "directory, or you will need to change the file paths below to match the\n",
    "locations of your files.\n",
    "\n",
    "See the top of this notebook for links and information about the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change this to the path where you stored the data files. See the top of this\n",
    "# notebook for links and information about the datasets.\n",
    "DATA_PATH = \"../../../../datasets/\"\n",
    "\n",
    "# read the datasets from CSV files\n",
    "reviews_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movie_reviews.csv\")\n",
    "movies_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movies.csv\")\n",
    "\n",
    "print(\"Data is loaded from CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data\n",
    "\n",
    "First, we rename one column in each of the two dataframes so that we can use\n",
    "them later to build a knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# rename the id columns to more informative and useful names\n",
    "reviews_all = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"})\n",
    "movies_all = movies_all.rename(columns={\"id\": \"movie_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's have a look at the movies that have the most reviews,\n",
    "and take a subset of the reviews to save time in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Here, we limit our dataset to the movies with the most reviews. This is simply\n",
    "# to save data processing and loading time while testing things in this notebook.\n",
    "N_TOP_MOVIES = 10\n",
    "most_reviewed_movies = reviews_all[\"reviewed_movie_id\"].value_counts()[:N_TOP_MOVIES]\n",
    "\n",
    "most_reviewed_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# subset the data to only reviews and movies corresponding to the most reviewed movies\n",
    "reviews_data = reviews_all[\n",
    "    reviews_all[\"reviewed_movie_id\"].isin(most_reviewed_movies.index)\n",
    "]\n",
    "movies_data = movies_all[movies_all[\"movie_id\"].isin(most_reviewed_movies.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the vector store, with embedding\n",
    "\n",
    "Next, for the small data sample, we create an `AstraDBVectorStore` from\n",
    "LangChain using `OpenAIEmbeddings()` to embed the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION = \"movie_reviews_rotten_tomatoes\"\n",
    "vectorstore = AstraDBVectorStore(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=COLLECTION,\n",
    "    pre_delete_collection=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to `Document` objects and store them\n",
    "\n",
    "Next, we convert both movies and movie reviews into LangChain `Document`\n",
    "objects. The content of each document---which is embedded into vectors---is\n",
    "configured to be the movie review text (for review documents) or the movie title\n",
    "(for movie documents). All remaining information is saved as metadata on each\n",
    "document.\n",
    "\n",
    "Note that to save time in this demo, we limit the dataset to include only the\n",
    "movies that have the most reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert each movie review into a LangChain document\n",
    "documents = []\n",
    "# convert each movie into a LangChain document\n",
    "for index, row in movies_data.iterrows():\n",
    "    content = str(row[\"title\"])\n",
    "    metadata = row.fillna(\"\").astype(str).to_dict()\n",
    "    metadata[\"doc_type\"] = \"movie_info\"\n",
    "    document = Document(page_content=content, metadata=metadata)\n",
    "    documents.append(document)\n",
    "\n",
    "\n",
    "for index, row in reviews_data.iterrows():\n",
    "    content = str(row[\"reviewText\"])\n",
    "    metadata = row.drop(\"reviewText\").fillna(\"\").astype(str).to_dict()\n",
    "    metadata[\"doc_type\"] = \"movie_review\"\n",
    "    document = Document(page_content=content, metadata=metadata)\n",
    "    documents.append(document)\n",
    "\n",
    "\n",
    "# check the total number of documents\n",
    "print(\"There are\", len(documents), \"total Documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the structure of a document\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add documents to the store\n",
    "vectorstore.add_documents(documents)\n",
    "\n",
    "# NOTE: this may take some minutes to load many documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the GraphRetriever\n",
    "\n",
    "The `GraphRetriever` operates on top of the vector store, using document\n",
    "metadata to traverse the implicit knowledge graph as defined by the `edges`\n",
    "parameter in `GraphRetriever` configuration.\n",
    "\n",
    "Edges are specified as directed pairs of metadata fields. In the example below,\n",
    "the edge configuration\n",
    "\n",
    "```\n",
    "edges = [(\"reviewed_movie_id\", \"movie_id\")]\n",
    "```\n",
    "\n",
    "specifies that there is a directed graph edge between two documents whenever the\n",
    "`reviewed_movie_id` of the first document matches the `movie_id` of the\n",
    "second---and graph traversal proceeds along these directed edges. In this case,\n",
    "all of our edges lead from a document containing a movie review to a document\n",
    "containing information about the movie.\n",
    "\n",
    "The `strategy` parameter of the `GraphRetriever` configuration determines how\n",
    "the graph is traversed, starting with the initial documents retrieved and\n",
    "proceeding along the directed edges to adjacent documents.\n",
    "\n",
    "In the example below, the configuration\n",
    "\n",
    "```\n",
    "strategy=Eager(start_k=10,\n",
    "               adjacent_k=10,\n",
    "               select_k=10,\n",
    "               max_depth=1)\n",
    "```\n",
    "\n",
    "uses the following steps:\n",
    "\n",
    "1. it initially retrieves `start_k=10` documents using pure vector search,\n",
    "2. then traverses graph edges from the initial documents to adjacent documents\n",
    "   (a max of `adjacent_k`),\n",
    "3. it repeats traversal from the new documents until reaching `max_depth=1`,\n",
    "4. it returns both the initial documents and documents retrieved during\n",
    "   traversal, up to a maximum of `select_k` documents.\n",
    "\n",
    "Note that in this simple example, each movie review has a graph edge leading to\n",
    "exactly one movie, so each initial document (a movie review) should have one\n",
    "edge to traverse to another document (a movie) at a depth of 1. And, each movie\n",
    "document has no out-going edges to traverse, so the traversal depth would not\n",
    "proceed beyond depth 1 regardless of the value for `max_depth`. We demonstrate\n",
    "deeper and more complex strategies in other examples.\n",
    "\n",
    "For more details, see the [documentation on GraphRetriever\n",
    "strategy.](https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_retriever.strategies import Eager\n",
    "from langchain_graph_retriever import GraphRetriever\n",
    "\n",
    "retriever = GraphRetriever(\n",
    "    store=vectorstore,\n",
    "    edges=[(\"reviewed_movie_id\", \"movie_id\")],\n",
    "    strategy=Eager(start_k=10, adjacent_k=10, select_k=100, max_depth=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_PROMPT_TEXT = \"What are some good family movies?\"\n",
    "# INITIAL_PROMPT_TEXT = \"What are some recommendations of exciting action movies?\"\n",
    "# INITIAL_PROMPT_TEXT = \"What are some classic movies with amazing cinematography?\"\n",
    "\n",
    "\n",
    "# invoke the query\n",
    "query_results = retriever.invoke(INITIAL_PROMPT_TEXT)\n",
    "\n",
    "# print the raw retrieved results\n",
    "for result in query_results:\n",
    "    print(result.metadata[\"doc_type\"], \": \", result.page_content)\n",
    "    print(result.metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Graph RAG results\n",
    "\n",
    "Now that we have completed graph retrieval, we can reformat the text and\n",
    "metadata in the results, so we can pass them to an LLM---via an augmented\n",
    "prompt---and generate a response to the initial prompt question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the movie info for each film retrieved\n",
    "compiled_results = {}\n",
    "for result in query_results:\n",
    "    if result.metadata[\"doc_type\"] == \"movie_info\":\n",
    "        movie_id = result.metadata[\"movie_id\"]\n",
    "        movie_title = result.metadata[\"title\"]\n",
    "        compiled_results[movie_id] = {\n",
    "            \"movie_id\": movie_id,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"reviews\": {},\n",
    "        }\n",
    "\n",
    "# go through the results a second time, collecting the retreived reviews for\n",
    "# each of the movies\n",
    "for result in query_results:\n",
    "    if result.metadata[\"doc_type\"] == \"movie_review\":\n",
    "        reviewed_movie_id = result.metadata[\"reviewed_movie_id\"]\n",
    "        review_id = result.metadata[\"reviewId\"]\n",
    "        review_text = result.page_content\n",
    "        compiled_results[reviewed_movie_id][\"reviews\"][review_id] = review_text\n",
    "\n",
    "\n",
    "# compile the retrieved movies and reviews into a string that we can pass to an\n",
    "# LLM in an augmented prompt\n",
    "formatted_text = \"\"\n",
    "for movie_id, review_list in compiled_results.items():\n",
    "    formatted_text += \"\\n\\n Movie Title: \"\n",
    "    formatted_text += review_list[\"movie_title\"]\n",
    "    formatted_text += \"\\n Movie ID: \"\n",
    "    formatted_text += review_list[\"movie_id\"]\n",
    "    for review_id, review_text in review_list[\"reviews\"].items():\n",
    "        formatted_text += \"\\n Review: \"\n",
    "        formatted_text += review_text\n",
    "\n",
    "\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an AI summary of results\n",
    "\n",
    "Here, using the `formatted_text` from above, we set up a prompt template, and\n",
    "then pass it the retrieved movie reviews along with the the original query text\n",
    "to be answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "VECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "\n",
    "A list of Movie Reviews appears below. Please answer the Initial Prompt text\n",
    "(below) using only the listed Movie Reviews.\n",
    "\n",
    "Please include all movies that might be helpful to someone looking for movie\n",
    "recommendations.\n",
    "\n",
    "\n",
    "\n",
    "Initial Prompt:\n",
    "{initial_prompt}\n",
    "\n",
    "\n",
    "Movie Reviews:\n",
    "{movie_reviews}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "formatted_prompt = VECTOR_ANSWER_PROMPT.format(\n",
    "    initial_prompt=INITIAL_PROMPT_TEXT,\n",
    "    movie_reviews=formatted_text,\n",
    ")\n",
    "\n",
    "result = MODEL.invoke(formatted_prompt)\n",
    "\n",
    "# print(formatted_prompt)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-rag-dZGJIgE-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
