{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Graph RAG","text":"<p>Graph RAG provides retrievers that combine unstructured similarity-search on vectors and structured traversal of metadata properties. These retrievers are implemented using the metadata search functionality of existing vector stores, allowing you to traverse your existing vector store!</p> <ul> <li> <p> Link based on existing metadata</p> <p>Use existing metadata fields without additional processing. Retrieve more from your existing vector store!</p> <p> Get started</p> </li> <li> <p> Change links on demand</p> <p>Edges can be specified on-the-fly, allowing different relationships to be traversed based on the question.</p> <p> Edges</p> </li> <li> <p> Pluggable Traversal Strategies</p> <p>Use built-in traversal strategies like Eager or MMR, or define your own logic to select which nodes to explore.</p> <p> Strategies</p> </li> <li> <p> Broad compatibility</p> <p>Adapters are available for a variety of vector stores with support for additional stores easily added.</p> <p> Adapters</p> </li> </ul>"},{"location":"#example-langchain-retriever-combining-vector-and-graph-traversal","title":"Example: LangChain Retriever combining Vector and Graph traversal","text":"<pre><code>from langchain_graph_retriever import GraphRetriever\n\nretriever = GraphRetriever(\n    store = store,\n    edges = [(\"mentions\", \"$id\"), (\"entities\", \"entities\")], # (1)!\n)\n\nretriever.invoke(\"where is Santa Clara?\")\n</code></pre> <ol> <li><code>edges</code> configures traversing from a node to other nodes listed in the <code>metadata[\"mentions\"]</code> field (to the corresponding <code>id</code>) and to other nodes with overlapping <code>metadata[\"entities\"]</code>.</li> </ol> <p>See Examples for more complete examples.</p>"},{"location":"blog/2025/01/31/introducing-graph-rag/","title":"Introducing Graph Retrievers: Smarter, Simpler Document Graphs for Vector Stores","text":"<p>We're excited to announce the release of Graph Retrievers, a powerful new tool for leveraging graph traversal in your vector stores with ease!</p> <p>With Graph Retrievers, you can dynamically explore relationships between documents using metadata fields\u2014no need for complex preprocessing or building an entire knowledge graph upfront.</p>"},{"location":"blog/2025/01/31/introducing-graph-rag/#a-brief-history-where-we-started","title":"A Brief History: Where We Started","text":"<p>We originally developed <code>GraphVectorStore</code> to efficiently handle structured relationships between documents. This approach proved especially useful for reducing costs in knowledge graph creation. By lazily traversing metadata instead of building a full graph, we made real-time retrieval more efficient and cost-effective.</p> <p>Recently, Microsoft introduced LazyGraphRAG which found similar cost and performance benefits by linking documents based on named entities rather than building a full knowledge graph.</p> <p>Since GraphVectorStore was introduced into LangChain, the concept of traversing document graphs has evolved significantly, and today, Graph Retrievers offers an easier and more flexible way to bring graph-like capabilities to your vector stores.</p>"},{"location":"blog/2025/01/31/introducing-graph-rag/#whats-new-in-graph-retrievers","title":"What\u2019s New in Graph Retrievers?","text":"<ol> <li> <p>Effortless Metadata Linking    Documents can now be linked via metadata fields without additional processing. You define relationships on-the-fly.    Use different configurations to tailor traversal to your needs, such as exploring citations or co-authorships.</p> </li> <li> <p>Pluggable Traversal Strategies    In addition to built-in strategies like eager traversal and MMR, you can now define your own logic for graph exploration.</p> </li> <li> <p>Broad Compatibility    Adapters are available for DataStax Astra DB, Apache Cassandra, Chroma DB, and OpenSearch, with support for additional stores easily added.</p> </li> </ol>"},{"location":"blog/2025/01/31/introducing-graph-rag/#example-getting-started-with-graph-retrievers","title":"Example: Getting Started with Graph Retrievers","text":"<p>Here\u2019s how you can use Graph Retrievers with an existing <code>AstraDBVectorStore</code> that includes metadata fields for article mentions and named entities.</p> <p>Assuming you already have a LangChain project using a Vector Store, all you need to do is:</p> <ol> <li> <p>The following example assumes you already have a LangChain Vector Store.    We're using an existing <code>AstraDBVectorStore</code> similar to:</p> <pre><code>from langchain_astradb import AstraDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = AstraDBVectorStore(\n    collection_name=\"animals\",\n    embedding=OpenAIEmbeddings(),\n)\n</code></pre> </li> <li> <p>Install <code>langchain-graph-retriever</code>:</p> <pre><code>pip install langchain-graph-retriever\n</code></pre> </li> <li> <p>Add the following code using your existing Vector Store.</p> <pre><code>from langchain_graph_retriever import GraphRetriever\n\n# Define your graph traversal\ntraversal = GraphRetriever(\n    store=vector_store,\n    edges=[(\"mentions\", \"id\"), (\"entities\", \"entites\")],\n)\n\n# Query the graph\ntraversal.invoke(\"Where is Lithuania?\")\n</code></pre> </li> </ol> <p>With just a few lines of code, you can navigate relationships between articles, dynamically retrieving the most relevant information for your query.</p>"},{"location":"blog/2025/01/31/introducing-graph-rag/#try-it-out-today","title":"Try It Out Today!","text":"<p>Reflecting these improvements, we've moved the implementation to a new package and repository, making it even easier to integrate and explore.</p> <ul> <li>Documentation: Learn how to get started in the official documentation.</li> <li>Join the Community: Share feedback or contribute by opening an issue or pull request in the GitHub repo.</li> </ul> <p>Give Graph Retrievers a try today and take your retrieval-augmented generation (RAG) workflows to the next level. We can\u2019t wait to hear what you build!</p>"},{"location":"examples/","title":"Examples","text":"<ul> <li> <p> Connecting Movies and Reviews</p> <p>This example shows how to build a system that can search movie reviews for certain types  of comments---such as \u201cWhat is a good family movie?\u201d---and then immediately connect the  resulting reviews to the movies they are discussing.</p> <p> Movie Reviews Example</p> </li> <li> <p> Lazy Graph RAG</p> <p>Implements LazyGraphRAG using LangChain and <code>langchain-graph-retriever</code>.</p> <p>It loads Wikipedia articles and traverses based on links (\"mentions\") and named entities (extracted from the content). It retrieves a large number of articles, groups them by community, and extracts claims from each community. The best claims are used to answer the question.</p> <p> Lazy Graph RAG Example</p> </li> <li> <p> Code Generation</p> <p>This example notebook shows how to load documentation for python packages into a vector store so that it can be used to provide context to an LLM for code generation.</p> <p>It uses LangChain and <code>langchain-graph-retriever</code> with a custom traversal Strategy in order to improve LLM generated code output. It shows that using GraphRAG can provide a significant increase in quality over using either an LLM alone or standard RAG.</p> <p>GraphRAG traverses cross references in the documentation like a software engineer would, in order to determine how to solve a coding problem.</p> <p> Code Generation Example</p> </li> </ul>"},{"location":"examples/code-generation/","title":"Code Generation with GraphRAG","text":"In\u00a0[\u00a0]: Copied! <pre>query = \"\"\"\nGenerate a function for connecting to an AstraDB cluster using the AstraPy library,\nand retrieve some rows from a collection. The number of rows to return should be a\nparameter on the method. Use Token Authentication. Assume the cluster is hosted on\nAstraDB. Include the necessary imports and any other necessary setup. The following\nenvironment variables are available for your use:\n\n- `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint.\n- `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token.\n- `ASTRA_DB_KEYSPACE`: The Astra DB keyspace.\n- `ASTRA_DB_COLLECTION`: The Astra DB collection.\" \\\n\"\"\"\n</pre> query = \"\"\" Generate a function for connecting to an AstraDB cluster using the AstraPy library, and retrieve some rows from a collection. The number of rows to return should be a parameter on the method. Use Token Authentication. Assume the cluster is hosted on AstraDB. Include the necessary imports and any other necessary setup. The following environment variables are available for your use:  - `ASTRA_DB_API_ENDPOINT`: The Astra DB API endpoint. - `ASTRA_DB_APPLICATION_TOKEN`: The Astra DB Application token. - `ASTRA_DB_KEYSPACE`: The Astra DB keyspace. - `ASTRA_DB_COLLECTION`: The Astra DB collection.\" \\ \"\"\" <p>The following block will configure the environment from the Colab Secrets. To run it, you should have the following Colab Secrets defined and accessible to this notebook:</p> <ul> <li><code>OPENAI_API_KEY</code>: The OpenAI key.</li> <li><code>ASTRA_DB_API_ENDPOINT</code>: The Astra DB API endpoint.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: The Astra DB Application token.</li> <li><code>LANGCHAIN_API_KEY</code>: Optional. If defined, will enable LangSmith tracing.</li> <li><code>ASTRA_DB_KEYSPACE</code>: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default.</li> </ul> <p>If you don't yet have access to an AstraDB database, or need to check your credentials, see the help here.</p> In\u00a0[\u00a0]: Copied! <pre># Install modules.\n\n%pip install \\\n    langchain-core \\\n    langchain-astradb \\\n    langchain-openai \\\n    langchain-graph-retriever \\\n    graph-rag-example-helpers\n</pre> # Install modules.  %pip install \\     langchain-core \\     langchain-astradb \\     langchain-openai \\     langchain-graph-retriever \\     graph-rag-example-helpers <p>The last package -- <code>graph-rag-example-helpers</code> -- includes the helpers and example documents that we will use in this notebook.</p> In\u00a0[\u00a0]: Copied! <pre># Configure import paths.\nimport os\nimport sys\n\nfrom langchain_core.documents import Document\n\nsys.path.append(\"../../\")\n\n# Initialize environment variables.\nfrom graph_rag_example_helpers.env import Environment, initialize_environment\n\ninitialize_environment(Environment.ASTRAPY)\n\nos.environ[\"LANGCHAIN_PROJECT\"] = \"code-generation\"\nos.environ[\"ASTRA_DB_COLLECTION\"] = \"code_generation\"\n\n\ndef print_doc_ids(docs: list[Document]):\n    [print(f\"`{doc.id}` has example: {'example' in doc.metadata}\") for doc in docs]\n</pre> # Configure import paths. import os import sys  from langchain_core.documents import Document  sys.path.append(\"../../\")  # Initialize environment variables. from graph_rag_example_helpers.env import Environment, initialize_environment  initialize_environment(Environment.ASTRAPY)  os.environ[\"LANGCHAIN_PROJECT\"] = \"code-generation\" os.environ[\"ASTRA_DB_COLLECTION\"] = \"code_generation\"   def print_doc_ids(docs: list[Document]):     [print(f\"`{doc.id}` has example: {'example' in doc.metadata}\") for doc in docs] In\u00a0[\u00a0]: Copied! <pre>from langchain_astradb import AstraDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nstore = AstraDBVectorStore(\n    embedding=OpenAIEmbeddings(),\n    collection_name=os.getenv(\"ASTRA_DB_COLLECTION\"),\n)\n</pre> from langchain_astradb import AstraDBVectorStore from langchain_openai import OpenAIEmbeddings  store = AstraDBVectorStore(     embedding=OpenAIEmbeddings(),     collection_name=os.getenv(\"ASTRA_DB_COLLECTION\"), ) In\u00a0[\u00a0]: Copied! <pre>from graph_rag_example_helpers.datasets.astrapy import fetch_documents\nfrom langchain_graph_retriever.transformers import ParentTransformer\n\ntransformer = ParentTransformer(path_delimiter=\".\")\ndoc_ids = store.add_documents(transformer.transform_documents(fetch_documents()))\n</pre> from graph_rag_example_helpers.datasets.astrapy import fetch_documents from langchain_graph_retriever.transformers import ParentTransformer  transformer = ParentTransformer(path_delimiter=\".\") doc_ids = store.add_documents(transformer.transform_documents(fetch_documents())) <p>We can retrieve a sample document to check if the parent field was added correctly:</p> In\u00a0[\u00a0]: keep_output Copied! <pre>from graph_rag_example_helpers.examples.code_generation import format_document\n\nprint(\n    format_document(\n        store.get_by_document_id(\"astrapy.admin.AstraDBAdmin.callers\"), debug=True\n    )\n)\n</pre> from graph_rag_example_helpers.examples.code_generation import format_document  print(     format_document(         store.get_by_document_id(\"astrapy.admin.AstraDBAdmin.callers\"), debug=True     ) ) <pre>callers (attribute)\n\npath: \n\tastrapy.admin.AstraDBAdmin.callers\n\ncallers = callers_param\n\nparent: astrapy.admin.AstraDBAdmin\n</pre> <p>At this point, we've created a Vector Store with all the documents from the AstraPy documentation. Each document contains metadata about the module, class, attribute, or function, and the page content contains the description of the item.</p> <p>In the next section we'll see how to build relationships from the metadata in order to traverse through the documentation in a similar way to how a human would.</p> In\u00a0[\u00a0]: Copied! <pre>edges = [\n    (\"gathered_types\", \"$id\"),\n    (\"references\", \"$id\"),\n    (\"parent\", \"$id\"),\n    (\"implemented_by\", \"$id\"),\n    (\"bases\", \"$id\"),\n]\n</pre> edges = [     (\"gathered_types\", \"$id\"),     (\"references\", \"$id\"),     (\"parent\", \"$id\"),     (\"implemented_by\", \"$id\"),     (\"bases\", \"$id\"), ] <p>Note that edges are directional, and indicate metadata fields by default.  The magic string <code>$id</code> is used to indicate the document's id.</p> <p>In the above <code>edges</code> list, any document id found in <code>gathered_types</code> will be connected to documents with the corresponding id. The other edges will work in a similar way.</p> <p>Lets use these edges to create a LangChain retriever and documents for our query.</p> In\u00a0[\u00a0]: keep_output Copied! <pre>from langchain_graph_retriever import GraphRetriever\n\ndefault_retriever = GraphRetriever(store=store, edges=edges)\n\nprint_doc_ids(default_retriever.invoke(query, select_k=6, start_k=3, max_depth=2))\n</pre> from langchain_graph_retriever import GraphRetriever  default_retriever = GraphRetriever(store=store, edges=edges)  print_doc_ids(default_retriever.invoke(query, select_k=6, start_k=3, max_depth=2)) <pre>`astrapy.core.db.AsyncAstraDB.collection` has example: False\n`astrapy.core.db.AstraDB.collection` has example: False\n`astrapy.admin.DataAPIDatabaseAdmin.list_keyspaces` has example: True\n`astrapy.admin.DataAPIDatabaseAdmin` has example: True\n`astrapy.core.db.AsyncAstraDB` has example: False\n`astrapy.core.db.AstraDBCollection` has example: False\n</pre> <p>Notes on the extra keyword args:</p> <ul> <li><code>select_k</code> in GraphRAG is equivalent to <code>k</code> in LangChain. It specifies the number of nodes to select during retrieval.</li> <li><code>start_k</code> indicates the number of nodes to select using standard vector retrieval before moving onto graph traversal.</li> <li><code>max_depth</code> is the maximum depth to traverse in the graph.</li> </ul> <p>With this configuration, we were only able to find 2 documents with example code.</p> In\u00a0[\u00a0]: Copied! <pre>import dataclasses\nfrom collections.abc import Iterable\n\nfrom graph_retriever.strategies import NodeTracker, Strategy\nfrom graph_retriever.types import Node\n\n\n@dataclasses.dataclass\nclass CodeExamples(Strategy):\n    # internal dictionary to store all nodes found during the traversal\n    _nodes: dict[str, Node] = dataclasses.field(default_factory=dict)\n\n    def iteration(self, *, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:\n        # save all newly found nodes to the internal node dictionary for later use\n        self._nodes.update({n.id: n for n in nodes})\n        # traverse the newly found nodes\n        new_count = tracker.traverse(nodes=nodes)\n\n        # if no new nodes were found, we have reached the end of the traversal\n        if new_count == 0:\n            example_nodes = []\n            description_nodes = []\n\n            # iterate over all nodes and separate nodes with examples from nodes with\n            # descriptions\n            for node in self._nodes.values():\n                if \"example\" in node.metadata:\n                    example_nodes.append(node)\n                elif node.content != \"\":\n                    description_nodes.append(node)\n\n            # select the nodes with examples first and descriptions second\n            # note: the base `finalize_nodes` method will truncate the list to the\n            #   `select_k` number of nodes\n            tracker.select(example_nodes)\n            tracker.select(description_nodes)\n</pre> import dataclasses from collections.abc import Iterable  from graph_retriever.strategies import NodeTracker, Strategy from graph_retriever.types import Node   @dataclasses.dataclass class CodeExamples(Strategy):     # internal dictionary to store all nodes found during the traversal     _nodes: dict[str, Node] = dataclasses.field(default_factory=dict)      def iteration(self, *, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:         # save all newly found nodes to the internal node dictionary for later use         self._nodes.update({n.id: n for n in nodes})         # traverse the newly found nodes         new_count = tracker.traverse(nodes=nodes)          # if no new nodes were found, we have reached the end of the traversal         if new_count == 0:             example_nodes = []             description_nodes = []              # iterate over all nodes and separate nodes with examples from nodes with             # descriptions             for node in self._nodes.values():                 if \"example\" in node.metadata:                     example_nodes.append(node)                 elif node.content != \"\":                     description_nodes.append(node)              # select the nodes with examples first and descriptions second             # note: the base `finalize_nodes` method will truncate the list to the             #   `select_k` number of nodes             tracker.select(example_nodes)             tracker.select(description_nodes) <p>As described in the comments above, this custom strategy will first try to select documents that contain code examples, and then will use documents that contain descriptive text.</p> <p>We can now use this custom strategy to build a custom retriever, and ask the query again:</p> In\u00a0[\u00a0]: keep_output Copied! <pre>custom_retriever = GraphRetriever(store=store, edges=edges, strategy=CodeExamples())\n\nprint_doc_ids(custom_retriever.invoke(query, select_k=6, start_k=3, max_depth=2))\n</pre> custom_retriever = GraphRetriever(store=store, edges=edges, strategy=CodeExamples())  print_doc_ids(custom_retriever.invoke(query, select_k=6, start_k=3, max_depth=2)) <pre>`astrapy.admin.DataAPIDatabaseAdmin.list_keyspaces` has example: True\n`astrapy.admin.DataAPIDatabaseAdmin` has example: True\n`astrapy.client.DataAPIClient` has example: True\n`astrapy.database.AsyncDatabase` has example: True\n`astrapy.database.Database` has example: True\n`astrapy.authentication.UsernamePasswordTokenProvider` has example: True\n</pre> <p>Now we have found 6 documents with code examples! That is a significant improvement over the default strategy.</p> In\u00a0[\u00a0]: keep_output Copied! <pre>from graph_rag_example_helpers.examples.code_generation import format_docs\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\nllm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Generate a block of runnable python code using the following documentation as\n    guidance. Return only the code. Don't include any example usage.\n\n    Each documentation page is separated by three dashes (---) on its own line.\n    If certain pages of the provided documentation aren't useful for answering the\n    question, feel free to ignore them.\n\n    Question: {question}\n\n    Related Documentation:\n\n    {context}\n    \"\"\"\n)\n\ngraph_chain = (\n    {\"context\": custom_retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(graph_chain.invoke(query))\n</pre> from graph_rag_example_helpers.examples.code_generation import format_docs from langchain.chat_models import init_chat_model from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_core.runnables import RunnablePassthrough  llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")  prompt = ChatPromptTemplate.from_template(     \"\"\"Generate a block of runnable python code using the following documentation as     guidance. Return only the code. Don't include any example usage.      Each documentation page is separated by three dashes (---) on its own line.     If certain pages of the provided documentation aren't useful for answering the     question, feel free to ignore them.      Question: {question}      Related Documentation:      {context}     \"\"\" )  graph_chain = (     {\"context\": custom_retriever | format_docs, \"question\": RunnablePassthrough()}     | prompt     | llm     | StrOutputParser() )  print(graph_chain.invoke(query)) <pre>```python\nimport os\nfrom astrapy.client import DataAPIClient\nfrom astrapy.collection import Collection\n\ndef connect_and_retrieve_rows(num_rows):\n    api_endpoint = os.getenv('ASTRA_DB_API_ENDPOINT')\n    application_token = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n    keyspace = os.getenv('ASTRA_DB_KEYSPACE')\n    collection_name = os.getenv('ASTRA_DB_COLLECTION')\n\n    client = DataAPIClient(token=application_token)\n    database = client.get_database(api_endpoint)\n    collection = Collection(database=database, name=collection_name, keyspace=keyspace)\n\n    rows = collection.find(limit=num_rows)\n    return list(rows)\n```\n</pre> <p>We can try running this generated code to see if it works:</p> In\u00a0[\u00a0]: skip-execution Copied! <pre>import os\n\nfrom astrapy.client import DataAPIClient\nfrom astrapy.collection import Collection\n\n\ndef connect_and_retrieve_rows(num_rows):\n    api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n    application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n    keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")\n    collection_name = os.getenv(\"ASTRA_DB_COLLECTION\")\n\n    client = DataAPIClient(token=application_token)\n    database = client.get_database(api_endpoint)\n    collection = Collection(database=database, name=collection_name, keyspace=keyspace)\n\n    rows = collection.find(limit=num_rows)\n    return list(rows)\n</pre> import os  from astrapy.client import DataAPIClient from astrapy.collection import Collection   def connect_and_retrieve_rows(num_rows):     api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")     application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")     keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")     collection_name = os.getenv(\"ASTRA_DB_COLLECTION\")      client = DataAPIClient(token=application_token)     database = client.get_database(api_endpoint)     collection = Collection(database=database, name=collection_name, keyspace=keyspace)      rows = collection.find(limit=num_rows)     return list(rows) In\u00a0[\u00a0]: skip_execution keep_output raises-exception Copied! <pre>for row in connect_and_retrieve_rows(5):\n    print(row)\n</pre> for row in connect_and_retrieve_rows(5):     print(row) <pre>{'_id': 'astrapy.info.EmbeddingProviderAuthentication', 'content': 'A representation of an authentication mode for using an embedding model,\\nmodeling the corresponding part of the response returned by the\\n\\'findEmbeddingProviders\\' Data API endpoint (namely \"supportedAuthentication\").', 'metadata': {'kind': 'class', 'name': 'EmbeddingProviderAuthentication', 'path': 'astrapy.info.EmbeddingProviderAuthentication', 'parameters': [{'name': 'enabled', 'type': 'bool'}, {'name': 'tokens', 'type': 'list[EmbeddingProviderToken]'}], 'attributes': [{'name': 'enabled', 'type': 'bool', 'description': 'whether this authentication mode is available for a given model.'}, {'name': 'tokens', 'type': 'list[EmbeddingProviderToken]', 'description': 'a list of `EmbeddingProviderToken` objects,\\ndetailing the secrets required for the authentication mode.'}], 'gathered_types': ['EmbeddingProviderToken'], 'parent': 'astrapy.info'}}\n{'_id': 'astrapy.defaults.DEV_OPS_RESPONSE_HTTP_CREATED', 'content': '', 'metadata': {'kind': 'attribute', 'name': 'DEV_OPS_RESPONSE_HTTP_CREATED', 'path': 'astrapy.defaults.DEV_OPS_RESPONSE_HTTP_CREATED', 'value': 'DEV_OPS_RESPONSE_HTTP_CREATED = 201', 'parent': 'astrapy.defaults'}}\n{'_id': 'astrapy.info.CollectionInfo.full_name', 'content': '', 'metadata': {'kind': 'attribute', 'name': 'full_name', 'path': 'astrapy.info.CollectionInfo.full_name', 'value': 'full_name: str', 'parent': 'astrapy.info.CollectionInfo'}}\n{'_id': 'astrapy.collection.Collection.full_name', 'content': 'The fully-qualified collection name within the database,\\nin the form \"keyspace.collection_name\".', 'metadata': {'kind': 'attribute', 'name': 'full_name', 'path': 'astrapy.collection.Collection.full_name', 'value': 'full_name: str', 'example': \"&gt;&gt;&gt; my_coll.full_name\\n'default_keyspace.my_v_collection'\", 'parent': 'astrapy.collection.Collection'}}\n{'_id': 'astrapy.exceptions.DataAPIErrorDescriptor', 'content': 'An object representing a single error returned from the Data API,\\ntypically with an error code and a text message.\\nAn API request would return with an HTTP 200 success error code,\\nbut contain a nonzero amount of these.\\n\\nA single response from the Data API may return zero, one or more of these.\\nMoreover, some operations, such as an insert_many, may partally succeed\\nyet return these errors about the rest of the operation (such as,\\nsome of the input documents could not be inserted).', 'metadata': {'kind': 'class', 'name': 'DataAPIErrorDescriptor', 'path': 'astrapy.exceptions.DataAPIErrorDescriptor', 'parameters': [{'name': 'error_dict', 'type': 'dict[str, str]'}], 'attributes': [{'name': 'error_code', 'type': 'str | None', 'description': 'a string code as found in the API \"error\" item.'}, {'name': 'message', 'type': 'str | None', 'description': 'the text found in the API \"error\" item.'}, {'name': 'attributes', 'type': 'dict[str, Any]', 'description': 'a dict with any further key-value pairs returned by the API.'}], 'parent': 'astrapy.exceptions'}}\n</pre> In\u00a0[\u00a0]: skip_execution keep_output Copied! <pre>llm_only_prompt = ChatPromptTemplate.from_template(\n    \"\"\"Generate a block of runnable python code. Return only the code.\n    Don't include any example usage.\n\n    Question: {question}\n    \"\"\"\n)\n\nllm_only_chain = (\n    {\"question\": RunnablePassthrough()} | llm_only_prompt | llm | StrOutputParser()\n)\n\nprint(llm_only_chain.invoke(query))\n</pre> llm_only_prompt = ChatPromptTemplate.from_template(     \"\"\"Generate a block of runnable python code. Return only the code.     Don't include any example usage.      Question: {question}     \"\"\" )  llm_only_chain = (     {\"question\": RunnablePassthrough()} | llm_only_prompt | llm | StrOutputParser() )  print(llm_only_chain.invoke(query)) <pre>```python\nimport os\nfrom astra import AstraClient\n\ndef fetch_rows_from_astra_db(num_rows):\n    # Retrieve environment variables\n    api_endpoint = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n    application_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n    keyspace = os.getenv(\"ASTRA_DB_KEYSPACE\")\n    collection = os.getenv(\"ASTRA_DB_COLLECTION\")\n    \n    # Initialize the Astra DB client\n    client = AstraClient(api_endpoint, application_token)\n    \n    # Retrieve rows from the specified collection\n    query = f'SELECT * FROM {keyspace}.{collection} LIMIT {num_rows}'\n    response = client.execute_statement(query)\n    \n    # Return the rows retrieved\n    return response['rows']\n```\n</pre> <p>This code is not functional. The package <code>astra</code> and the class <code>AstraClient</code> do not exist.</p> In\u00a0[\u00a0]: skip_execution keep_output Copied! <pre>rag_chain = (\n    {\n        \"context\": store.as_retriever(k=6) | format_docs,\n        \"question\": RunnablePassthrough(),\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(rag_chain.invoke(query))\n</pre> rag_chain = (     {         \"context\": store.as_retriever(k=6) | format_docs,         \"question\": RunnablePassthrough(),     }     | prompt     | llm     | StrOutputParser() )  print(rag_chain.invoke(query)) <pre>```python\nimport os\nfrom astra import AstraClient\n\ndef fetch_rows_from_astradb(num_rows):\n    endpoint = os.getenv('ASTRA_DB_API_ENDPOINT')\n    token = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n    keyspace = os.getenv('ASTRA_DB_KEYSPACE')\n    collection = os.getenv('ASTRA_DB_COLLECTION')\n\n    client = AstraClient(\n        endpoint=endpoint,\n        token=token\n    )\n\n    query = f'SELECT * FROM {keyspace}.{collection} LIMIT {num_rows}'\n    response = client.execute(query)\n    return response['data']\n```\n</pre> <p>This code is also not functional.</p>"},{"location":"examples/code-generation/#code-generation-with-graphrag","title":"Code Generation with GraphRAG\u00b6","text":""},{"location":"examples/code-generation/#introduction","title":"Introduction\u00b6","text":"<p>In this notebook, we demonstrate that GraphRAG significantly outperforms standard vector-based retrieval for generating working code from documentation. While traditional vector search retrieves relevant snippets, it often lacks the structured understanding needed to produce executable results. In contrast, GraphRAG enables the LLM to follow logical relationships within documentation, leading to functional code generation.</p> <p>We achieve this by leveraging a custom traversal strategy, selecting nodes that contain both code examples and descriptive text, allowing the LLM to assemble more complete responses.</p>"},{"location":"examples/code-generation/#getting-started","title":"Getting Started\u00b6","text":"<p>Below we will experiment with the AstraPy documentation to evaluate how well GraphRAG can generate working code.</p> <p>Using AstraDB as the vector store, we compare GraphRAG\u2019s structured retrieval with standard vector search to solve a specific coding task. The query we will be sending to the LLM is the following:</p>"},{"location":"examples/code-generation/#part-1-loading-data","title":"Part 1: Loading Data\u00b6","text":"<p>First, we'll demonstrate how to load the example AstraPy documentation into <code>AstraDBVectorStore</code>. We will be creating a LangChain Document for every module, class, attribute, and function in the package.</p> <p>We will use the pydoc description field for the <code>page_content</code> field in the document. Note that not every item in the package has a description. Because of this, there will be many documents that have no page content.</p> <p>Besides the description, we will also include a bunch of extra information related to the item in the <code>metadata</code> field. This info can include the item's name, kind, parameters, return type, base class, etc.</p> <p>The item's <code>id</code> will be the items path in the package.</p> <p>Below are two example documents... One with page content and one without.</p>"},{"location":"examples/code-generation/#example-doc-with-page-content","title":"Example doc with page content\u00b6","text":"Click to expand <pre>id: astrapy.client.DataAPIClient\n\npage_content: |\n  A client for using the Data API. This is the main entry point and sits\n  at the top of the conceptual \"client -&gt; database -&gt; collection\" hierarchy.\n\n  A client is created first, optionally passing it a suitable Access Token.\n  Starting from the client, then:\n    - databases (Database and AsyncDatabase) are created for working with data\n    - AstraDBAdmin objects can be created for admin-level work\n\nmetadata:\n  name: DataAPIClient\n  kind: class\n  path: astrapy.client.DataAPIClient\n  parameters: \n    token: |\n      str | TokenProvider | None = None\n      an Access Token to the database. Example: `\"AstraCS:xyz...\"`.\n      This can be either a literal token string or a subclass of\n      `astrapy.authentication.TokenProvider`.\n       \n    environment: |\n      str | None = None\n      a string representing the target Data API environment.\n      It can be left unspecified for the default value of `Environment.PROD`;\n      other values include `Environment.OTHER`, `Environment.DSE`.\n        \n    callers: |\n      Sequence[CallerType] = []\n      a list of caller identities, i.e. applications, or frameworks,\n      on behalf of which Data API and DevOps API calls are performed.\n      These end up in the request user-agent.\n      Each caller identity is a (\"caller_name\", \"caller_version\") pair.\n\n  example: |\n    &gt;&gt;&gt; from astrapy import DataAPIClient\n    &gt;&gt;&gt; my_client = DataAPIClient(\"AstraCS:...\")\n    &gt;&gt;&gt; my_db0 = my_client.get_database(\n    ...     \"https://01234567-....apps.astra.datastax.com\"\n    ... )\n    &gt;&gt;&gt; my_coll = my_db0.create_collection(\"movies\", dimension=2)\n    &gt;&gt;&gt; my_coll.insert_one({\"title\": \"The Title\", \"$vector\": [0.1, 0.3]})\n    &gt;&gt;&gt; my_db1 = my_client.get_database(\"01234567-...\")\n    &gt;&gt;&gt; my_db2 = my_client.get_database(\"01234567-...\", region=\"us-east1\")\n    &gt;&gt;&gt; my_adm0 = my_client.get_admin()\n    &gt;&gt;&gt; my_adm1 = my_client.get_admin(token=more_powerful_token_override)\n    &gt;&gt;&gt; database_list = my_adm0.list_databases()\n\n  references: \n    astrapy.client.DataAPIClient\n\n  gathered_types: \n    astrapy.constants.CallerType\n    astrapy.authentication.TokenProvider\n</pre> <p>This is the documentation for <code>astrapy.client.DataAPIClient</code> class. The <code>page_content</code> field contains the description of the class, and the <code>metadata</code> field contains the rest of the details, including example code of how to use the class.</p> <p>The <code>references</code> metadata field contains the list of related items used in the example code block. The <code>gathered_types</code> field contains the list of types from the parameters section. In GraphRAG, we can use these fields to link to other documents.</p>"},{"location":"examples/code-generation/#example-doc-without-page-content","title":"Example doc without page content\u00b6","text":"Click to expand <pre>id: astrapy.admin.AstraDBAdmin.callers\n\npage_content: \"\"\n\nmetadata:\n  name: callers\n  path: astrapy.admin.AstraDBAdmin.callers\n  kind: attribute\n</pre> <p>This is the documentation for <code>astrapy.admin.AstraDBAdmin.callers</code>. The <code>page_content</code> field is empty, and the <code>metadata</code> field contains the details.</p> <p>Despite having no page content, this document can still be useful for Graph RAG.  We'll add a <code>parent</code> field to the metadata at vector store insertion time to link it to the parent document: <code>astrapy.admin.AstraDBAdmin</code>, and we can use this for traversal.</p>"},{"location":"examples/code-generation/#create-the-astradbvectorstore","title":"Create the AstraDBVectorStore\u00b6","text":"<p>Next, we'll create the Vector Store we're going to load these documents into. In our case, we'll use DataStax Astra DB with Open AI embeddings.</p>"},{"location":"examples/code-generation/#loading-data","title":"Loading Data\u00b6","text":"<p>Now its time to load the data into our Vector Store. We'll use a helper method to download already prepared documents from the <code>graph-rag-example-helpers</code> package. If you want to see how these documents were created from the AstraPy package, see details in the Appendix.</p> <p>We will use the <code>ParentTransformer</code> to add a parent field to the metadata document field. This will allow us to traverse the graph from a child to its parent.</p>"},{"location":"examples/code-generation/#part-2-graph-traversal","title":"Part 2: Graph Traversal\u00b6","text":"<p>The GraphRAG library allows us to traverse through the documents in the Vector Store.  By changing the <code>Strategy</code>, we can control how the traversal is performed.</p>"},{"location":"examples/code-generation/#basic-traversal","title":"Basic Traversal\u00b6","text":"<p>We'll start with the default <code>Eager</code> strategy, which will traverse the graph in a breadth-first manner. In order to do this we need to set up the relationships between the documents. This is done by defining the \"edges\" between the documents.</p> <p>In our case we will connect the \"references\", \"gathered_types\", \"parent\", \"implemented_by\", and \"bases\" fields in the metadata to the \"id\" field of the document they reference.</p>"},{"location":"examples/code-generation/#custom-strategy","title":"Custom Strategy\u00b6","text":"<p>Now we will create a custom strategy that will traverse a larger portion of the graph and return the documents that contain code examples or descriptive text.</p> <p>To do this, we need to implement a class that inherits from the base <code>Strategy</code> class and overrides <code>iteration</code> method:</p>"},{"location":"examples/code-generation/#step-3-using-graphrag-to-generate-code","title":"Step 3: Using GraphRAG to Generate Code\u00b6","text":"<p>We now use the <code>CodeExamples</code> strategy inside a Langchain pipeline to generate code snippets.</p> <p>We will also use a custom document formatter, which will format the document in a way that makes it look like standard documentation. In particular, it will format all the extra details stored in the metadata in a way that is easy to read.  This will help the LLM use the information in the documents to generate code.</p>"},{"location":"examples/code-generation/#conclusion","title":"Conclusion\u00b6","text":"<p>The results clearly demonstrate that GraphRAG leads to functional code generation, while standard vector-based retrieval fails.</p> <p>In contrast, attempts using only an LLM or standard vector-based RAG resulted in incomplete or non-functional outputs. The appendix includes examples illustrating these limitations.</p> <p>By structuring document relationships effectively, GraphRAG improves retrieval quality, enabling more reliable LLM-assisted code generation.</p>"},{"location":"examples/code-generation/#appendix","title":"Appendix\u00b6","text":""},{"location":"examples/code-generation/#llm-alone","title":"LLM Alone\u00b6","text":"<p>Here we show how to use the LLM alone to generate code for the query. We will use the same query as before, but modify the prompt to not include any context.</p>"},{"location":"examples/code-generation/#standard-rag","title":"Standard RAG\u00b6","text":"<p>Here we show how to use the LLM with standard RAG to generate code for the query. We will use the same query and prompt as we did with GraphRAG.</p>"},{"location":"examples/code-generation/#converting-astrapy-documentation","title":"Converting AstraPy Documentation\u00b6","text":"<p>The AstraPy documentation was converted into a JSONL format via some custom code that is not included in this notebook. However, the code is available in the <code>graph-rag-example-helpers</code> package here.</p>"},{"location":"examples/lazy-graph-rag/","title":"LazyGraphRAG in LangChain","text":"In\u00a0[\u00a0]: hide_output Copied! <pre># Install modules.\n#\n# On Apple hardware, \"spacy[apple]\" will improve performance.\n%pip install \\\n    langchain-core \\\n    langchain-astradb \\\n    langchain-openai \\\n    langchain-graph-retriever \\\n    spacy \\\n    graph-rag-example-helpers\n</pre> # Install modules. # # On Apple hardware, \"spacy[apple]\" will improve performance. %pip install \\     langchain-core \\     langchain-astradb \\     langchain-openai \\     langchain-graph-retriever \\     spacy \\     graph-rag-example-helpers <p>The last package -- <code>graph-rag-example-helpers</code> -- includes some helpers for setting up environment helpers and allowing the loading of wikipedia data to be restarted if it fails.</p> In\u00a0[\u00a0]: hide_output Copied! <pre># Downloads the model used by Spacy for extracting entities.\n!python -m spacy download en_core_web_sm\n</pre> # Downloads the model used by Spacy for extracting entities. !python -m spacy download en_core_web_sm In\u00a0[\u00a0]: hide_output Copied! <pre># Configure import paths.\nimport os\nimport sys\n\nsys.path.append(\"../../\")\n\n# Initialize environment variables.\nfrom graph_rag_example_helpers.env import Environment, initialize_environment\n\ninitialize_environment(Environment.ASTRAPY)\n\nos.environ[\"LANGCHAIN_PROJECT\"] = \"lazy-graph-rag\"\n\n# The full dataset is ~6m documents, and takes hours to load.\n# The short dataset is 1000 documents and loads quickly.\n# Change this to `True` to use the larger dataset.\nUSE_SHORT_DATASET = True\n</pre> # Configure import paths. import os import sys  sys.path.append(\"../../\")  # Initialize environment variables. from graph_rag_example_helpers.env import Environment, initialize_environment  initialize_environment(Environment.ASTRAPY)  os.environ[\"LANGCHAIN_PROJECT\"] = \"lazy-graph-rag\"  # The full dataset is ~6m documents, and takes hours to load. # The short dataset is 1000 documents and loads quickly. # Change this to `True` to use the larger dataset. USE_SHORT_DATASET = True In\u00a0[\u00a0]: Copied! <pre>import json\nfrom collections.abc import Iterator\n\nfrom langchain_core.documents import Document\nfrom langchain_graph_retriever.transformers.spacy import (\n    SpacyNERTransformer,\n)\n\n\ndef parse_document(line: bytes) -&gt; Document:\n    \"\"\"Reads one JSON line from the wikimultihop dump.\"\"\"\n    para = json.loads(line)\n\n    id = para[\"id\"]\n    title = para[\"title\"]\n\n    # Use structured information (mentioned Wikipedia IDs) as metadata.\n    mentioned_ids = [id for m in para[\"mentions\"] for m in m[\"ref_ids\"] or []]\n\n    return Document(\n        id=id,\n        page_content=\" \".join(para[\"sentences\"]),\n        metadata={\n            \"mentions\": mentioned_ids,\n            \"title\": title,\n        },\n    )\n\n\nNER_TRANSFORMER = SpacyNERTransformer(\n    limit=1000,\n    exclude_labels={\"CARDINAL\", \"MONEY\", \"QUANTITY\", \"TIME\", \"PERCENT\", \"ORDINAL\"},\n)\n\n\n# Load data in batches, using GLiNER to extract entities.\ndef prepare_batch(lines: Iterator[str]) -&gt; Iterator[Document]:\n    # Parse documents from the batch of lines.\n    docs = [parse_document(line) for line in lines]\n\n    docs = NER_TRANSFORMER.transform_documents(docs)\n\n    return docs\n</pre> import json from collections.abc import Iterator  from langchain_core.documents import Document from langchain_graph_retriever.transformers.spacy import (     SpacyNERTransformer, )   def parse_document(line: bytes) -&gt; Document:     \"\"\"Reads one JSON line from the wikimultihop dump.\"\"\"     para = json.loads(line)      id = para[\"id\"]     title = para[\"title\"]      # Use structured information (mentioned Wikipedia IDs) as metadata.     mentioned_ids = [id for m in para[\"mentions\"] for m in m[\"ref_ids\"] or []]      return Document(         id=id,         page_content=\" \".join(para[\"sentences\"]),         metadata={             \"mentions\": mentioned_ids,             \"title\": title,         },     )   NER_TRANSFORMER = SpacyNERTransformer(     limit=1000,     exclude_labels={\"CARDINAL\", \"MONEY\", \"QUANTITY\", \"TIME\", \"PERCENT\", \"ORDINAL\"}, )   # Load data in batches, using GLiNER to extract entities. def prepare_batch(lines: Iterator[str]) -&gt; Iterator[Document]:     # Parse documents from the batch of lines.     docs = [parse_document(line) for line in lines]      docs = NER_TRANSFORMER.transform_documents(docs)      return docs In\u00a0[\u00a0]: Copied! <pre>from langchain_astradb import AstraDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nCOLLECTION = \"lazy_graph_rag_short\" if USE_SHORT_DATASET else \"lazy_graph_rag\"\nstore = AstraDBVectorStore(\n    embedding=OpenAIEmbeddings(),\n    collection_name=COLLECTION,\n    pre_delete_collection=USE_SHORT_DATASET,\n)\n</pre> from langchain_astradb import AstraDBVectorStore from langchain_openai import OpenAIEmbeddings  COLLECTION = \"lazy_graph_rag_short\" if USE_SHORT_DATASET else \"lazy_graph_rag\" store = AstraDBVectorStore(     embedding=OpenAIEmbeddings(),     collection_name=COLLECTION,     pre_delete_collection=USE_SHORT_DATASET, ) In\u00a0[\u00a0]: hide_output Copied! <pre>import os\nimport os.path\n\nfrom graph_rag_example_helpers.datasets.wikimultihop import aload_2wikimultihop\n\n# Path to the file `para_with_hyperlink.zip`.\n# See instructions here to download from\n# [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\nPARA_WITH_HYPERLINK_ZIP = os.path.join(os.getcwd(), \"para_with_hyperlink.zip\")\n\nawait aload_2wikimultihop(\n    limit=100 if USE_SHORT_DATASET else None,\n    full_para_with_hyperlink_zip_path=PARA_WITH_HYPERLINK_ZIP,\n    store=store,\n    batch_prepare=prepare_batch,\n)\n</pre> import os import os.path  from graph_rag_example_helpers.datasets.wikimultihop import aload_2wikimultihop  # Path to the file `para_with_hyperlink.zip`. # See instructions here to download from # [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021). PARA_WITH_HYPERLINK_ZIP = os.path.join(os.getcwd(), \"para_with_hyperlink.zip\")  await aload_2wikimultihop(     limit=100 if USE_SHORT_DATASET else None,     full_para_with_hyperlink_zip_path=PARA_WITH_HYPERLINK_ZIP,     store=store,     batch_prepare=prepare_batch, ) <p>At this point, we've created a <code>VectorStore</code> with the Wikipedia articles. Each article is associated with metadata identifying other articles it mentions and entities from the article.</p> <p>As is, this is useful for performing a vector search filtered to articles mentioning a specific term or performing an entity seach on the documents. The library <code>langchain-graph-retriever</code> makes this even more useful by allowing articles to be traversed based on relationships such as articles mentioned in the current article (or mentioning the current article) or articles providing more information on the entities mentioned in the current article.</p> <p>In the next section we'll see not just how we can use the relationships in the metadata to retrieve more articles, but we'll go a step further and perform Lazy GraphRAG to extract relevant claims from both the similar and related articles and use the most relevant claims to answer the question.</p> In\u00a0[\u00a0]: Copied! <pre>from collections.abc import Iterable\nfrom operator import itemgetter\nfrom typing import TypedDict\n\nfrom langchain_core.documents import Document\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnableLambda, RunnableParallel, chain\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel, Field\n\n\nclass Claim(BaseModel):\n    \"\"\"Representation of an individual claim from a source document(s).\"\"\"\n\n    claim: str = Field(description=\"The claim from the original document(s).\")\n    source_id: str = Field(description=\"Document ID containing the claim.\")\n\n\nclass Claims(BaseModel):\n    \"\"\"Claims extracted from a set of source document(s).\"\"\"\n\n    claims: list[Claim] = Field(description=\"The extracted claims.\")\n\n\nMODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\nCLAIMS_MODEL = MODEL.with_structured_output(Claims)\n\nCLAIMS_PROMPT = ChatPromptTemplate.from_template(\"\"\"\nExtract claims from the following related documents.\n\nOnly return claims appearing within the specified documents.\nIf no documents are provided, do not make up claims or documents.\n\nClaims (and scores) should be relevant to the question.\nDon't include claims from the documents if they are not directly or indirectly\nrelevant to the question.\n\nIf none of the documents make any claims relevant to the question, return an\nempty list of claims.\n\nIf multiple documents make similar claims, include the original text of each as\nseparate claims. Score the most useful and authoritative claim higher than\nsimilar, lower-quality claims.\n\nQuestion: {question}\n\n{formatted_documents}\n\"\"\")\n\n# TODO: Few-shot examples? Possibly with a selector?\n\n\ndef format_documents_with_ids(documents: Iterable[Document]) -&gt; str:\n    formatted_docs = \"\\n\\n\".join(\n        f\"Document ID: {doc.id}\\nContent: {doc.page_content}\" for doc in documents\n    )\n    return formatted_docs\n\n\nCLAIM_CHAIN = (\n    RunnableParallel(\n        {\n            \"question\": itemgetter(\"question\"),\n            \"formatted_documents\": itemgetter(\"documents\")\n            | RunnableLambda(format_documents_with_ids),\n        }\n    )\n    | CLAIMS_PROMPT\n    | CLAIMS_MODEL\n)\n\n\nclass ClaimsChainInput(TypedDict):\n    question: str\n    communities: Iterable[Iterable[Document]]\n\n\n@chain\nasync def claims_chain(input: ClaimsChainInput) -&gt; Iterable[Claim]:\n    question = input[\"question\"]\n    communities = input[\"communities\"]\n\n    # TODO: Use openai directly so this can use the batch API for performance/cost?\n    community_claims = await CLAIM_CHAIN.abatch(\n        [{\"question\": question, \"documents\": community} for community in communities]\n    )\n    return [claim for community in community_claims for claim in community.claims]\n</pre> from collections.abc import Iterable from operator import itemgetter from typing import TypedDict  from langchain_core.documents import Document from langchain_core.prompts import ChatPromptTemplate from langchain_core.runnables import RunnableLambda, RunnableParallel, chain from langchain_openai import ChatOpenAI from pydantic import BaseModel, Field   class Claim(BaseModel):     \"\"\"Representation of an individual claim from a source document(s).\"\"\"      claim: str = Field(description=\"The claim from the original document(s).\")     source_id: str = Field(description=\"Document ID containing the claim.\")   class Claims(BaseModel):     \"\"\"Claims extracted from a set of source document(s).\"\"\"      claims: list[Claim] = Field(description=\"The extracted claims.\")   MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0) CLAIMS_MODEL = MODEL.with_structured_output(Claims)  CLAIMS_PROMPT = ChatPromptTemplate.from_template(\"\"\" Extract claims from the following related documents.  Only return claims appearing within the specified documents. If no documents are provided, do not make up claims or documents.  Claims (and scores) should be relevant to the question. Don't include claims from the documents if they are not directly or indirectly relevant to the question.  If none of the documents make any claims relevant to the question, return an empty list of claims.  If multiple documents make similar claims, include the original text of each as separate claims. Score the most useful and authoritative claim higher than similar, lower-quality claims.  Question: {question}  {formatted_documents} \"\"\")  # TODO: Few-shot examples? Possibly with a selector?   def format_documents_with_ids(documents: Iterable[Document]) -&gt; str:     formatted_docs = \"\\n\\n\".join(         f\"Document ID: {doc.id}\\nContent: {doc.page_content}\" for doc in documents     )     return formatted_docs   CLAIM_CHAIN = (     RunnableParallel(         {             \"question\": itemgetter(\"question\"),             \"formatted_documents\": itemgetter(\"documents\")             | RunnableLambda(format_documents_with_ids),         }     )     | CLAIMS_PROMPT     | CLAIMS_MODEL )   class ClaimsChainInput(TypedDict):     question: str     communities: Iterable[Iterable[Document]]   @chain async def claims_chain(input: ClaimsChainInput) -&gt; Iterable[Claim]:     question = input[\"question\"]     communities = input[\"communities\"]      # TODO: Use openai directly so this can use the batch API for performance/cost?     community_claims = await CLAIM_CHAIN.abatch(         [{\"question\": question, \"documents\": community} for community in communities]     )     return [claim for community in community_claims for claim in community.claims] In\u00a0[\u00a0]: Copied! <pre>import math\n\nfrom langchain_core.runnables import chain\n\nRANK_PROMPT = ChatPromptTemplate.from_template(\"\"\"\nRank the relevance of the following claim to the question.\nOutput \"True\" if the claim is relevant and \"False\" if it is not.\nOnly output True or False.\n\nQuestion: Where is Seattle?\n\nClaim: Seattle is in Washington State.\n\nRelevant: True\n\nQuestion: Where is LA?\n\nClaim: New York City is in New York State.\n\nRelevant: False\n\nQuestion: {question}\n\nClaim: {claim}\n\nRelevant:\n\"\"\")\n\n\ndef compute_rank(msg):\n    logprob = msg.response_metadata[\"logprobs\"][\"content\"][0]\n    prob = math.exp(logprob[\"logprob\"])\n    token = logprob[\"token\"]\n    if token == \"True\":\n        return prob\n    elif token == \"False\":\n        return 1.0 - prob\n    else:\n        raise ValueError(f\"Unexpected logprob: {logprob}\")\n\n\nRANK_CHAIN = RANK_PROMPT | MODEL.bind(logprobs=True) | RunnableLambda(compute_rank)\n\n\nclass RankChainInput(TypedDict):\n    question: str\n    claims: Iterable[Claim]\n\n\n@chain\nasync def rank_chain(input: RankChainInput) -&gt; Iterable[Claim]:\n    # TODO: Use openai directly so this can use the batch API for performance/cost?\n    claims = input[\"claims\"]\n    ranks = await RANK_CHAIN.abatch(\n        [{\"question\": input[\"question\"], \"claim\": claim} for claim in claims]\n    )\n    rank_claims = sorted(\n        zip(ranks, claims, strict=True), key=lambda rank_claim: rank_claim[0]\n    )\n\n    return [claim for _, claim in rank_claims]\n</pre> import math  from langchain_core.runnables import chain  RANK_PROMPT = ChatPromptTemplate.from_template(\"\"\" Rank the relevance of the following claim to the question. Output \"True\" if the claim is relevant and \"False\" if it is not. Only output True or False.  Question: Where is Seattle?  Claim: Seattle is in Washington State.  Relevant: True  Question: Where is LA?  Claim: New York City is in New York State.  Relevant: False  Question: {question}  Claim: {claim}  Relevant: \"\"\")   def compute_rank(msg):     logprob = msg.response_metadata[\"logprobs\"][\"content\"][0]     prob = math.exp(logprob[\"logprob\"])     token = logprob[\"token\"]     if token == \"True\":         return prob     elif token == \"False\":         return 1.0 - prob     else:         raise ValueError(f\"Unexpected logprob: {logprob}\")   RANK_CHAIN = RANK_PROMPT | MODEL.bind(logprobs=True) | RunnableLambda(compute_rank)   class RankChainInput(TypedDict):     question: str     claims: Iterable[Claim]   @chain async def rank_chain(input: RankChainInput) -&gt; Iterable[Claim]:     # TODO: Use openai directly so this can use the batch API for performance/cost?     claims = input[\"claims\"]     ranks = await RANK_CHAIN.abatch(         [{\"question\": input[\"question\"], \"claim\": claim} for claim in claims]     )     rank_claims = sorted(         zip(ranks, claims, strict=True), key=lambda rank_claim: rank_claim[0]     )      return [claim for _, claim in rank_claims] <p>We could extend this by using an MMR-like strategy for selecting claims. Specifically, we could combine the relevance of the claim to the question and the diversity compared to already selected claims to select the best variety of claims.</p> <p>Finally, we produce a chain that puts everything together. Given a <code>GraphRetriever</code> it retrieves documents, creates communities using edges amongst the retrieved documents, extracts claims from those communities, ranks and selects the best claims, and then answers the question using those claims.</p> In\u00a0[\u00a0]: Copied! <pre>from typing import Any\n\nfrom graph_retriever.edges import EdgeSpec, MetadataEdgeFunction\nfrom langchain_core.language_models import BaseLanguageModel\nfrom langchain_core.runnables import chain\nfrom langchain_graph_retriever import GraphRetriever\nfrom langchain_graph_retriever.document_graph import create_graph, group_by_community\n\n\n@chain\nasync def lazy_graph_rag(\n    question: str,\n    *,\n    retriever: GraphRetriever,\n    model: BaseLanguageModel,\n    edges: Iterable[EdgeSpec] | MetadataEdgeFunction | None = None,\n    max_tokens: int = 1000,\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Retrieve claims relating to the question using LazyGraphRAG.\n\n    Returns the top claims up to the given `max_tokens` as a markdown list.\n\n    \"\"\"\n    edges = edges or retriever.edges\n    if edges is None:\n        raise ValueError(\"Must specify 'edges' in invocation or retriever\")\n\n    # 1. Retrieve documents using the (traversing) retriever.\n    documents = await retriever.ainvoke(question, edges=edges, **kwargs)\n\n    # 2. Create a graph and extract communities.\n    document_graph = create_graph(documents, edges=edges)\n    communities = group_by_community(document_graph)\n\n    # 3. Extract claims from the communities.\n    claims = await claims_chain.ainvoke(\n        {\"question\": question, \"communities\": communities}\n    )\n\n    # 4. Rank the claims and select claims up to the given token limit.\n    result_claims = []\n    tokens = 0\n\n    for claim in await rank_chain.ainvoke({\"question\": question, \"claims\": claims}):\n        claim_str = f\"- {claim.claim} (Source: {claim.source_id})\"\n\n        tokens += model.get_num_tokens(claim_str)\n        if tokens &gt; max_tokens:\n            break\n        result_claims.append(claim_str)\n\n    return \"\\n\".join(result_claims)\n</pre> from typing import Any  from graph_retriever.edges import EdgeSpec, MetadataEdgeFunction from langchain_core.language_models import BaseLanguageModel from langchain_core.runnables import chain from langchain_graph_retriever import GraphRetriever from langchain_graph_retriever.document_graph import create_graph, group_by_community   @chain async def lazy_graph_rag(     question: str,     *,     retriever: GraphRetriever,     model: BaseLanguageModel,     edges: Iterable[EdgeSpec] | MetadataEdgeFunction | None = None,     max_tokens: int = 1000,     **kwargs: Any, ) -&gt; str:     \"\"\"Retrieve claims relating to the question using LazyGraphRAG.      Returns the top claims up to the given `max_tokens` as a markdown list.      \"\"\"     edges = edges or retriever.edges     if edges is None:         raise ValueError(\"Must specify 'edges' in invocation or retriever\")      # 1. Retrieve documents using the (traversing) retriever.     documents = await retriever.ainvoke(question, edges=edges, **kwargs)      # 2. Create a graph and extract communities.     document_graph = create_graph(documents, edges=edges)     communities = group_by_community(document_graph)      # 3. Extract claims from the communities.     claims = await claims_chain.ainvoke(         {\"question\": question, \"communities\": communities}     )      # 4. Rank the claims and select claims up to the given token limit.     result_claims = []     tokens = 0      for claim in await rank_chain.ainvoke({\"question\": question, \"claims\": claims}):         claim_str = f\"- {claim.claim} (Source: {claim.source_id})\"          tokens += model.get_num_tokens(claim_str)         if tokens &gt; max_tokens:             break         result_claims.append(claim_str)      return \"\\n\".join(result_claims) In\u00a0[\u00a0]: Copied! <pre>from langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_graph_retriever import GraphRetriever\n\nRETRIEVER = GraphRetriever(\n    store=store,\n    edges=[(\"mentions\", \"$id\"), (\"entities\", \"entities\")],\n    k=100,\n    start_k=30,\n    adjacent_k=20,\n    max_depth=3,\n)\n\nANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\nAnswer the question based on the supporting claims.\n\nOnly use information from the claims. Do not guess or make up any information.\n\nWhere possible, reference and quote the supporting claims.\n\nQuestion: {question}\n\nClaims:\n{claims}\n\"\"\")\n\nLAZY_GRAPH_RAG_CHAIN = (\n    {\n        \"question\": RunnablePassthrough(),\n        \"claims\": RunnablePassthrough()\n        | lazy_graph_rag.bind(\n            retriever=RETRIEVER,\n            model=MODEL,\n            max_tokens=1000,\n        ),\n    }\n    | ANSWER_PROMPT\n    | MODEL\n)\n</pre> from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnablePassthrough from langchain_graph_retriever import GraphRetriever  RETRIEVER = GraphRetriever(     store=store,     edges=[(\"mentions\", \"$id\"), (\"entities\", \"entities\")],     k=100,     start_k=30,     adjacent_k=20,     max_depth=3, )  ANSWER_PROMPT = PromptTemplate.from_template(\"\"\" Answer the question based on the supporting claims.  Only use information from the claims. Do not guess or make up any information.  Where possible, reference and quote the supporting claims.  Question: {question}  Claims: {claims} \"\"\")  LAZY_GRAPH_RAG_CHAIN = (     {         \"question\": RunnablePassthrough(),         \"claims\": RunnablePassthrough()         | lazy_graph_rag.bind(             retriever=RETRIEVER,             model=MODEL,             max_tokens=1000,         ),     }     | ANSWER_PROMPT     | MODEL ) In\u00a0[\u00a0]: keep_output Copied! <pre>QUESTION = \"Why are Bermudan sloop ships widely prized compared to other ships?\"\nresult = await LAZY_GRAPH_RAG_CHAIN.ainvoke(QUESTION)\nresult.content\n</pre> QUESTION = \"Why are Bermudan sloop ships widely prized compared to other ships?\" result = await LAZY_GRAPH_RAG_CHAIN.ainvoke(QUESTION) result.content Out[\u00a0]: <pre>'Bermudan sloop ships are widely prized for several reasons. Firstly, they feature the Bermuda rig, which is popular because it is easier to sail with a smaller crew or even single-handed, is cheaper due to having less hardware, and performs well when sailing into the wind (Source: 48520). Additionally, Bermuda sloops were constructed using Bermuda cedar, a material valued for its durability and resistance to rot, contributing to the ships' longevity and performance (Source: 17186373). These factors combined make Bermudan sloops highly valued compared to other ships.'</pre> <p>For comparison, below are the results to the same question using a basic RAG pattern with just vector similarity.</p> In\u00a0[\u00a0]: keep_output Copied! <pre>from langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\nVECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\nAnswer the question based on the provided documents.\n\nOnly use information from the documents. Do not guess or make up any information.\n\nQuestion: {question}\n\nDocuments:\n{documents}\n\"\"\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nVECTOR_CHAIN = (\n    {\n        \"question\": RunnablePassthrough(),\n        \"documents\": (store.as_retriever() | format_docs),\n    }\n    | VECTOR_ANSWER_PROMPT\n    | MODEL\n)\n\nresult = VECTOR_CHAIN.invoke(QUESTION)\nresult.content\n</pre> from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnablePassthrough  VECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\" Answer the question based on the provided documents.  Only use information from the documents. Do not guess or make up any information.  Question: {question}  Documents: {documents} \"\"\")   def format_docs(docs):     return \"\\n\\n\".join(doc.page_content for doc in docs)   VECTOR_CHAIN = (     {         \"question\": RunnablePassthrough(),         \"documents\": (store.as_retriever() | format_docs),     }     | VECTOR_ANSWER_PROMPT     | MODEL )  result = VECTOR_CHAIN.invoke(QUESTION) result.content Out[\u00a0]: <pre>'The documents do not provide specific reasons why Bermudan sloop ships are widely prized compared to other ships. They describe the development and characteristics of the Bermuda sloop, such as its fore-and-aft rigged single-masted design and the use of the Bermuda rig with triangular sails, but do not explicitly state why these ships are particularly valued over others.'</pre> <p>The LazyGraphRAG chain is great when a question needs to consider a large amount of relevant information in order to produce a thorough answer.</p>"},{"location":"examples/lazy-graph-rag/#lazygraphrag-in-langchain","title":"LazyGraphRAG in LangChain\u00b6","text":""},{"location":"examples/lazy-graph-rag/#introduction","title":"Introduction\u00b6","text":"<p>In LazyGraphRAG, Microsoft demonstrates significant cost and performance benefits to delaying the construction of a knowledge graph. This is largely because not all documents need to be analyzed. However, it is also benefical that documents by the time documents are analyzed the question is already known, allowing irrelevant information to be ignored.</p> <p>We've noticed similar cost benefits to building a document graph linking content based on simple properties such as extracted keywords compared to building a complete knowledge graph. For the Wikipedia dataset used in this notebook, we estimated it would have taken $70k to build a knowledege graph using the example from LangChain, while the document graph was basically free.</p> <p>In this notebook we demonstrate how to populate a document graph with Wikipedia articles linked based on mentions in the articles and extracted keywords. Keyword extraction uses a local KeyBERT model, making it fast and cost-effective to construct these graphs. We'll then show how to build out a chain which does the steps of Lazy GraphRAG -- retrieving articles, extracting claims from each community, ranking and selecting the top claims, and generating an answer based on those claims.</p>"},{"location":"examples/lazy-graph-rag/#environment-setup","title":"Environment Setup\u00b6","text":"<p>The following block will configure the environment from the Colab Secrets. To run it, you should have the following Colab Secrets defined and accessible to this notebook:</p> <ul> <li><code>OPENAI_API_KEY</code>: The OpenAI key.</li> <li><code>ASTRA_DB_API_ENDPOINT</code>: The Astra DB API endpoint.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: The Astra DB Application token.</li> <li><code>LANGCHAIN_API_KEY</code>: Optional. If defined, will enable LangSmith tracing.</li> <li><code>ASTRA_DB_KEYSPACE</code>: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default.</li> </ul>"},{"location":"examples/lazy-graph-rag/#part-1-loading-data","title":"Part 1: Loading Data\u00b6","text":"<p>First, we'll demonstrate how to load Wikipedia data into an <code>AstraDBVectorStore</code>, using the mentioned articles and keywords as metadata fields. In this section, we're not actually doing anything special for the graph -- we're just populating the metadata with fields that useful describe our content.</p>"},{"location":"examples/lazy-graph-rag/#create-documents-from-wikipedia-articles","title":"Create Documents from Wikipedia Articles\u00b6","text":"<p>The first thing we need to do is create the <code>LangChain</code> <code>Document</code>s we'll import.</p> <p>To do this, we write some code to convert lines from a JSON file downloaded from 2wikimultihop and create a <code>Document</code>. We populate the <code>id</code> and <code>metadata[\"mentions\"]</code> from information in this file.</p> <p>Then, we run those documents through the <code>SpacyNERTransformer</code> to populate <code>metadata[\"entities\"]</code> with entities named in the article.</p>"},{"location":"examples/lazy-graph-rag/#create-the-astradbvectorstore","title":"Create the AstraDBVectorStore\u00b6","text":"<p>Next, we create the Vector Store we're going to load these documents into. In our case, we use DataStax Astra DB with Open AI embeddings.</p>"},{"location":"examples/lazy-graph-rag/#loading-data-into-the-store","title":"Loading Data into the Store\u00b6","text":"<p>Next, we perform the actual loading. This takes a while, so we use a helper utility to persist which batches have been written so we can resume if there are any failures.</p> <p>On OS X, it is useful to run <code>caffeinate -dis</code> in a shell to prevent the machine from going to sleep and seems to reduce errors.</p>"},{"location":"examples/lazy-graph-rag/#part-2-lazy-graph-rag-via-hierarchical-summarization","title":"Part 2: Lazy Graph RAG via Hierarchical Summarization\u00b6","text":"<p>As we've noted before, eagerly building a knowledge graph is prohibitively expensive. Microsoft seems to agree, and recently introduced LazyGraphRAG, which enables GraphRAG to be performed late -- after a query is retrieved.</p> <p>We implement the LazyGraphRAG technique using the traversing retrievers as follows:</p> <ol> <li>Retrieve a good number of nodes using a traversing retrieval.</li> <li>Identify communities in the retrieved sub-graph.</li> <li>Extract claims from each community relevant to the query using an LLM.</li> <li>Rank each of the claims based on the relevance to the question and select the top claims.</li> <li>Generate an answer to the question based on the extracted claims.</li> </ol>"},{"location":"examples/lazy-graph-rag/#langchain-for-extracting-claims","title":"LangChain for Extracting Claims\u00b6","text":"<p>The first thing we do is create a chain that produces the claims. Given an input containing the question and the retrieved communities, it applies an LLM in parallel extracting claims from each community.</p> <p>A claim is just a string representing the statement and the <code>source_id</code> of the document. We request structured output so we get a list of claims.</p>"},{"location":"examples/lazy-graph-rag/#langchain-for-ranking-claims","title":"LangChain for Ranking Claims\u00b6","text":"<p>The next chain is used for ranking the claims so we can select the most relevant to the question.</p> <p>This is based on ideas from RankRAG. Specifically, the prompt is constructed so that the next token should be <code>True</code> if the content is relevant and <code>False</code> if not. The probability of the token is used to determine the relevance -- <code>True</code> with a higher probability is more relevant than <code>True</code> with a lesser probability.</p>"},{"location":"examples/lazy-graph-rag/#lazygraphrag-in-langchain","title":"LazyGraphRAG in LangChain\u00b6","text":""},{"location":"examples/lazy-graph-rag/#using-lazy-graphrag-in-langchain","title":"Using Lazy GraphRAG in LangChain\u00b6","text":"<p>Finally, we sue the Lazy GraphRAG chain we created on the store we populated earlier.</p>"},{"location":"examples/lazy-graph-rag/#conclusion","title":"Conclusion\u00b6","text":"<p>This post demonstrated how easy it is to implement Lazy GraphRAG on top of a document graph.</p> <p>It used <code>langchain-graph-retriever</code> from the graph-rag project to implement the document graph and graph-based retrieval on top of an existing LangChain <code>VectorStore</code>. This means you can focus on populating and using your <code>VectorStore</code> with useful metadata and add graph-based retrieval and even Lazy GraphRAG when you need it.</p> <p>Any LangChain <code>VectorStore</code> can be used with Lazy GraphRAG without needing to change or re-ingest the stored documents. Knowledge Graphs and GraphRAG shouldn't be hard or scary. Start simple and easily overlay edges when you need them.</p> <p>Graph retrievers and LazyGraph RAG work well with agents. You can allow the agent to retrieve differently depending on the question -- doing a vector only search for simple questions, traversing to mentioned articles for a deeper question or traversing to articles that cite this to see if there is newer information available. We'll show how to combine these techniques with agents in a future post. Until then, give <code>langchain-graph-retriever</code> a try and let us know how it goes!</p>"},{"location":"examples/movie-reviews-graph-rag/","title":"Graph RAG on Movie Reviews from Rotten Tomatoes","text":"In\u00a0[\u00a0]: Copied! <pre># install the required packages\n%pip install \\\n        dotenv \\\n        pandas \\\n        langchain_openai \\\n        langchain-graph-retriever \\\n        langchain-astradb\n</pre> # install the required packages %pip install \\         dotenv \\         pandas \\         langchain_openai \\         langchain-graph-retriever \\         langchain-astradb In\u00a0[\u00a0]: Copied! <pre>from dotenv import load_dotenv\n\n# load environment variables from the .env file\nload_dotenv()\n</pre> from dotenv import load_dotenv  # load environment variables from the .env file load_dotenv() In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nfrom io import StringIO\n\nreviews_data_string = \"\"\"\nid,reviewId,creationDate,criticName,isTopCritic,originalScore,reviewState,publicatioName,reviewText,scoreSentiment,reviewUrl\naddams_family,2644238,2019-11-10,James Kendrick,False,3/4,fresh,Q Network Film Desk,captures the family's droll humor with just the right mixture of morbidity and genuine care,POSITIVE,http://www.qnetwork.com/review/4178\naddams_family,2509777,2018-09-12,John Ferguson,False,4/5,fresh,Radio Times,A witty family comedy that has enough sly humour to keep adults chuckling throughout.,POSITIVE,https://www.radiotimes.com/film/fj8hmt/the-addams-family/\naddams_family,26216,2000-01-01,Rita Kempley,True,,fresh,Washington Post,\"More than merely a sequel of the TV series, the film is a compendium of paterfamilias Charles Addams's macabre drawings, a resurrection of the cartoonist's body of work. For family friends, it would seem a viewing is de rigueur mortis.\",POSITIVE,http://www.washingtonpost.com/wp-srv/style/longterm/movies/videos/theaddamsfamilypg13kempley_a0a280.htm\nthe_addams_family_2019,2699537,2020-06-27,Damond Fudge,False,,fresh,\"KCCI (Des Moines, IA)\",\"As was proven by the 1992-93 cartoon series, animation is the perfect medium for this creepy, kooky family, allowing more outlandish escapades\",POSITIVE,https://www.kcci.com/article/movie-review-the-addams-family/29443537\nthe_addams_family_2019,2662133,2020-01-21,Ryan Silberstein,False,,fresh,Cinema76,\"This origin casts the Addams family as an immigrant story, and the film leans so hard into the theme of accepting those different from us and valuing diversity over conformity,\",POSITIVE,https://www.cinema76.com/home/2019/10/11/the-addams-family-is-a-fun-update-to-an-iconic-american-clan\nthe_addams_family_2019,2661356,2020-01-17,Jennifer Heaton,False,5.5/10,rotten,Alternative Lens,...The film's simplistic and episodic plot put a major dampener on what could have been a welcome breath of fresh air for family animation.,NEGATIVE,https://altfilmlens.wordpress.com/2020/01/17/my-end-of-year-surplus-review-extravaganza-thing-2019/\nthe_addams_family_2,102657551,2022-02-16,Mat Brunet,False,4/10,rotten,AniMat's Review (YouTube),The Addams Family 2 repeats what the first movie accomplished by taking the popular family and turning them into one of the most boringly generic kids films in recent years.,NEGATIVE,https://www.youtube.com/watch?v=G9deslxPDwI\nthe_addams_family_2,2832101,2021-10-15,Sandie Angulo Chen,False,3/5,fresh,Common Sense Media,This serviceable animated sequel focuses on Wednesday's feelings of alienation and benefits from the family's kid-friendly jokes and road trip adventures.,POSITIVE,https://www.commonsensemedia.org/movie-reviews/the-addams-family-2\nthe_addams_family_2,2829939,2021-10-08,Emily Breen,False,2/5,rotten,HeyUGuys,\"Lifeless and flat, doing a disservice to the family name and the talent who voice them. WIthout glamour, wit or a hint of a soul. A void. Avoid.\",NEGATIVE,https://www.heyuguys.com/the-addams-family-2-review/\naddams_family_values,102735159,2022-09-22,Sean P. Means,False,3/4,fresh,Salt Lake Tribune,Addams Family Values is a ghoulishly fun time. It would have been a real howl if the producers weren't too scared to go out on a limb in this twisted family tree.,POSITIVE,https://www.newspapers.com/clip/110004014/addams-family-values/\naddams_family_values,102734540,2022-09-21,Jami Bernard,True,3.5/4,fresh,New York Daily News,\"The title is apt. Using those morbidly sensual cartoon characters as pawns, the new movie Addams Family Values launches a witty assault on those with fixed ideas about what constitutes a loving family. \",POSITIVE,https://www.newspapers.com/clip/109964753/addams-family-values/\naddams_family_values,102734521,2022-09-21,Jeff Simon,False,3/4,fresh,Buffalo News,\"Addams Family Values has its moments -- rather a lot of them, in fact. You knew that just from the title, which is a nice way of turning Charles Addams' family of ghouls, monsters and vampires loose on Dan Quayle.\",POSITIVE,https://buffalonews.com/news/quirky-values-the-addams-family-returns-with-a-bouncing-baby/article_2aafde74-da6c-5fa7-924a-76bb1a906d9c.html\n\"\"\"\n\nmovies_data_string = \"\"\"\nid,title,audienceScore,tomatoMeter,rating,ratingContents,releaseDateTheaters,releaseDateStreaming,runtimeMinutes,genre,originalLanguage,director,writer,boxOffice,distributor,soundMix\naddams_family,The Addams Family,66,67,,,1991-11-22,2005-08-18,99,Comedy,English,Barry Sonnenfeld,\"Charles Addams,Caroline Thompson,Larry Wilson\",$111.3M,Paramount Pictures,\"Surround, Dolby SR\"\nthe_addams_family_2019,The Addams Family,69,45,PG,\"['Some Action', 'Macabre and Suggestive Humor']\",2019-10-11,2019-10-11,87,\"Kids &amp; family, Comedy, Animation\",English,\"Conrad Vernon,Greg Tiernan\",\"Matt Lieberman,Erica Rivinoja\",$673.0K,Metro-Goldwyn-Mayer,Dolby Atmos\nthe_addams_family_2,The Addams Family 2,69,28,PG,\"['Macabre and Rude Humor', 'Language', 'Violence']\",2021-10-01,2021-10-01,93,\"Kids &amp; family, Comedy, Adventure, Animation\",English,\"Greg Tiernan,Conrad Vernon\",\"Dan Hernandez,Benji Samit,Ben Queen,Susanna Fogel\",$56.5M,Metro-Goldwyn-Mayer,\naddams_family_reunion,Addams Family Reunion,33,,,,,,92,Comedy,English,Dave Payne,,,,\naddams_family_values,Addams Family Values,63,75,,,1993-11-19,2003-08-05,93,Comedy,English,Barry Sonnenfeld,Paul Rudnick,$45.7M,\"Argentina Video Home, Paramount Pictures\",\"Surround, Dolby Digital\"\n\"\"\"\n\nreviews_all = pd.read_csv(StringIO(reviews_data_string))\nmovies_all = pd.read_csv(StringIO(movies_data_string))\n</pre> import pandas as pd from io import StringIO  reviews_data_string = \"\"\" id,reviewId,creationDate,criticName,isTopCritic,originalScore,reviewState,publicatioName,reviewText,scoreSentiment,reviewUrl addams_family,2644238,2019-11-10,James Kendrick,False,3/4,fresh,Q Network Film Desk,captures the family's droll humor with just the right mixture of morbidity and genuine care,POSITIVE,http://www.qnetwork.com/review/4178 addams_family,2509777,2018-09-12,John Ferguson,False,4/5,fresh,Radio Times,A witty family comedy that has enough sly humour to keep adults chuckling throughout.,POSITIVE,https://www.radiotimes.com/film/fj8hmt/the-addams-family/ addams_family,26216,2000-01-01,Rita Kempley,True,,fresh,Washington Post,\"More than merely a sequel of the TV series, the film is a compendium of paterfamilias Charles Addams's macabre drawings, a resurrection of the cartoonist's body of work. For family friends, it would seem a viewing is de rigueur mortis.\",POSITIVE,http://www.washingtonpost.com/wp-srv/style/longterm/movies/videos/theaddamsfamilypg13kempley_a0a280.htm the_addams_family_2019,2699537,2020-06-27,Damond Fudge,False,,fresh,\"KCCI (Des Moines, IA)\",\"As was proven by the 1992-93 cartoon series, animation is the perfect medium for this creepy, kooky family, allowing more outlandish escapades\",POSITIVE,https://www.kcci.com/article/movie-review-the-addams-family/29443537 the_addams_family_2019,2662133,2020-01-21,Ryan Silberstein,False,,fresh,Cinema76,\"This origin casts the Addams family as an immigrant story, and the film leans so hard into the theme of accepting those different from us and valuing diversity over conformity,\",POSITIVE,https://www.cinema76.com/home/2019/10/11/the-addams-family-is-a-fun-update-to-an-iconic-american-clan the_addams_family_2019,2661356,2020-01-17,Jennifer Heaton,False,5.5/10,rotten,Alternative Lens,...The film's simplistic and episodic plot put a major dampener on what could have been a welcome breath of fresh air for family animation.,NEGATIVE,https://altfilmlens.wordpress.com/2020/01/17/my-end-of-year-surplus-review-extravaganza-thing-2019/ the_addams_family_2,102657551,2022-02-16,Mat Brunet,False,4/10,rotten,AniMat's Review (YouTube),The Addams Family 2 repeats what the first movie accomplished by taking the popular family and turning them into one of the most boringly generic kids films in recent years.,NEGATIVE,https://www.youtube.com/watch?v=G9deslxPDwI the_addams_family_2,2832101,2021-10-15,Sandie Angulo Chen,False,3/5,fresh,Common Sense Media,This serviceable animated sequel focuses on Wednesday's feelings of alienation and benefits from the family's kid-friendly jokes and road trip adventures.,POSITIVE,https://www.commonsensemedia.org/movie-reviews/the-addams-family-2 the_addams_family_2,2829939,2021-10-08,Emily Breen,False,2/5,rotten,HeyUGuys,\"Lifeless and flat, doing a disservice to the family name and the talent who voice them. WIthout glamour, wit or a hint of a soul. A void. Avoid.\",NEGATIVE,https://www.heyuguys.com/the-addams-family-2-review/ addams_family_values,102735159,2022-09-22,Sean P. Means,False,3/4,fresh,Salt Lake Tribune,Addams Family Values is a ghoulishly fun time. It would have been a real howl if the producers weren't too scared to go out on a limb in this twisted family tree.,POSITIVE,https://www.newspapers.com/clip/110004014/addams-family-values/ addams_family_values,102734540,2022-09-21,Jami Bernard,True,3.5/4,fresh,New York Daily News,\"The title is apt. Using those morbidly sensual cartoon characters as pawns, the new movie Addams Family Values launches a witty assault on those with fixed ideas about what constitutes a loving family. \",POSITIVE,https://www.newspapers.com/clip/109964753/addams-family-values/ addams_family_values,102734521,2022-09-21,Jeff Simon,False,3/4,fresh,Buffalo News,\"Addams Family Values has its moments -- rather a lot of them, in fact. You knew that just from the title, which is a nice way of turning Charles Addams' family of ghouls, monsters and vampires loose on Dan Quayle.\",POSITIVE,https://buffalonews.com/news/quirky-values-the-addams-family-returns-with-a-bouncing-baby/article_2aafde74-da6c-5fa7-924a-76bb1a906d9c.html \"\"\"  movies_data_string = \"\"\" id,title,audienceScore,tomatoMeter,rating,ratingContents,releaseDateTheaters,releaseDateStreaming,runtimeMinutes,genre,originalLanguage,director,writer,boxOffice,distributor,soundMix addams_family,The Addams Family,66,67,,,1991-11-22,2005-08-18,99,Comedy,English,Barry Sonnenfeld,\"Charles Addams,Caroline Thompson,Larry Wilson\",$111.3M,Paramount Pictures,\"Surround, Dolby SR\" the_addams_family_2019,The Addams Family,69,45,PG,\"['Some Action', 'Macabre and Suggestive Humor']\",2019-10-11,2019-10-11,87,\"Kids &amp; family, Comedy, Animation\",English,\"Conrad Vernon,Greg Tiernan\",\"Matt Lieberman,Erica Rivinoja\",$673.0K,Metro-Goldwyn-Mayer,Dolby Atmos the_addams_family_2,The Addams Family 2,69,28,PG,\"['Macabre and Rude Humor', 'Language', 'Violence']\",2021-10-01,2021-10-01,93,\"Kids &amp; family, Comedy, Adventure, Animation\",English,\"Greg Tiernan,Conrad Vernon\",\"Dan Hernandez,Benji Samit,Ben Queen,Susanna Fogel\",$56.5M,Metro-Goldwyn-Mayer, addams_family_reunion,Addams Family Reunion,33,,,,,,92,Comedy,English,Dave Payne,,,, addams_family_values,Addams Family Values,63,75,,,1993-11-19,2003-08-05,93,Comedy,English,Barry Sonnenfeld,Paul Rudnick,$45.7M,\"Argentina Video Home, Paramount Pictures\",\"Surround, Dolby Digital\" \"\"\"  reviews_all = pd.read_csv(StringIO(reviews_data_string)) movies_all = pd.read_csv(StringIO(movies_data_string)) In\u00a0[\u00a0]: Copied! <pre># rename the id columns to more informative and useful names\nreviews_data = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"})\nmovies_data = movies_all.rename(columns={\"id\": \"movie_id\"})\n</pre> # rename the id columns to more informative and useful names reviews_data = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"}) movies_data = movies_all.rename(columns={\"id\": \"movie_id\"}) In\u00a0[\u00a0]: Copied! <pre>from langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\n# create the vector store\nvectorstore = InMemoryVectorStore(OpenAIEmbeddings())\n</pre> from langchain_core.vectorstores import InMemoryVectorStore from langchain_openai import OpenAIEmbeddings  # create the vector store vectorstore = InMemoryVectorStore(OpenAIEmbeddings()) In\u00a0[\u00a0]: skip-execution Copied! <pre>import pandas as pd\n\n# Change this to the path where you stored the data files. See the top of this\n# notebook for links and information about the datasets.\nDATA_PATH = \"../../../../datasets/\"\n\n# read the datasets from CSV files\nreviews_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movie_reviews.csv\")\nmovies_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movies.csv\")\n\nprint(\"Data is loaded from CSV.\")\n</pre> import pandas as pd  # Change this to the path where you stored the data files. See the top of this # notebook for links and information about the datasets. DATA_PATH = \"../../../../datasets/\"  # read the datasets from CSV files reviews_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movie_reviews.csv\") movies_all = pd.read_csv(DATA_PATH + \"rotten_tomatoes_movies.csv\")  print(\"Data is loaded from CSV.\") In\u00a0[\u00a0]: skip-execution Copied! <pre># rename the id columns to more informative and useful names\nreviews_all = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"})\nmovies_all = movies_all.rename(columns={\"id\": \"movie_id\"})\n</pre> # rename the id columns to more informative and useful names reviews_all = reviews_all.rename(columns={\"id\": \"reviewed_movie_id\"}) movies_all = movies_all.rename(columns={\"id\": \"movie_id\"}) <p>Next, let's have a look at the movies that have the most reviews, and take a subset of the reviews to save time in this demo.</p> In\u00a0[\u00a0]: skip-execution Copied! <pre># Here, we limit our dataset to the movies with the most reviews. This is simply\n# to save data processing and loading time while testing things in this notebook.\nN_TOP_MOVIES = 10\nmost_reviewed_movies = reviews_all[\"reviewed_movie_id\"].value_counts()[:N_TOP_MOVIES]\n\nmost_reviewed_movies\n</pre> # Here, we limit our dataset to the movies with the most reviews. This is simply # to save data processing and loading time while testing things in this notebook. N_TOP_MOVIES = 10 most_reviewed_movies = reviews_all[\"reviewed_movie_id\"].value_counts()[:N_TOP_MOVIES]  most_reviewed_movies In\u00a0[\u00a0]: skip-execution Copied! <pre># subset the data to only reviews and movies corresponding to the most reviewed movies\nreviews_data = reviews_all[\n    reviews_all[\"reviewed_movie_id\"].isin(most_reviewed_movies.index)\n]\nmovies_data = movies_all[movies_all[\"movie_id\"].isin(most_reviewed_movies.index)]\n</pre> # subset the data to only reviews and movies corresponding to the most reviewed movies reviews_data = reviews_all[     reviews_all[\"reviewed_movie_id\"].isin(most_reviewed_movies.index) ] movies_data = movies_all[movies_all[\"movie_id\"].isin(most_reviewed_movies.index)] In\u00a0[\u00a0]: skip-execution Copied! <pre>from langchain_astradb import AstraDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nCOLLECTION = \"movie_reviews_rotten_tomatoes\"\nvectorstore = AstraDBVectorStore(\n    embedding=OpenAIEmbeddings(),\n    collection_name=COLLECTION,\n    pre_delete_collection=True,\n)\n</pre> from langchain_astradb import AstraDBVectorStore from langchain_openai import OpenAIEmbeddings  COLLECTION = \"movie_reviews_rotten_tomatoes\" vectorstore = AstraDBVectorStore(     embedding=OpenAIEmbeddings(),     collection_name=COLLECTION,     pre_delete_collection=True, ) In\u00a0[\u00a0]: Copied! <pre>from langchain_core.documents import Document\n\n# Convert each movie review into a LangChain document\ndocuments = []\n# convert each movie into a LangChain document\nfor index, row in movies_data.iterrows():\n    content = str(row[\"title\"])\n    metadata = row.fillna(\"\").astype(str).to_dict()\n    metadata[\"doc_type\"] = \"movie_info\"\n    document = Document(page_content=content, metadata=metadata)\n    documents.append(document)\n\n\nfor index, row in reviews_data.iterrows():\n    content = str(row[\"reviewText\"])\n    metadata = row.drop(\"reviewText\").fillna(\"\").astype(str).to_dict()\n    metadata[\"doc_type\"] = \"movie_review\"\n    document = Document(page_content=content, metadata=metadata)\n    documents.append(document)\n\n\n# check the total number of documents\nprint(\"There are\", len(documents), \"total Documents\")\n</pre> from langchain_core.documents import Document  # Convert each movie review into a LangChain document documents = [] # convert each movie into a LangChain document for index, row in movies_data.iterrows():     content = str(row[\"title\"])     metadata = row.fillna(\"\").astype(str).to_dict()     metadata[\"doc_type\"] = \"movie_info\"     document = Document(page_content=content, metadata=metadata)     documents.append(document)   for index, row in reviews_data.iterrows():     content = str(row[\"reviewText\"])     metadata = row.drop(\"reviewText\").fillna(\"\").astype(str).to_dict()     metadata[\"doc_type\"] = \"movie_review\"     document = Document(page_content=content, metadata=metadata)     documents.append(document)   # check the total number of documents print(\"There are\", len(documents), \"total Documents\") In\u00a0[\u00a0]: Copied! <pre># let's inspect the structure of a document\nfrom pprint import pprint\n\npprint(documents[0].metadata)\n</pre> # let's inspect the structure of a document from pprint import pprint  pprint(documents[0].metadata) In\u00a0[\u00a0]: Copied! <pre># add documents to the store\nvectorstore.add_documents(documents)\n\n# NOTE: this may take some minutes to load many documents\n</pre> # add documents to the store vectorstore.add_documents(documents)  # NOTE: this may take some minutes to load many documents In\u00a0[\u00a0]: Copied! <pre>from graph_retriever.strategies import Eager\nfrom langchain_graph_retriever import GraphRetriever\n\nretriever = GraphRetriever(\n    store=vectorstore,\n    edges=[(\"reviewed_movie_id\", \"movie_id\")],\n    strategy=Eager(start_k=10, adjacent_k=10, select_k=100, max_depth=1),\n)\n</pre> from graph_retriever.strategies import Eager from langchain_graph_retriever import GraphRetriever  retriever = GraphRetriever(     store=vectorstore,     edges=[(\"reviewed_movie_id\", \"movie_id\")],     strategy=Eager(start_k=10, adjacent_k=10, select_k=100, max_depth=1), ) In\u00a0[\u00a0]: Copied! <pre>INITIAL_PROMPT_TEXT = \"What are some good family movies?\"\n# INITIAL_PROMPT_TEXT = \"What are some recommendations of exciting action movies?\"\n# INITIAL_PROMPT_TEXT = \"What are some classic movies with amazing cinematography?\"\n\n\n# invoke the query\nquery_results = retriever.invoke(INITIAL_PROMPT_TEXT)\n\n# print the raw retrieved results\nfor result in query_results:\n    print(result.metadata[\"doc_type\"], \": \", result.page_content)\n    print(result.metadata)\n    print()\n</pre> INITIAL_PROMPT_TEXT = \"What are some good family movies?\" # INITIAL_PROMPT_TEXT = \"What are some recommendations of exciting action movies?\" # INITIAL_PROMPT_TEXT = \"What are some classic movies with amazing cinematography?\"   # invoke the query query_results = retriever.invoke(INITIAL_PROMPT_TEXT)  # print the raw retrieved results for result in query_results:     print(result.metadata[\"doc_type\"], \": \", result.page_content)     print(result.metadata)     print() In\u00a0[\u00a0]: Copied! <pre># collect the movie info for each film retrieved\ncompiled_results = {}\nfor result in query_results:\n    if result.metadata[\"doc_type\"] == \"movie_info\":\n        movie_id = result.metadata[\"movie_id\"]\n        movie_title = result.metadata[\"title\"]\n        compiled_results[movie_id] = {\n            \"movie_id\": movie_id,\n            \"movie_title\": movie_title,\n            \"reviews\": {},\n        }\n\n# go through the results a second time, collecting the retreived reviews for\n# each of the movies\nfor result in query_results:\n    if result.metadata[\"doc_type\"] == \"movie_review\":\n        reviewed_movie_id = result.metadata[\"reviewed_movie_id\"]\n        review_id = result.metadata[\"reviewId\"]\n        review_text = result.page_content\n        compiled_results[reviewed_movie_id][\"reviews\"][review_id] = review_text\n\n\n# compile the retrieved movies and reviews into a string that we can pass to an\n# LLM in an augmented prompt\nformatted_text = \"\"\nfor movie_id, review_list in compiled_results.items():\n    formatted_text += \"\\n\\n Movie Title: \"\n    formatted_text += review_list[\"movie_title\"]\n    formatted_text += \"\\n Movie ID: \"\n    formatted_text += review_list[\"movie_id\"]\n    for review_id, review_text in review_list[\"reviews\"].items():\n        formatted_text += \"\\n Review: \"\n        formatted_text += review_text\n\n\nprint(formatted_text)\n</pre> # collect the movie info for each film retrieved compiled_results = {} for result in query_results:     if result.metadata[\"doc_type\"] == \"movie_info\":         movie_id = result.metadata[\"movie_id\"]         movie_title = result.metadata[\"title\"]         compiled_results[movie_id] = {             \"movie_id\": movie_id,             \"movie_title\": movie_title,             \"reviews\": {},         }  # go through the results a second time, collecting the retreived reviews for # each of the movies for result in query_results:     if result.metadata[\"doc_type\"] == \"movie_review\":         reviewed_movie_id = result.metadata[\"reviewed_movie_id\"]         review_id = result.metadata[\"reviewId\"]         review_text = result.page_content         compiled_results[reviewed_movie_id][\"reviews\"][review_id] = review_text   # compile the retrieved movies and reviews into a string that we can pass to an # LLM in an augmented prompt formatted_text = \"\" for movie_id, review_list in compiled_results.items():     formatted_text += \"\\n\\n Movie Title: \"     formatted_text += review_list[\"movie_title\"]     formatted_text += \"\\n Movie ID: \"     formatted_text += review_list[\"movie_id\"]     for review_id, review_text in review_list[\"reviews\"].items():         formatted_text += \"\\n Review: \"         formatted_text += review_text   print(formatted_text) In\u00a0[\u00a0]: Copied! <pre>from langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom pprint import pprint\n\nMODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n\nVECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"\n\nA list of Movie Reviews appears below. Please answer the Initial Prompt text\n(below) using only the listed Movie Reviews.\n\nPlease include all movies that might be helpful to someone looking for movie\nrecommendations.\n\n\n\nInitial Prompt:\n{initial_prompt}\n\n\nMovie Reviews:\n{movie_reviews}\n\"\"\")\n\n\nformatted_prompt = VECTOR_ANSWER_PROMPT.format(\n    initial_prompt=INITIAL_PROMPT_TEXT,\n    movie_reviews=formatted_text,\n)\n\nresult = MODEL.invoke(formatted_prompt)\n\n# print(formatted_prompt)\nprint(result.content)\n</pre> from langchain_core.prompts import PromptTemplate from langchain_openai import ChatOpenAI from pprint import pprint  MODEL = ChatOpenAI(model=\"gpt-4o\", temperature=0)  VECTOR_ANSWER_PROMPT = PromptTemplate.from_template(\"\"\"  A list of Movie Reviews appears below. Please answer the Initial Prompt text (below) using only the listed Movie Reviews.  Please include all movies that might be helpful to someone looking for movie recommendations.    Initial Prompt: {initial_prompt}   Movie Reviews: {movie_reviews} \"\"\")   formatted_prompt = VECTOR_ANSWER_PROMPT.format(     initial_prompt=INITIAL_PROMPT_TEXT,     movie_reviews=formatted_text, )  result = MODEL.invoke(formatted_prompt)  # print(formatted_prompt) print(result.content)"},{"location":"examples/movie-reviews-graph-rag/#graph-rag-on-movie-reviews-from-rotten-tomatoes","title":"Graph RAG on Movie Reviews from Rotten Tomatoes\u00b6","text":"<p>This notebook presents a basic case study for using graph RAG techniques to combine the power of retrieval-augmented generation (RAG) with knowledge graphs based on datasets that are linked to one another in a natural way.</p> <p>In particular, we use the <code>GraphRetriever</code> implementation in LangChain. For more information, see the open-source Graph RAG project on GitHub</p>"},{"location":"examples/movie-reviews-graph-rag/#the-dataset","title":"The Dataset\u00b6","text":"<p>The website Rotten Tomatoes has published a large dataset of movie reviews. The dataset includes two CSV files containing:</p> <ol> <li>the movie reviews, and</li> <li>information about the movies referenced in those reviews</li> </ol>"},{"location":"examples/movie-reviews-graph-rag/#the-challenge","title":"The Challenge\u00b6","text":"<p>In this case study, the challenge is to build a system that allows users to search movie review content using arbitrary prompts, and then return the top reviews together with the full information about the reviewed movies.</p>"},{"location":"examples/movie-reviews-graph-rag/#the-strategy","title":"The Strategy\u00b6","text":"<p>First, we build a standard RAG system for querying the movie reviews, which are embedded and stored in a vector database. It is important to note that in this step, we store the embedded reviews together with metadata that is necessary for traversing the knowledge graph and linking reviews with the movie data.</p> <p>Second, we use a <code>GraphRetriever</code> that is configured specifically to:</p> <ol> <li>retrieve relevant movie reviews via standard RAG,</li> <li>traverse the knowledge graph edges to the relevant movies, and</li> <li>return the full movie data together with each movie review.</li> </ol> <p>In this implementation, the metadata is the basis for the knowledge graph, and the mechanics of graph traversal is specified as part of the <code>GraphRetriever</code>. In this way, a change in the configuration of the <code>GraphRetriever</code> changes the way that graph edges are defined and how the implied knowledge graph is traversed. There is no need to modify the data set or re-build the knoweledge graph beyond specifying a new <code>GraphRetriever</code> configuration.</p> <p>See below for how to build this graph RAG system.</p>"},{"location":"examples/movie-reviews-graph-rag/#environment-setup","title":"Environment Setup\u00b6","text":"<p>This notebook uses the APIs for OpenAI and Astra DB</p> <p>NOTE: the environment variables for Astra DB are not required if running only the code with the small data sample below, but are required for the code below that works with the full dataset.</p> <p>You can get an OpenAI API key here. And, more information about using the OpenAI API in Python can be found here.</p> <p>Here are the instructions to set up a free Astra serverless database.</p> <p>To connect to these services within this notebook, the following environment variables are required (or optional, as noted):</p> <ul> <li><code>OPENAI_API_KEY</code>: Your OpenAI API key.</li> <li><code>ASTRA_DB_API_ENDPOINT</code>: The Astra DB API endpoint.</li> <li><code>ASTRA_DB_APPLICATION_TOKEN</code>: The Astra DB Application token.</li> <li><code>ASTRA_DB_KEYSPACE</code>: Optional. If defined, will specify the Astra DB keyspace. If not defined, will use the default.</li> <li><code>LANGCHAIN_API_KEY</code>: Optional. If defined, will enable LangSmith tracing.</li> </ul> <p>If running this notebook in Colab, configure these environment variables as Colab Secrets.</p> <p>If running this notebook locally, make sure you have a <code>.env</code> file containing all of the required variables, and then use the <code>dotenv</code> package as below to load environment variables from that file. More details on <code>dotenv</code> can be found here.</p>"},{"location":"examples/movie-reviews-graph-rag/#loading-the-data","title":"Loading the data\u00b6","text":"<p>The website Rotten Tomatoes has published a large dataset of movie reviews. containing:</p> <ol> <li><code>rotten_tomatoes_movie_reviews.csv</code> -- the movie reviews</li> <li><code>rotten_tomatoes_movies.csv</code> -- information about the movies referenced in those reviews</li> </ol> <p>Below, we first give a small sample dataset contained in this notebook, so that you can try this implementation of graph RAG without needing to download and process the full dataset from files.</p> <p>Or, you can skip loading this data sample and proceed directly to \"Loading the full dataset from file\" below.</p>"},{"location":"examples/movie-reviews-graph-rag/#loading-a-small-data-sample","title":"Loading a small data sample\u00b6","text":"<p>Below is a sample dataset that is coded into this notebook as string objects and then read into <code>pandas</code> dataframes using <code>StringIO</code>.</p>"},{"location":"examples/movie-reviews-graph-rag/#pre-processing-the-data","title":"Pre-processing the data\u00b6","text":"<p>First, we rename one column in each of the two dataframes so that we can use them later to build a knowledge graph.</p>"},{"location":"examples/movie-reviews-graph-rag/#create-the-vector-store-with-embedding","title":"Create the vector store, with embedding\u00b6","text":"<p>Next, for the small data sample, we create an <code>InMemoryVectorStore</code> from LangChain using <code>OpenAIEmbeddings()</code> to embed the documents.</p>"},{"location":"examples/movie-reviews-graph-rag/#loading-the-full-dataset-from-file","title":"Loading the full dataset from file\u00b6","text":"<p>Before running this code, make sure you have downloaded (and extracted) the dataset from the link provided above. The date files should be in your working directory, or you will need to change the file paths below to match the locations of your files.</p> <p>See the top of this notebook for links and information about the datasets.</p>"},{"location":"examples/movie-reviews-graph-rag/#pre-processing-the-data","title":"Pre-processing the data\u00b6","text":"<p>First, we rename one column in each of the two dataframes so that we can use them later to build a knowledge graph.</p>"},{"location":"examples/movie-reviews-graph-rag/#create-the-vector-store-with-embedding","title":"Create the vector store, with embedding\u00b6","text":"<p>Next, for the small data sample, we create an <code>AstraDBVectorStore</code> from LangChain using <code>OpenAIEmbeddings()</code> to embed the documents.</p>"},{"location":"examples/movie-reviews-graph-rag/#convert-data-to-document-objects-and-store-them","title":"Convert data to <code>Document</code> objects and store them\u00b6","text":"<p>Next, we convert both movies and movie reviews into LangChain <code>Document</code> objects. The content of each document---which is embedded into vectors---is configured to be the movie review text (for review documents) or the movie title (for movie documents). All remaining information is saved as metadata on each document.</p> <p>Note that to save time in this demo, we limit the dataset to include only the movies that have the most reviews.</p>"},{"location":"examples/movie-reviews-graph-rag/#setting-up-the-graphretriever","title":"Setting up the GraphRetriever\u00b6","text":"<p>The <code>GraphRetriever</code> operates on top of the vector store, using document metadata to traverse the implicit knowledge graph as defined by the <code>edges</code> parameter in <code>GraphRetriever</code> configuration.</p> <p>Edges are specified as directed pairs of metadata fields. In the example below, the edge configuration</p> <pre><code>edges = [(\"reviewed_movie_id\", \"movie_id\")]\n</code></pre> <p>specifies that there is a directed graph edge between two documents whenever the <code>reviewed_movie_id</code> of the first document matches the <code>movie_id</code> of the second---and graph traversal proceeds along these directed edges. In this case, all of our edges lead from a document containing a movie review to a document containing information about the movie.</p> <p>The <code>strategy</code> parameter of the <code>GraphRetriever</code> configuration determines how the graph is traversed, starting with the initial documents retrieved and proceeding along the directed edges to adjacent documents.</p> <p>In the example below, the configuration</p> <pre><code>strategy=Eager(start_k=10,\n               adjacent_k=10,\n               select_k=10,\n               max_depth=1)\n</code></pre> <p>uses the following steps:</p> <ol> <li>it initially retrieves <code>start_k=10</code> documents using pure vector search,</li> <li>then traverses graph edges from the initial documents to adjacent documents (a max of <code>adjacent_k</code>),</li> <li>it repeats traversal from the new documents until reaching <code>max_depth=1</code>,</li> <li>it returns both the initial documents and documents retrieved during traversal, up to a maximum of <code>select_k</code> documents.</li> </ol> <p>Note that in this simple example, each movie review has a graph edge leading to exactly one movie, so each initial document (a movie review) should have one edge to traverse to another document (a movie) at a depth of 1. And, each movie document has no out-going edges to traverse, so the traversal depth would not proceed beyond depth 1 regardless of the value for <code>max_depth</code>. We demonstrate deeper and more complex strategies in other examples.</p> <p>For more details, see the documentation on GraphRetriever strategy.</p>"},{"location":"examples/movie-reviews-graph-rag/#compile-graph-rag-results","title":"Compile Graph RAG results\u00b6","text":"<p>Now that we have completed graph retrieval, we can reformat the text and metadata in the results, so we can pass them to an LLM---via an augmented prompt---and generate a response to the initial prompt question.</p>"},{"location":"examples/movie-reviews-graph-rag/#get-an-ai-summary-of-results","title":"Get an AI summary of results\u00b6","text":"<p>Here, using the <code>formatted_text</code> from above, we set up a prompt template, and then pass it the retrieved movie reviews along with the the original query text to be answered.</p>"},{"location":"faqs/","title":"FAQs","text":""},{"location":"faqs/#is-graph-rag-a-knowledge-graph","title":"Is Graph RAG a Knowledge Graph?","text":"<p>Yes, for the recent usage of the term. Graph RAG implements graph traversal of structured metadata during retrieval. The structured metadata provides edges connecting unstructured content (\"knowledge\"). Graph RAG traverses a graph of knowledge.</p> <p>However, prior to the recent surge of Graph RAG, there was a more academic definition of knowledge graphs where nodes specifically represented entities and knowledge about the relationships appeared as edges. Graph RAG is not this version of a knowledge graph.</p> <p>We have found that adding edges to unstructured content is much easier and efficient to use. See the Lazy Graph RAG example for more details.</p> Links with more information. <p>We previously wrote about this distinction as \"content-centric\" (nodes are content) vs. \"entity-centric\" (nodes are entities).</p> <p>We've also demonstrated that building the content-centric knowledge graph is significinatly cheaper.</p> <p>In many ways this mirrors the difference between Microsoft's GraphRAG and LazyGraphRAG.</p>"},{"location":"faqs/#does-graph-rag-need-a-graph-db","title":"Does Graph RAG need a Graph DB?","text":"<p>No.</p> <p>Graph databases are excellent for operating on academic knowledge graphs, where you way be looking for specific relationships between multiple nodes -- eg., finding people who live in Seattle (have a \"lives in\" edge pointing at Seattle) and work at a company in Santa Clara (has a \"works at\" edge to a company node with a \"headquartered in\" edge pointing at Santa Clara). In this case, the graph structure encodes information, meaning the graph query needs to understand that structure.</p> <p>However, the best knowledge graph for Graph RAG is a vector store containing unstructured content with structured metadata first, and support traversal of those structured relationships second. This means that any vector store with metadata filtering capabilities (all or nearly all) can be used for traversal.</p> <p>Important</p> <p>Traditional graph databases require materializing edges during ingestion, making them inflexible and costly to maintain as data evolves. Our approach operates on relationships present in the metadata without materializing them, eliminating the need to decide on the graph relationships during ingestion and enabling each query to operate on a different set of relationships. This makes it easy to add your structured metadata to the documents and traverse it for enhanced retrieval in RAG applications and adapts effortlessly to changing data.</p> <p>There are some things a vector store can support that make the kinds of metadata queries needed for traversal more efficient. See the support matrix in the Adapters guide for more information.</p>"},{"location":"guide/","title":"Guide","text":"<p>Graph RAG provides the ability to traverse content in a vector store based on relationships in the metadata. The traversal may start from specific nodes or use vector search to find the best starting places (or both). Each traversal may define a different way to use the metadata to relate information, allowing different calls to traverse to focus on different properties.</p> <p>A variety of traversal strategies are supported, allowing the specific nodes selected during traversal to be controlled depending on the goals. In some cases, it is important to find deeper supporting content, while in others finding a broader set of relevant perspectives is more appropriate.</p> <p>This guide provides an overview of the key concepts and the components provided by the project.</p> <p>In a hurry to get started?</p> <p>Go to the Getting Started Guide to jump in!</p>"},{"location":"guide/#packages-and-components","title":"Packages and Components","text":"<p>The Graph RAG project primarily consists of two Python packages:</p> <ul> <li> <p><code>graph_retriever</code> provides the core traversal functions in a framework independent way.</p> <ul> <li>Traversal: The primary methods <code>traverse</code> and <code>atraverse</code> for performing the graph traversal.</li> <li>Strategies: Configurable and customizable strategies for selecting nodes to visit.</li> <li>Edges: Configurable and customizable specification of relationships between nodes.</li> <li>Adapters: Interface used to interact with a Vector Store.</li> </ul> </li> <li> <p><code>langchain_graph_retriever</code> is built on it and integrates with LangChain to allow graph retrieval on LangChain supported Vector Stores.</p> <ul> <li>GraphRetriever: A LangChain Retriever for performing the traversal. Uses <code>traverse</code> and <code>atraverse</code> under the hood.</li> <li>Transformers: A variety of LangChain document transformers adding metadata that may be useful for traversing.</li> <li>Adapters: Adapter implementations for LangChain Vector Stores.</li> </ul> </li> </ul>"},{"location":"guide/adapters/","title":"Adapters","text":"<p>Adapters allow <code>graph-retriever</code> to connect to specific vector stores.</p> Vector Store Supported Collections Dict-In-List Nested Metadata Optimized Adjacency DataStax Astra OpenSearch Apache Cassandra Chroma Supported <p>Indicates whether a given store is completely supported () or has limited support ().</p> Collections <p>Indicates whether the store supports lists in metadata values or not. Stores which do not support it directly () can be used by applying the ShreddingTransformer document transformer to documents before writing, which spreads the items of the collection into multiple metadata keys.</p> Dict-In-List <p>Indicates the store supports using a dict-value in a list for edges. For example, when using named-entity recognition, you may have <code>entities = [{\"type\": \"PERSON\", \"entity\": \"Bell\"}, ...]</code> and wish to link nodes with the same entity using an edge defined as <code>(\"entities\", \"entities\")</code>.</p> Nested Metadata <p>Whether edges can be defined using values of nested metadata. For example, <code>page_structure.section</code> to access the section ID stored in metadata as <code>metadata[\"page_structure\"] = { \"section\": ... }</code>.</p> Optimized Adjacency <p>Whether the store supports an optimized query for nodes adjacent to multiple edges. Without this optimization each edge must be queried separately. Stores that support the combined adjacent query perform much better, especially when retrieving large numbers of nodes and/or dealing with high connectivity.</p> <p>Warning</p> <p>Graph Retriever can be used with any of these supported Vector Stores. However, stores that operate directly on nested collections (without denormalization) and support optimized adjacency much more performant and better suited for production use. Stores like Chroma are best employed for early experimentation, while it is generally recommended to use a store like DataStax AstraDB when scaling up.</p>"},{"location":"guide/adapters/#supported-stores","title":"Supported Stores","text":""},{"location":"guide/adapters/#astra","title":"Astra","text":"<p>DataStax AstraDB is supported by the <code>AstraAdapter</code>. The adapter supports operating on metadata containing both primitive and list values. Additionally, it optimizes the request for nodes connected to multiple edges into a single query.</p>"},{"location":"guide/adapters/#opensearch","title":"OpenSearch","text":"<p>OpenSearch is supported by the <code>OpenSearchAdapter</code>. The adapter supports operating on metadata containing both primitive and list values. It does not perform an optimized adjacent query.</p>"},{"location":"guide/adapters/#cassandra","title":"Apache Cassandra","text":"<p>Apache Cassandra is supported by the <code>CassandraAdapter</code>. The adapter requires shredding metadata containing lists in order to use them as edges. It does not perform an optimized adjacent query.</p>"},{"location":"guide/adapters/#chroma","title":"Chroma","text":"<p>Chroma is supported by the <code>ChromaAdapter</code>. The adapter requires shredding metadata containing lists in order to use them as edges. It does not perform an optimized adjacent query.</p>"},{"location":"guide/adapters/#implementation","title":"Implementation","text":"<p>The Adapter interface may be implemented directly. For LangChain VectorStores, LangchainAdapter and ShreddedLangchainAdapter provide much of the necessary functionality.</p>"},{"location":"guide/edges/","title":"Edges","text":"<p>Edges specify how content should be linked. Often, content in existing vector stores has metadata based on structured information. For example, a vector store containing articles may have information about the authors, keywords, and citations of those articles. Such content can be traversed along relationships already present in that metadata! See Specifying Edges for more on how edges are specified.</p> <p>Edges can be dynamically specified each time</p> <p>Since edges can be different each time the traversal is invoked, it is possible to tailor the relationships being used to the question.</p>"},{"location":"guide/edges/#specifying-edges","title":"Specifying Edges","text":"<p>Edges are specified by passing the <code>edges</code> parameter to <code>traverse</code> or <code>atraverse</code>. When used with LangChain, they may be provided when the <code>GraphRetriever</code> is instantiated or when <code>invoke</code> or <code>ainvoke</code> is called.</p> <p>The following example shows how edges can be defined using metadata from an example article.</p> <p>Specifying Edges</p> Example content for an article<pre><code>Content(\n    id=\"article1\",\n    content=\"...\",\n    metadata={\n        \"keywords\": [\"GPT\", \"GenAI\"],\n        \"authors\": [\"Ben\", \"Eric\"],\n        \"primary_author\": \"Eric\",\n        \"cites\": [\"article2\", \"article3\"],\n    }\n)\n</code></pre> <ol> <li><code>(\"keywords\", \"keywords\")</code> connects to other articles about GPT and GenAI.</li> <li><code>(\"authors\", \"authors\")</code> connects to other articles by any of the same authors.</li> <li><code>(\"authors\", \"primary_author\")</code> connects to other articles whose primary author was Ben or Eric.</li> <li><code>(\"cites\", \"$id\")</code> connects to the articles cited (by ID).</li> <li><code>(\"$id\", \"cites\")</code> connects to articles which cite this one.</li> <li><code>(\"cites\", \"cites\")</code> connects to other articles with citations in common.</li> </ol>"},{"location":"guide/edges/#edge-functions","title":"Edge Functions","text":"<p>While sometimes the information to traverse is missing and the vector store needs to be re-populated, in other cases the information exist but not quite be in a suitable format for traversal. For instance, the <code>\"authors\"</code> field may contain a list of authors and their institution, making it impossible to link to other articles by the same author when they were at a different institution.</p> <p>In such cases, you can provide a custom <code>EdgeFunction</code> to extract the edges for traversal.</p>"},{"location":"guide/get-started/","title":"Get Started","text":"<p>This page demonstrates how to combine Graph Traversal and Vector Search using <code>langchain-graph-retriever</code> with <code>langchain</code>.</p>"},{"location":"guide/get-started/#pre-requisites","title":"Pre-requisites","text":"<p>We assume you already have a working <code>langchain</code> installation, including an LLM and embedding model as well as a supported vector store.</p> <p>In that case, you only need to install <code>langchain-graph-retriever</code>:</p> <pre><code>pip install langchain langchain-graph-retriever\n</code></pre>"},{"location":"guide/get-started/#preparing-data","title":"Preparing Data","text":"<p>Loading data is exactly the same as for whichever vector store you use. The main thing to consider is what structured information you wish to include in the metadata to support traversal.</p> <p>For this guide, I have a JSON file with information about animals. Several example entries are shown below. The actual file has one entry per line, making it easy to load into <code>Document</code>s.</p> <pre><code>{\n    \"id\": \"alpaca\",\n    \"text\": \"alpacas are domesticated mammals valued for their soft wool and friendly demeanor.\",\n    \"metadata\": {\n        \"type\": \"mammal\",\n        \"number_of_legs\": 4,\n        \"keywords\": [\"wool\", \"domesticated\", \"friendly\"],\n        \"origin\": \"south america\"\n    }\n}\n{\n    \"id\": \"caribou\",\n    \"text\": \"caribou, also known as reindeer, are migratory mammals found in arctic regions.\",\n    \"metadata\": {\n        \"type\": \"mammal\",\n        \"number_of_legs\": 4,\n        \"keywords\": [\"migratory\", \"arctic\", \"herbivore\", \"tundra\"],\n        \"diet\": \"herbivorous\"\n    }\n}\n{\n    \"id\": \"cassowary\",\n    \"text\": \"cassowaries are flightless birds known for their colorful necks and powerful legs.\",\n    \"metadata\": {\n        \"type\": \"bird\",\n        \"number_of_legs\": 2,\n        \"keywords\": [\"flightless\", \"colorful\", \"powerful\"],\n        \"habitat\": \"rainforest\"\n    }\n}\n</code></pre> Fetching Animal Data<pre><code>from graph_rag_example_helpers.datasets.animals import fetch_documents\nanimals = fetch_documents()\n</code></pre>"},{"location":"guide/get-started/#populating-the-vector-store","title":"Populating the Vector Store","text":"<p>The following shows how to populate a variety of vector stores with the animal data.</p> AstraApache CassandraOpenSearchChroma <pre><code>from dotenv import load_dotenv\nfrom langchain_astradb import AstraDBVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nload_dotenv()\nvector_store = AstraDBVectorStore.from_documents(\n    collection_name=\"animals\",\n    documents=animals,\n    embedding=OpenAIEmbeddings(),\n)\n</code></pre> <pre><code>from langchain_community.vectorstores.cassandra import Cassandra\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_graph_retriever.transformers import ShreddingTransformer\n\nshredder = ShreddingTransformer() # (1)!\nvector_store = Cassandra.from_documents(\n    documents=list(shredder.transform_documents(animals)),\n    embedding=OpenAIEmbeddings(),\n    table_name=\"animals\",\n)\n</code></pre> <ol> <li>Since Cassandra doesn't index items in lists for querying, it is necessary to shred metadata containing list to be queried. By default, the <code>ShreddingTransformer</code> shreds all keys. It may be configured to only shred those metadata keys used as edge targets.</li> </ol> <pre><code>from langchain_community.vectorstores import OpenSearchVectorSearch\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = OpenSearchVectorSearch.from_documents(\n    opensearch_url=OPEN_SEARCH_URL,\n    index_name=\"animals\",\n    embedding=OpenAIEmbeddings(),\n    engine=\"faiss\",\n    documents=animals,\n    bulk_size=500, # (1)!\n)\n</code></pre> <ol> <li>There is currently a bug in the OpenSearchVectorStore implementation that requires this extra parameter.</li> </ol> <pre><code>from langchain_chroma.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_graph_retriever.transformers import ShreddingTransformer\n\nshredder = ShreddingTransformer() # (1)!\nvector_store = Chroma.from_documents(\n    documents=list(shredder.transform_documents(animals)),\n    embedding=OpenAIEmbeddings(),\n    collection_name=\"animals\",\n)\n</code></pre> <ol> <li>Since Chroma doesn't index items in lists for querying, it is necessary to shred metadata containing list to be queried. By default, the <code>ShreddingTransformer</code> shreds all keys. It may be configured to only shred those metadata keys used as edge targets.</li> </ol>"},{"location":"guide/get-started/#simple-traversal","title":"Simple Traversal","text":"<p>For our first retrieval and graph traversal, we're going to start with a single animal best matching the query, and then traverse to other animals with the same <code>habitat</code> and/or <code>origin</code>.</p> AstraApache CassandraOpenSearchChroma <pre><code>from graph_retriever.strategies import Eager\nfrom langchain_graph_retriever import GraphRetriever\n\nsimple = GraphRetriever(\n    store = vector_store,\n    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\"), (\"keywords\", \"keywords\")],\n    strategy = Eager(k=10, start_k=1, max_depth=2),\n)\n</code></pre> <pre><code>from graph_retriever.strategies import Eager\nfrom langchain_graph_retriever import GraphRetriever\nfrom langchain_graph_retriever.adapters.cassandra import CassandraAdapter\n\nsimple = GraphRetriever(\n    store = CassandraAdapter(vector_store, shredder, {\"keywords\"}),,\n    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\"), (\"keywords\", \"keywords\")],\n    strategy = Eager(k=10, start_k=1, max_depth=2),\n)\n</code></pre> <pre><code>from graph_retriever.strategies import Eager\nfrom langchain_graph_retriever import GraphRetriever\n\nsimple = GraphRetriever(\n    store = vector_store,\n    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\"), (\"keywords\", \"keywords\")],\n    strategy = Eager(k=10, start_k=1, max_depth=2),\n)\n</code></pre> <pre><code>from graph_retriever.strategies import Eager\nfrom langchain_graph_retriever import GraphRetriever\nfrom langchain_graph_retriever.adapters.chroma import ChromaAdapter\n\nsimple = GraphRetriever(\n    store = ChromaAdapter(vector_store, shredder, {\"keywords\"}),\n    edges = [(\"habitat\", \"habitat\"), (\"origin\", \"origin\"), (\"keywords\", \"keywords\")],\n    strategy = Eager(k=10, start_k=1, max_depth=2),\n)\n</code></pre> <p>Shredding</p> <p>The above code is exactly the same for all stores, however adapters for shredded stores (Chroma and Apache Cassandra) require configuration to specify which metadata fields need to be rewritten when issuing queries.</p> <p>The above creates a graph traversing retriever that starts with the nearest animal (<code>start_k=1</code>), retrieves 10 documents (<code>k=10</code>) and limits the search to documents that are at most 2 steps away from the first animal (<code>max_depth=2</code>).</p> <p>The edges define how metadata values can be used for traversal. In this case, every animal is connected to other animals with the same habitat and/or same origin.</p> <pre><code>simple_results = simple.invoke(\"what mammals could be found near a capybara\")\n\nfor doc in simple_results:\n    print(f\"{doc.id}: {doc.page_content}\")\n</code></pre>"},{"location":"guide/get-started/#visualizing","title":"Visualizing","text":"<p><code>langchain-graph-retrievers</code> includes code for converting the document graph into a <code>networkx</code> graph, for rendering and other analysis. See @fig-document-graph</p> Graph retrieved documents<pre><code>import networkx as nx\nimport matplotlib.pyplot as plt\nfrom langchain_graph_retriever.document_graph import create_graph\n\ndocument_graph = create_graph(\n    documents=simple_results,\n    edges = simple.edges,\n)\n\nnx.draw(document_graph, with_labels=True)\nplt.show()\n</code></pre>"},{"location":"guide/migration/","title":"Migration","text":"<p>This page discusses migration from LangChain <code>GraphVectorStore</code> as well as between versions of <code>graph-retriever</code> and <code>langchain-graph-retriever</code>.</p>"},{"location":"guide/migration/#from-langchain-graphvectorstore","title":"From LangChain GraphVectorStore","text":"<p>LangChain <code>GraphVectorStore</code> relied on putting specially crafted <code>Link</code> instances into <code>metadata[\"links\"]</code>. Many cases used link extractors to compute these links, but it was also often useful (and necessary) to create them manually.</p> <p>When converting from a <code>GraphVectorStore</code> to the new <code>langchain-graph-retriever</code> library, you need to do the following:</p> <ol> <li>Replace uses of the link extractors with document transformers.</li> <li>Replace manualy link creation with metadata fields.</li> <li>Replace <code>GraphVectorStore</code> usage with the <code>GraphRetriever</code>.</li> </ol>"},{"location":"guide/migration/#replace-link-extractors-with-document-transformers","title":"Replace Link Extractors with Document Transformers","text":"<code>GLiNERLinkExtractor</code> <p>Replace with GLiNERTransformer, which will populate metadata fields for each label.</p> <code>HierarchyLinkExtractor</code> <p>If you already have a parent ID in the metadata, you can remove this. Otherwise, replace with the ParentTransformer which populates a <code>parent</code> field computed from a path. The parent field may be used with edges to achieve parent-to-child, child-to-parent, and sibling-to-sibling navigation.</p> <code>HtmlLinkExtractor</code> <p>Replace with HyperlinkTransformer which extracts hyperlinks from each chunk and writes them to a metadata field.</p> <code>KeybertLinkExtractor</code> <p>Replace with KeybertTransformer, which will populate a metadata field with the keywords.</p>"},{"location":"guide/migration/#replace-manual-link-creation-with-metadata-fields","title":"Replace Manual Link Creation with Metadata Fields","text":"<p>With the old library, you had to choose the direction of the links when they were created -- either <code>in</code>, <code>out</code> or <code>bidir</code>. With the new library, you simply create the corresponding fields and choose the direction of edges when you issue a query (see next section).</p> GraphVectorStore Links (Old)<pre><code># Document metadata for a page at `http://somesite` linking to some other URLs\n# and a few keyword links.\ndoc = Document(\n    ...,\n    metadata = {\n        \"links\": [\n            Link.incoming(\"url\", \"http://somesite\"),\n            Link.outgoing(\"url\", \"http://someothersite\"),\n            Link.outgoing(\"url\", \"http://yetanothersite\"),\n            Link.bidir(\"keyword\", \"sites\"),\n            Link.bidir(\"keyword\", \"web\"),\n        ]\n    }\n)\n</code></pre> LangChain Graph Retriever (New)<pre><code>doc = Document(\n    ...,\n    metadata = {\n        \"url\": \"http://somesite\",\n        \"hrefs\": [\"http://someothersite\", \"http://yetanothersite\"],\n        \"keywords\": [\"sites\", \"web\"],\n    }\n)\n</code></pre> <p>These metadata fields can be used to accomplish a variety of graph traversals. For example:</p> <ul> <li><code>edges = [(\"hrefs\", \"url\"), ...]</code> navigates from a site to the pages it links to (from <code>hrefs</code> to <code>url</code>).</li> <li><code>edges = [(\"keywords\", \"keywords\"), ...]</code> navigates from a site to other sites with the same keyword.</li> <li><code>edges = [(\"url\", \"hrefs\"), ...]</code> navigates from a site to other sites that link to it.</li> </ul> <p>Per-Query Edges</p> <p>You can use different edges for each query, allowing you to navigate different directions depending on the needs. In the old library, you only ever navigated out from a site to the things it linked to, while with the new library the metadata captures the information (what URL is this document from, what URLs does it reference) and the edges determine which fileds are traversed at retrieval time.</p>"},{"location":"guide/migration/#replace-graphvectorstore-with-the-graphretriever","title":"Replace GraphVectorStore with the GraphRetriever","text":"<p>Finally, rather than creating the links and writing them to a <code>GraphVectorStore</code> you write the documents (with metadata) to a standard <code>VectorStore</code> and apply a GraphRetriever:</p> LangChain Graph Retriever (New)<pre><code>from langchain_graph_retriever import GraphRetriever\nretriever = GraphRetriever(\n    store=vector_store,\n    edges=[(\"hrefs\", \"url\"), (\"keywords\", \"keywords\")],\n)\n</code></pre>"},{"location":"guide/strategies/","title":"Strategies","text":"<p>Strategies determine which nodes are selected during traversal.</p> <p>All strategies allow you to control how many nodes are retrieved (<code>k</code>) as well as how many nodes are found during the initial vector search (<code>start_k</code>) and each step of the traversal (<code>adjacent_k</code>) as well as bounding the nodes retrieved based on depth (<code>max_depth</code>).</p>"},{"location":"guide/strategies/#eager","title":"Eager","text":"<p>The <code>Eager</code> strategy selects all of the discovered nodes at each step of the traversal.</p> <p>It doesn't support configuration beyond the standard options.</p>"},{"location":"guide/strategies/#mmr","title":"MMR","text":"<p>The <code>MMR</code> strategy selects nodes with the highest maximum marginal relevance score at each iteration.</p> <p>It can be configured with a <code>lambda_mult</code> which controls the trade-off between relevance and diversity.</p>"},{"location":"guide/strategies/#scored","title":"Scored","text":"<p>The <code>Scored</code> strategy applies a user-defined function to each node to assign a score, and selects a number of nodes with the highest scores.</p>"},{"location":"guide/strategies/#user-defined-strategies","title":"User-Defined Strategies","text":"<p>You can also implement your own <code>Strategy</code>. This allows you to control how discovered nodes are tracked and selected for traversal.</p>"},{"location":"guide/transformers/","title":"Transformers","text":"<p>Transformers are optional, not mandatory</p> <p>Graph traversal operates on the structured metadata. Transformers provide tools for populating the metadata, but they are not necessary. In many cases you may have existing structured information that is useful in addition or instead of what the transformers would populate.</p> <p>We provide two types of document transformers that can be useful in setting up your documents for graph traversal.</p> <ul> <li> <p>Information Extractors: These extract information out of document content     and add to the metadata.</p> </li> <li> <p>Metadata Utilities: These add to or modify document metadata to enable certain     features</p> </li> </ul>"},{"location":"guide/transformers/#information-extractors","title":"Information Extractors","text":"<p>Extras required</p> <p>Most of the Transformers in this section require extra packages to be installed. Either look at the specifics in the reference documentation for each transformer, or install all the extras via:</p> <pre><code>pip install \"langchain-graph-retriever[all]\"\n</code></pre>"},{"location":"guide/transformers/#nlp-model-based","title":"NLP-Model Based","text":"<p>Several of our document transformers that extract information depend on pre-trained Natural Language Processing (NLP) models.</p> <p>The following LangChain documents will be used for the code examples in this section:</p> Test Documents <pre><code>from langchain_core.documents import Document\n\nmodel_docs = [\n    Document(\n        id=\"red_fox\",\n        page_content=\"\"\"\nThe Red Fox is an omnivore, feeding on small mammals, birds, fruits, and insects. It\nthrives in a wide range of habitats, including forests, grasslands, and even urban areas\nlike New York City, where it has adapted to human presence. This agile creature moves\nprimarily by walking and running, but it can also leap and climb when necessary. Its\nbody is covered in thick fur, which helps it stay warm in colder climates. The National\nWildlife Federation has tracked their urban expansion, and their population was\nhighlighted in the Wildlife Conservation Summit 2023.\"\"\",\n    ),\n    Document(\n        id=\"sea_turtle\",\n        page_content=\"\"\"\nThe Green Sea Turtle is a herbivore, grazing on seagrass and algae in coastal waters and\nshallow tropical seas, particularly around the Great Barrier Reef. It is a powerful\nswimmer, using its large, flipper-like limbs to glide through the ocean. Unlike mammals,\nits body is covered in a tough, scaly shell, providing protection from predators.\nConservation efforts by The World Wildlife Fund have played a significant role in\nprotecting this species, and it was a major focus of discussion at the Marine Life\nProtection Conference 2024.\",\n    ),\n]\n</code></pre>"},{"location":"guide/transformers/#glinertransformer","title":"GLiNERTransformer","text":"<p>The <code>GLiNERTransformer</code> extracts structured entity labels from text, identifying key attributes and categories to enrich document metadata with semantic information.</p> <p>Example use:     <pre><code>from pprint import pprint\nfrom langchain_graph_retriever.transformers.gliner import GLiNERTransformer\ngliner = GLiNERTransformer(labels=[\"diet\", \"habitat\", \"locomotion\", \"body covering\"])\n\ngliner_docs = gliner.transform_documents(docs)\nfor doc in gliner_docs:\n    pprint({\"id\": doc.id, \"metadata\": doc.metadata}, width=100)\n</code></pre></p> <p>Example output:     <pre><code>{'id': 'red_fox',\n'metadata': {'body covering': ['thick fur'],\n            'diet': ['birds', 'omnivore', 'small mammals', 'insects', 'fruits'],\n            'habitat': ['urban areas', 'new york city', 'forests', 'grasslands'],\n            'locomotion': ['walking and running']}}\n{'id': 'sea_turtle',\n'metadata': {'body covering': ['scaly shell'],\n            'diet': ['seagrass and algae'],\n            'habitat': ['coastal waters', 'shallow tropical seas', 'great barrier reef']}}\n</code></pre></p>"},{"location":"guide/transformers/#keyberttransformer","title":"KeyBERTTransformer","text":"<p>The <code>KeyBERTTransformer</code> extracts key topics and concepts from text, generating metadata that highlights the most relevant terms to describe the content.</p> <p>Example use:     <pre><code>from langchain_graph_retriever.transformers.keybert import KeyBERTTransformer\nkeybert = KeyBERTTransformer()\n\nkeybert_docs = keybert.transform_documents(model_docs)\nfor doc in keybert_docs:\n    print(f\"{doc.id}: {doc.metadata}\")\n</code></pre></p> <p>Example output:     <pre><code>red_fox: {'keywords': ['wildlife', 'fox', 'mammals', 'habitats', 'omnivore']}\nsea_turtle: {'keywords': ['turtle', 'reef', 'marine', 'seagrass', 'wildlife']}\n</code></pre></p>"},{"location":"guide/transformers/#spacynertransformer","title":"SpacyNERTransformer","text":"<p>The <code>SpacyNERTransformer</code> identifies and labels named entities in text, extracting structured metadata such as organizations, locations, dates, and other key entity types.</p> <p>Example use:     <pre><code>from pprint import pprint\nfrom langchain_graph_retriever.transformers.spacy import SpacyNERTransformer\nspacy = SpacyNERTransformer()\n\nspacy_docs = spacy.transform_documents(docs)\nfor doc in spacy_docs:\n    pprint({\"id\": doc.id, \"metadata\": doc.metadata}, width=100)\n</code></pre></p> <p>Example output:     <pre><code>{'id': 'red_fox',\n'metadata': {'entities': ['ORG: The National Wildlife Federation',\n                        'GPE: New York City',\n                        'ORG: the Wildlife Conservation Summit',\n                        'DATE: 2023']}}\n{'id': 'sea_turtle',\n'metadata': {'entities': ['ORG: The World Wildlife Fund',\n                        'FAC: the Great Barrier Reef',\n                        'ORG: the Marine Life Protection Conference',\n                        'LOC: The Green Sea Turtle',\n                        'DATE: 2024']}}\n</code></pre></p>"},{"location":"guide/transformers/#parser-based","title":"Parser Based","text":"<p>The following document transformer uses a parser to extract metadata.</p>"},{"location":"guide/transformers/#hyperlinktransformer","title":"HyperlinkTransformer","text":"<p>The <code>HyperlinkTransformer</code> extracts hyperlinks from HTML content and stores them in document metadata.</p> Test Html Documents <pre><code>from langchain_core.documents import Document\nanimal_html = \"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;&lt;head&gt;&lt;title&gt;Animals of the World&lt;/title&gt;&lt;/head&gt;\n    &lt;body&gt;\n        &lt;h2&gt;Mammals&lt;/h2&gt;\n        &lt;p&gt;The &lt;a href=\"https://example.com/lion\"&gt;lion&lt;/a&gt; is the king of the jungle.&lt;/p&gt;\n        &lt;p&gt;The &lt;a href=\"https://example.com/elephant\"&gt;elephant&lt;/a&gt; is a large animal.&lt;/p&gt;\n\n        &lt;h2&gt;Birds&lt;/h2&gt;\n        &lt;p&gt;The &lt;a href=\"https://example.com/eagle\"&gt;eagle&lt;/a&gt; soars high in the sky.&lt;/p&gt;\n        &lt;p&gt;The &lt;a href=\"https://example.com/penguin\"&gt;penguin&lt;/a&gt; thrives in icy areas.&lt;/p&gt;\n    &lt;/body&gt;&lt;/html&gt;\n    \"\"\"\n\nhtml_doc = Document(\n    page_content=animal_html,\n    metadata={\"url\": \"https://example.com/animals\"}\n)\n</code></pre> <p>Note that each document needs to have an existing <code>url</code> metadata field.</p> <p>Example use:     <pre><code>from pprint import pprint\nfrom langchain_graph_retriever.transformers.html import HyperlinkTransformer\nhtml_transformer = HyperlinkTransformer()\n\nextracted_doc = html_transformer.transform_documents(html_docs)[0]\n\npprint(extracted_doc.metadata)\n</code></pre></p> <p>Example output:     <pre><code>{'hyperlink': ['https://example.com/eagle',\n            'https://example.com/lion',\n            'https://example.com/elephant',\n            'https://example.com/penguin'],\n'url': 'https://example.com/animals'}\n</code></pre></p>"},{"location":"guide/transformers/#metadata-utilities","title":"Metadata Utilities","text":""},{"location":"guide/transformers/#parenttransformer","title":"ParentTransformer","text":"<p>The <code>ParentTransformer</code> adds the hierarchal <code>Parent</code> path to the document metadata.</p> Test Documents <pre><code>from langchain_core.documents import Document\n\nparent_docs = [\n    Document(id=\"root\", page_content=\"test\", metadata={\"path\": \"root\"}),\n    Document(id=\"h1\", page_content=\"test\", metadata={\"path\": \"root.h1\"}),\n    Document(id=\"h1a\", page_content=\"test\", metadata={\"path\": \"root.h1.a\"}),\n]\n</code></pre> <p>Note that each document needs to have an existing <code>path</code> metadata field.</p> <p>Example use:     <pre><code>from langchain_graph_retriever.transformers import ParentTransformer\ntransformer = ParentTransformer(path_delimiter=\".\")\n\ntransformed_docs = transformer.transform_documents(parent_docs)\nfor doc in transformed_docs:\n    print(f\"{doc.id}: {doc.metadata}\")\n</code></pre></p> <p>Example output:     <pre><code>root: {'path': 'root'}\nh1: {'path': 'root.h1', 'parent': 'root'}\nh1a: {'path': 'root.h1.a', 'parent': 'root.h1'}\n</code></pre></p>"},{"location":"guide/transformers/#shreddingtransformer","title":"ShreddingTransformer","text":"<p>The <code>ShreddingTransformer</code> is primarily designed as a helper utility for vector stores that do not have native support for collection-based metadata fields. It transforms these fields into multiple metadata key-value pairs before database insertion. It also provides a method to restore metadata back to its original format.</p>"},{"location":"guide/transformers/#shredding","title":"Shredding","text":"Test Document <pre><code>from langchain_core.documents import Document\n\ncollection_doc = Document(id=\"red_fox\", page_content=\"test\", metadata={\n    \"diet\": [\"birds\", \"omnivore\", \"small mammals\", \"insects\", \"fruits\"],\n    \"size\": \"small\"\n})\n</code></pre> <p>Example use:     <pre><code>from pprint import pprint\nfrom langchain_graph_retriever.transformers import ShreddingTransformer\n\nshredder = ShreddingTransformer()\nshredded_docs = shredder.transform_documents([collection_doc])\npprint(shredded_docs[0].metadata)\n</code></pre></p> <p>Example output:     <pre><code>{'__shredded_keys': '[\"diet\"]',\n'diet\u2192birds': '\u00a7',\n'diet\u2192fruits': '\u00a7',\n'diet\u2192insects': '\u00a7',\n'diet\u2192omnivore': '\u00a7',\n'diet\u2192small mammals': '\u00a7',\n'size': 'small'}\n</code></pre></p>"},{"location":"guide/transformers/#restoration","title":"Restoration","text":"<p>This example uses the output from the Shredding Example above.</p> <p>Example use:     <pre><code>restored_docs = shredder.restore_documents(shredded_docs)\npprint(restored_docs[0].metadata)\n</code></pre></p> <p>Example output:     <pre><code>{'diet': ['birds', 'omnivore', 'small mammals', 'insects', 'fruits'],\n 'size': 'small'}\n</code></pre></p>"},{"location":"guide/traversal/","title":"Traversal","text":"<p>At a high level, traversal performs the following steps:</p> <ol> <li>Retrieve <code>start_k</code> most similar to the <code>query</code> using vector search.</li> <li>Find the nodes reachable from the <code>initial_root_ids</code>.</li> <li>Discover the <code>start_k</code> nodes and the neighbors of the initial roots as \"depth 0\" candidates.</li> <li>Ask the strategy which nodes to visit next.</li> <li>If no more nodes to visit, exit and return the selected nodes.</li> <li>Record those nodes as selected and retrieve the top <code>adjacent_k</code> nodes reachable from them.</li> <li>Discover the newly reachable nodes (updating depths as needed).</li> <li>Goto 4.</li> </ol>"},{"location":"guide/traversal/#traversal-methods","title":"Traversal Methods","text":"<p>The <code>graph_retriever</code> package provides <code>traverse</code> and <code>atraverse</code> for performing traversals.</p>"},{"location":"guide/traversal/#graph-retriever","title":"LangChain Graph Retriever","text":"<p>The <code>langchain_graph_retriever</code> package provides <code>GraphRetriever</code>, an implementation of LangChain's <code>BaseRetriever</code> which performs traversals.</p>"},{"location":"reference/","title":"API Reference","text":"<ul> <li><code>graph-retriever</code> contains the core graph traversal logic.</li> <li><code>langchain-graph-retriever</code> contains a <code>GraphRetriever</code> and store adapters for use with LangChain.</li> <li><code>graph-rag-example-helpers</code> contains utilities used in some examples, such as recoverably loading large datasets.</li> </ul>"},{"location":"reference/graph_rag_example_helpers/","title":"graph_rag_example_helpers","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets","title":"datasets","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.animals","title":"animals","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.animals.fetch_documents","title":"fetch_documents","text":"<pre><code>fetch_documents() -&gt; list[Document]\n</code></pre> <p>Download and parse a list of Documents for use with Graph Retriever.</p> <p>This is a small example dataset with useful links.</p> <p>This method downloads the dataset each time -- generally it is preferable to invoke this only once and store the documents in memory or a vector store.</p> RETURNS DESCRIPTION <code>list[Document]</code> <p>The fetched animal documents.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/animals/fetch.py</code> <pre><code>def fetch_documents() -&gt; list[Document]:\n    \"\"\"\n    Download and parse a list of Documents for use with Graph Retriever.\n\n    This is a small example dataset with useful links.\n\n    This method downloads the dataset each time -- generally it is preferable\n    to invoke this only once and store the documents in memory or a vector\n    store.\n\n    Returns\n    -------\n    :\n        The fetched animal documents.\n    \"\"\"\n    response = requests.get(ANIMALS_JSONL_URL)\n    response.raise_for_status()  # Ensure we got a valid response\n\n    return [\n        Document(id=data[\"id\"], page_content=data[\"text\"], metadata=data[\"metadata\"])\n        for line in response.text.splitlines()\n        if (data := json.loads(line))\n    ]\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.animals.fetch","title":"fetch","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.animals.fetch.fetch_documents","title":"fetch_documents","text":"<pre><code>fetch_documents() -&gt; list[Document]\n</code></pre> <p>Download and parse a list of Documents for use with Graph Retriever.</p> <p>This is a small example dataset with useful links.</p> <p>This method downloads the dataset each time -- generally it is preferable to invoke this only once and store the documents in memory or a vector store.</p> RETURNS DESCRIPTION <code>list[Document]</code> <p>The fetched animal documents.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/animals/fetch.py</code> <pre><code>def fetch_documents() -&gt; list[Document]:\n    \"\"\"\n    Download and parse a list of Documents for use with Graph Retriever.\n\n    This is a small example dataset with useful links.\n\n    This method downloads the dataset each time -- generally it is preferable\n    to invoke this only once and store the documents in memory or a vector\n    store.\n\n    Returns\n    -------\n    :\n        The fetched animal documents.\n    \"\"\"\n    response = requests.get(ANIMALS_JSONL_URL)\n    response.raise_for_status()  # Ensure we got a valid response\n\n    return [\n        Document(id=data[\"id\"], page_content=data[\"text\"], metadata=data[\"metadata\"])\n        for line in response.text.splitlines()\n        if (data := json.loads(line))\n    ]\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.astrapy","title":"astrapy","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.astrapy.fetch_documents","title":"fetch_documents","text":"<pre><code>fetch_documents() -&gt; list[Document]\n</code></pre> <p>Download and parse a list of Documents for use with Graph Retriever.</p> <p>This dataset contains the documentation for the AstraPy project as of version 1.5.2.</p> <p>This method downloads the dataset each time -- generally it is preferable to invoke this only once and store the documents in memory or a vector store.</p> RETURNS DESCRIPTION <code>list[Document]</code> <p>The fetched astra-py documentation Documents.</p> Notes <ul> <li>The dataset is setup in a way where the path of the item is the <code>id</code>, the pydoc description is the <code>page_content</code>, and the items other attributes are stored in the <code>metadata</code>.</li> <li>There are many documents that contain an id and metadata, but no page_content.</li> </ul> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/astrapy/fetch.py</code> <pre><code>def fetch_documents() -&gt; list[Document]:\n    \"\"\"\n    Download and parse a list of Documents for use with Graph Retriever.\n\n    This dataset contains the documentation for the AstraPy project as of version 1.5.2.\n\n    This method downloads the dataset each time -- generally it is preferable\n    to invoke this only once and store the documents in memory or a vector\n    store.\n\n    Returns\n    -------\n    :\n        The fetched astra-py documentation Documents.\n\n    Notes\n    -----\n    - The dataset is setup in a way where the path of the item is the `id`, the pydoc\n    description is the `page_content`, and the items other attributes are stored in the\n    `metadata`.\n    - There are many documents that contain an id and metadata, but no page_content.\n    \"\"\"\n    response = requests.get(ASTRAPY_JSONL_URL)\n    response.raise_for_status()  # Ensure we got a valid response\n\n    return [\n        Document(id=data[\"id\"], page_content=data[\"text\"], metadata=data[\"metadata\"])\n        for line in response.text.splitlines()\n        if (data := json.loads(line))\n    ]\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.astrapy.fetch","title":"fetch","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.astrapy.fetch.fetch_documents","title":"fetch_documents","text":"<pre><code>fetch_documents() -&gt; list[Document]\n</code></pre> <p>Download and parse a list of Documents for use with Graph Retriever.</p> <p>This dataset contains the documentation for the AstraPy project as of version 1.5.2.</p> <p>This method downloads the dataset each time -- generally it is preferable to invoke this only once and store the documents in memory or a vector store.</p> RETURNS DESCRIPTION <code>list[Document]</code> <p>The fetched astra-py documentation Documents.</p> Notes <ul> <li>The dataset is setup in a way where the path of the item is the <code>id</code>, the pydoc description is the <code>page_content</code>, and the items other attributes are stored in the <code>metadata</code>.</li> <li>There are many documents that contain an id and metadata, but no page_content.</li> </ul> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/astrapy/fetch.py</code> <pre><code>def fetch_documents() -&gt; list[Document]:\n    \"\"\"\n    Download and parse a list of Documents for use with Graph Retriever.\n\n    This dataset contains the documentation for the AstraPy project as of version 1.5.2.\n\n    This method downloads the dataset each time -- generally it is preferable\n    to invoke this only once and store the documents in memory or a vector\n    store.\n\n    Returns\n    -------\n    :\n        The fetched astra-py documentation Documents.\n\n    Notes\n    -----\n    - The dataset is setup in a way where the path of the item is the `id`, the pydoc\n    description is the `page_content`, and the items other attributes are stored in the\n    `metadata`.\n    - There are many documents that contain an id and metadata, but no page_content.\n    \"\"\"\n    response = requests.get(ASTRAPY_JSONL_URL)\n    response.raise_for_status()  # Ensure we got a valid response\n\n    return [\n        Document(id=data[\"id\"], page_content=data[\"text\"], metadata=data[\"metadata\"])\n        for line in response.text.splitlines()\n        if (data := json.loads(line))\n    ]\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop","title":"wikimultihop","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.BatchPreparer","title":"BatchPreparer  <code>module-attribute</code>","text":"<pre><code>BatchPreparer = Callable[\n    [Iterator[bytes]], Iterator[Document]\n]\n</code></pre> <p>Function to apply to batches of lines to produce the document.</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.aload_2wikimultihop","title":"aload_2wikimultihop  <code>async</code>","text":"<pre><code>aload_2wikimultihop(\n    limit: int | None,\n    *,\n    full_para_with_hyperlink_zip_path: str,\n    store: VectorStore,\n    batch_prepare: BatchPreparer,\n) -&gt; None\n</code></pre> <p>Load 2wikimultihop data into the given <code>VectorStore</code>.</p> PARAMETER DESCRIPTION <code>limit</code> <p>Maximum number of lines to load. If a number less than one thousand, limits loading to the given number of lines. If <code>None</code>, loads all content.</p> <p> TYPE: <code>int | None</code> </p> <code>full_para_with_hyperlink_zip_path</code> <p>Path to <code>para_with_hyperlink.zip</code> downloaded following the instructions in 2wikimultihop.</p> <p> TYPE: <code>str</code> </p> <code>store</code> <p>The VectorStore to populate.</p> <p> TYPE: <code>VectorStore</code> </p> <code>batch_prepare</code> <p>Function to apply to batches of lines to produce the document.</p> <p> TYPE: <code>BatchPreparer</code> </p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/wikimultihop/load.py</code> <pre><code>async def aload_2wikimultihop(\n    limit: int | None,\n    *,\n    full_para_with_hyperlink_zip_path: str,\n    store: VectorStore,\n    batch_prepare: BatchPreparer,\n) -&gt; None:\n    \"\"\"\n    Load 2wikimultihop data into the given `VectorStore`.\n\n    Parameters\n    ----------\n    limit :\n        Maximum number of lines to load.\n        If a number less than one thousand, limits loading to the given number of lines.\n        If `None`, loads all content.\n    full_para_with_hyperlink_zip_path :\n        Path to `para_with_hyperlink.zip` downloaded following the instructions\n        in\n        [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\n    store :\n        The VectorStore to populate.\n    batch_prepare :\n        Function to apply to batches of lines to produce the document.\n    \"\"\"\n    if limit is None or limit &gt; LINES_IN_FILE:\n        limit = LINES_IN_FILE\n\n    if limit &lt;= 1000:\n        local_path = \"../../data/para_with_hyperlink_short.jsonl\"\n        if os.path.isfile(local_path):\n            for batch in batched(\n                itertools.islice(open(local_path, \"rb\").readlines(), limit), BATCH_SIZE\n            ):\n                docs = batch_prepare(iter(batch))\n                store.add_documents(list(docs))\n            print(f\"Loaded from {local_path}\")  # noqa: T201\n        else:\n            print(f\"{local_path} not found, fetching short dataset\")  # noqa: T201\n            response = requests.get(SHORT_URL)\n            response.raise_for_status()  # Ensure we get a valid response\n\n            for batch in batched(\n                itertools.islice(response.content.splitlines(), limit), BATCH_SIZE\n            ):\n                docs = batch_prepare(iter(batch))\n                store.add_documents(list(docs))\n            print(f\"Loaded from {SHORT_URL}\")  # noqa: T201\n        return\n\n    assert os.path.isfile(full_para_with_hyperlink_zip_path)\n    persistence = PersistentIteration(\n        journal_name=\"load_2wikimultihop.jrnl\",\n        iterator=batched(\n            itertools.islice(wikipedia_lines(full_para_with_hyperlink_zip_path), limit),\n            BATCH_SIZE,\n        ),\n    )\n    total_batches = ceil(limit / BATCH_SIZE) - persistence.completed_count()\n    if persistence.completed_count() &gt; 0:\n        print(  # noqa: T201\n            f\"Resuming loading with {persistence.completed_count()}\"\n            f\" completed, {total_batches} remaining\"\n        )\n\n    @backoff.on_exception(\n        backoff.expo,\n        EXCEPTIONS_TO_RETRY,\n        max_tries=MAX_RETRIES,\n    )\n    async def add_docs(batch_docs, offset) -&gt; None:\n        from astrapy.exceptions import CollectionInsertManyException\n\n        try:\n            await store.aadd_documents(batch_docs)\n            persistence.ack(offset)\n        except CollectionInsertManyException as err:\n            for exp in err.exceptions:\n                exp_desc = str(exp)\n                if \"DOCUMENT_ALREADY_EXISTS\" not in exp_desc:\n                    print(exp_desc)  # noqa: T201\n            raise\n\n    # We can't use asyncio.TaskGroup in 3.10. This would be simpler with that.\n    tasks: list[asyncio.Task] = []\n\n    for offset, batch_lines in tqdm(persistence, total=total_batches):\n        batch_docs = batch_prepare(batch_lines)\n        if batch_docs:\n            task = asyncio.create_task(add_docs(batch_docs, offset))\n\n            # It is OK if tasks are lost upon failure since that means we're\n            # aborting the loading.\n            tasks.append(task)\n\n            while len(tasks) &gt;= MAX_IN_FLIGHT:\n                completed, pending = await asyncio.wait(\n                    tasks, return_when=asyncio.FIRST_COMPLETED\n                )\n                for complete in completed:\n                    if (e := complete.exception()) is not None:\n                        print(f\"Exception in task: {e}\")  # noqa: T201\n                tasks = list(pending)\n        else:\n            persistence.ack(offset)\n\n    # Make sure all the tasks are done.\n    # This wouldn't be necessary if we used a taskgroup, but that is Python 3.11+.\n    while len(tasks) &gt; 0:\n        completed, pending = await asyncio.wait(\n            tasks, return_when=asyncio.FIRST_COMPLETED\n        )\n        for complete in completed:\n            if (e := complete.exception()) is not None:\n                print(f\"Exception in task: {e}\")  # noqa: T201\n        tasks = list(pending)\n\n    assert len(tasks) == 0\n    assert persistence.pending_count() == 0\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.load","title":"load","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.load.BatchPreparer","title":"BatchPreparer  <code>module-attribute</code>","text":"<pre><code>BatchPreparer = Callable[\n    [Iterator[bytes]], Iterator[Document]\n]\n</code></pre> <p>Function to apply to batches of lines to produce the document.</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.load.aload_2wikimultihop","title":"aload_2wikimultihop  <code>async</code>","text":"<pre><code>aload_2wikimultihop(\n    limit: int | None,\n    *,\n    full_para_with_hyperlink_zip_path: str,\n    store: VectorStore,\n    batch_prepare: BatchPreparer,\n) -&gt; None\n</code></pre> <p>Load 2wikimultihop data into the given <code>VectorStore</code>.</p> PARAMETER DESCRIPTION <code>limit</code> <p>Maximum number of lines to load. If a number less than one thousand, limits loading to the given number of lines. If <code>None</code>, loads all content.</p> <p> TYPE: <code>int | None</code> </p> <code>full_para_with_hyperlink_zip_path</code> <p>Path to <code>para_with_hyperlink.zip</code> downloaded following the instructions in 2wikimultihop.</p> <p> TYPE: <code>str</code> </p> <code>store</code> <p>The VectorStore to populate.</p> <p> TYPE: <code>VectorStore</code> </p> <code>batch_prepare</code> <p>Function to apply to batches of lines to produce the document.</p> <p> TYPE: <code>BatchPreparer</code> </p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/wikimultihop/load.py</code> <pre><code>async def aload_2wikimultihop(\n    limit: int | None,\n    *,\n    full_para_with_hyperlink_zip_path: str,\n    store: VectorStore,\n    batch_prepare: BatchPreparer,\n) -&gt; None:\n    \"\"\"\n    Load 2wikimultihop data into the given `VectorStore`.\n\n    Parameters\n    ----------\n    limit :\n        Maximum number of lines to load.\n        If a number less than one thousand, limits loading to the given number of lines.\n        If `None`, loads all content.\n    full_para_with_hyperlink_zip_path :\n        Path to `para_with_hyperlink.zip` downloaded following the instructions\n        in\n        [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\n    store :\n        The VectorStore to populate.\n    batch_prepare :\n        Function to apply to batches of lines to produce the document.\n    \"\"\"\n    if limit is None or limit &gt; LINES_IN_FILE:\n        limit = LINES_IN_FILE\n\n    if limit &lt;= 1000:\n        local_path = \"../../data/para_with_hyperlink_short.jsonl\"\n        if os.path.isfile(local_path):\n            for batch in batched(\n                itertools.islice(open(local_path, \"rb\").readlines(), limit), BATCH_SIZE\n            ):\n                docs = batch_prepare(iter(batch))\n                store.add_documents(list(docs))\n            print(f\"Loaded from {local_path}\")  # noqa: T201\n        else:\n            print(f\"{local_path} not found, fetching short dataset\")  # noqa: T201\n            response = requests.get(SHORT_URL)\n            response.raise_for_status()  # Ensure we get a valid response\n\n            for batch in batched(\n                itertools.islice(response.content.splitlines(), limit), BATCH_SIZE\n            ):\n                docs = batch_prepare(iter(batch))\n                store.add_documents(list(docs))\n            print(f\"Loaded from {SHORT_URL}\")  # noqa: T201\n        return\n\n    assert os.path.isfile(full_para_with_hyperlink_zip_path)\n    persistence = PersistentIteration(\n        journal_name=\"load_2wikimultihop.jrnl\",\n        iterator=batched(\n            itertools.islice(wikipedia_lines(full_para_with_hyperlink_zip_path), limit),\n            BATCH_SIZE,\n        ),\n    )\n    total_batches = ceil(limit / BATCH_SIZE) - persistence.completed_count()\n    if persistence.completed_count() &gt; 0:\n        print(  # noqa: T201\n            f\"Resuming loading with {persistence.completed_count()}\"\n            f\" completed, {total_batches} remaining\"\n        )\n\n    @backoff.on_exception(\n        backoff.expo,\n        EXCEPTIONS_TO_RETRY,\n        max_tries=MAX_RETRIES,\n    )\n    async def add_docs(batch_docs, offset) -&gt; None:\n        from astrapy.exceptions import CollectionInsertManyException\n\n        try:\n            await store.aadd_documents(batch_docs)\n            persistence.ack(offset)\n        except CollectionInsertManyException as err:\n            for exp in err.exceptions:\n                exp_desc = str(exp)\n                if \"DOCUMENT_ALREADY_EXISTS\" not in exp_desc:\n                    print(exp_desc)  # noqa: T201\n            raise\n\n    # We can't use asyncio.TaskGroup in 3.10. This would be simpler with that.\n    tasks: list[asyncio.Task] = []\n\n    for offset, batch_lines in tqdm(persistence, total=total_batches):\n        batch_docs = batch_prepare(batch_lines)\n        if batch_docs:\n            task = asyncio.create_task(add_docs(batch_docs, offset))\n\n            # It is OK if tasks are lost upon failure since that means we're\n            # aborting the loading.\n            tasks.append(task)\n\n            while len(tasks) &gt;= MAX_IN_FLIGHT:\n                completed, pending = await asyncio.wait(\n                    tasks, return_when=asyncio.FIRST_COMPLETED\n                )\n                for complete in completed:\n                    if (e := complete.exception()) is not None:\n                        print(f\"Exception in task: {e}\")  # noqa: T201\n                tasks = list(pending)\n        else:\n            persistence.ack(offset)\n\n    # Make sure all the tasks are done.\n    # This wouldn't be necessary if we used a taskgroup, but that is Python 3.11+.\n    while len(tasks) &gt; 0:\n        completed, pending = await asyncio.wait(\n            tasks, return_when=asyncio.FIRST_COMPLETED\n        )\n        for complete in completed:\n            if (e := complete.exception()) is not None:\n                print(f\"Exception in task: {e}\")  # noqa: T201\n        tasks = list(pending)\n\n    assert len(tasks) == 0\n    assert persistence.pending_count() == 0\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.datasets.wikimultihop.load.wikipedia_lines","title":"wikipedia_lines","text":"<pre><code>wikipedia_lines(\n    para_with_hyperlink_zip_path: str,\n) -&gt; Iterable[bytes]\n</code></pre> <p>Return iterable of lines from the wikipedia file.</p> PARAMETER DESCRIPTION <code>para_with_hyperlink_zip_path</code> <p>Path to <code>para_with_hyperlink.zip</code> downloaded following the instructions in 2wikimultihop.</p> <p> TYPE: <code>str</code> </p> YIELDS DESCRIPTION <code>str</code> <p>Lines from the Wikipedia file.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/datasets/wikimultihop/load.py</code> <pre><code>def wikipedia_lines(para_with_hyperlink_zip_path: str) -&gt; Iterable[bytes]:\n    \"\"\"\n    Return iterable of lines from the wikipedia file.\n\n    Parameters\n    ----------\n    para_with_hyperlink_zip_path :\n        Path to `para_with_hyperlink.zip` downloaded following the instructions\n        in\n        [2wikimultihop](https://github.com/Alab-NII/2wikimultihop?tab=readme-ov-file#new-update-april-7-2021).\n\n    Yields\n    ------\n    str\n        Lines from the Wikipedia file.\n    \"\"\"\n    with zipfile.ZipFile(para_with_hyperlink_zip_path, \"r\") as archive:\n        with archive.open(\"para_with_hyperlink.jsonl\", \"r\") as para_with_hyperlink:\n            yield from para_with_hyperlink\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env","title":"env","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.NON_SECRETS","title":"NON_SECRETS  <code>module-attribute</code>","text":"<pre><code>NON_SECRETS = {\n    \"ASTRA_DB_API_ENDPOINT\",\n    \"ASTRA_DB_DATABASE_ID\",\n}\n</code></pre> <p>Environment variables that can use <code>input</code> instead of <code>getpass</code>.</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.Environment","title":"Environment","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of supported environments for examples.</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.Environment.ASTRAPY","title":"ASTRAPY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ASTRAPY = auto()\n</code></pre> <p>Environment variables for connecting to AstraDB via AstraPy</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.Environment.CASSIO","title":"CASSIO  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CASSIO = auto()\n</code></pre> <p>Environment variables for connecting to AstraDB via CassIO</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.Environment.required_envvars","title":"required_envvars","text":"<pre><code>required_envvars() -&gt; list[str]\n</code></pre> <p>Return the required environment variables for this environment.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>The environment variables required in this environment.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the environment isn't recognized.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/env.py</code> <pre><code>def required_envvars(self) -&gt; list[str]:\n    \"\"\"\n    Return the required environment variables for this environment.\n\n    Returns\n    -------\n    :\n        The environment variables required in this environment.\n\n    Raises\n    ------\n    ValueError\n        If the environment isn't recognized.\n    \"\"\"\n    required = [\"OPENAI_API_KEY\", \"ASTRA_DB_APPLICATION_TOKEN\"]\n    if self == Environment.CASSIO:\n        required.append(\"ASTRA_DB_DATABASE_ID\")\n    elif self == Environment.ASTRAPY:\n        required.append(\"ASTRA_DB_API_ENDPOINT\")\n    else:\n        raise ValueError(f\"Unrecognized environment '{self}\")\n    return required\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.initialize_environment","title":"initialize_environment","text":"<pre><code>initialize_environment(env: Environment = CASSIO)\n</code></pre> <p>Initialize the environment variables.</p> PARAMETER DESCRIPTION <code>env</code> <p>The environment to initialize</p> <p> TYPE: <code>Environment</code> DEFAULT: <code>CASSIO</code> </p> Notes <pre><code>This uses the following:\n\n1. If a `.env` file is found, load environment variables from that.\n2. If not, and running in colab, set necessary environment variables from\n    secrets.\n3. If necessary variables aren't set by the above, then prompts the user.\n</code></pre> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/env.py</code> <pre><code>def initialize_environment(env: Environment = Environment.CASSIO):\n    \"\"\"\n    Initialize the environment variables.\n\n    Parameters\n    ----------\n    env :\n        The environment to initialize\n\n    Notes\n    -----\n        This uses the following:\n\n        1. If a `.env` file is found, load environment variables from that.\n        2. If not, and running in colab, set necessary environment variables from\n            secrets.\n        3. If necessary variables aren't set by the above, then prompts the user.\n    \"\"\"\n    # 1. If a `.env` file is found, load environment variables from that.\n    if dotenv_path := find_dotenv():\n        load_dotenv(dotenv_path)\n        verify_environment(env)\n        return\n\n    # 2. If not, and running in colab, set necesary environment variables from secrets.\n    try:\n        initialize_from_colab_userdata(env)\n        verify_environment(env)\n        return\n    except (ImportError, ModuleNotFoundError):\n        pass\n\n    # 3. Initialize from prompts.\n    initialize_from_prompts(env)\n    verify_environment(env)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.initialize_from_colab_userdata","title":"initialize_from_colab_userdata","text":"<pre><code>initialize_from_colab_userdata(env: Environment = CASSIO)\n</code></pre> <p>Try to initialize environment from colab <code>userdata</code>.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/env.py</code> <pre><code>def initialize_from_colab_userdata(env: Environment = Environment.CASSIO):\n    \"\"\"Try to initialize environment from colab `userdata`.\"\"\"\n    from google.colab import userdata  # type: ignore[import-untyped]\n\n    for required in env.required_envvars():\n        os.environ[required] = userdata.get(required)\n\n    try:\n        os.environ[\"ASTRA_DB_KEYSPACE\"] = userdata.get(\"ASTRA_DB_KEYSPACE\")\n    except userdata.SecretNotFoundError as _:\n        # User doesn't have a keyspace set, so use the default.\n        os.environ.pop(\"ASTRA_DB_KEYSPACE\", None)\n\n    try:\n        os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n    except (userdata.SecretNotFoundError, userdata.NotebookAccessError):\n        print(\"Colab Secret not set / accessible. Not configuring tracing\")  # noqa: T201\n        os.environ.pop(\"LANGCHAIN_API_KEY\")\n        os.environ.pop(\"LANGCHAIN_TRACING_V2\")\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.initialize_from_prompts","title":"initialize_from_prompts","text":"<pre><code>initialize_from_prompts(env: Environment = CASSIO)\n</code></pre> <p>Initialize the environment by prompting the user.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/env.py</code> <pre><code>def initialize_from_prompts(env: Environment = Environment.CASSIO):\n    \"\"\"Initialize the environment by prompting the user.\"\"\"\n    import getpass\n\n    for required in env.required_envvars():\n        if required in os.environ:\n            continue\n        elif required in NON_SECRETS:\n            os.environ[required] = input(required)\n        else:\n            os.environ[required] = getpass.getpass(required)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.env.verify_environment","title":"verify_environment","text":"<pre><code>verify_environment(env: Environment = CASSIO)\n</code></pre> <p>Verify the necessary environment variables are set.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/env.py</code> <pre><code>def verify_environment(env: Environment = Environment.CASSIO):\n    \"\"\"Verify the necessary environment variables are set.\"\"\"\n    for required in env.required_envvars():\n        assert required in os.environ, f'\"{required}\" not defined in environment'\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples","title":"examples","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation","title":"code_generation","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.format_docs","title":"format_docs","text":"<pre><code>format_docs(docs: list[Document]) -&gt; str\n</code></pre> <p>Format documents as documentation for including as context in a LLM query.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/format.py</code> <pre><code>def format_docs(docs: list[Document]) -&gt; str:\n    \"\"\"Format documents as documentation for including as context in a LLM query.\"\"\"\n    return \"\\n---\\n\".join(format_document(doc) for doc in docs)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.format_document","title":"format_document","text":"<pre><code>format_document(doc: Document, debug: bool = False) -&gt; str\n</code></pre> <p>Format a document as documentation for including as context in a LLM query.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/format.py</code> <pre><code>def format_document(doc: Document, debug: bool = False) -&gt; str:\n    \"\"\"Format a document as documentation for including as context in a LLM query.\"\"\"\n    metadata = doc.metadata\n    text = f\"{metadata['name']} ({metadata['kind']})\\n\\n\"\n\n    text += f\"path: \\n\\t{metadata['path']}\\n\\n\"\n\n    for key in [\"bases\", \"exports\", \"implemented_by\"]:\n        if key in metadata:\n            values = \"\\n\".join(metadata[key])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    if \"properties\" in metadata:\n        props = [f\"{k}: {v}\" for k, v in metadata[\"properties\"].items()]\n        values = \"\\n\".join(props)\n        text += f\"properties: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    if doc.page_content != \"\":\n        text += f\"description: \\n\\t{_add_tabs(doc.page_content)}\\n\\n\"\n    elif \"value\" in metadata:\n        text += f\"{metadata['value']}\\n\\n\"\n\n    for key in [\"attributes\", \"parameters\"]:\n        if key in metadata:\n            values = \"\\n\\n\".join([_format_parameter(v) for v in metadata[key]])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    for key in [\"returns\", \"yields\"]:\n        if key in metadata:\n            values = \"\\n\\n\".join([_format_return(v) for v in metadata[key]])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    for key in [\"note\", \"example\"]:\n        if key in metadata:\n            text += f\"{key}: \\n\\t{_add_tabs(metadata[key])}\\n\\n\"\n\n    if debug:\n        if \"imports\" in metadata:\n            imports = []\n            for as_name, real_name in metadata[\"imports\"].items():\n                if real_name == as_name:\n                    imports.append(real_name)\n                else:\n                    imports.append(f\"{real_name} as {as_name}\")\n            values = \"\\n\".join(imports)\n            text += f\"imports: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n        for key in [\"references\", \"gathered_types\"]:\n            if key in metadata:\n                values = \"\\n\".join(metadata[key])\n                text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n        if \"parent\" in metadata:\n            text += f\"parent: {metadata['parent']}\\n\\n\"\n\n    return text\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.converter","title":"converter","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.converter.convert","title":"convert","text":"<pre><code>convert(\n    package_name: str,\n    search_paths: list[str],\n    docstring_parser: DocstringStyle,\n    output_path: str,\n) -&gt; None\n</code></pre> <p>Load and convert a package's objects and documentation into a JSONL file.</p> <p>This method converts the internal documentation of modules, classes, functions, and attributes of a package into a format that is better suited for RAG (and GraphRAG in particular).</p> <p>The code uses the <code>griffe</code> library, which is a Python code analysis tool that extracts information from Python code and docstrings.</p> <p>The JSONL file contains one JSON object per line, with the following structure:     id: the path to the object in the package     text: the description of the object (if any, can be empty)     metadata: Always includes <code>name</code>, <code>path</code>, <code>kind</code> keys.               The remaining keys below are included when available.         name: the name of the object         path: the path to the object in the package         kind: either <code>module</code>, <code>class</code>, <code>function</code>, or <code>attribute</code>         parameters: the parameters for a class or function. Includes type             information, default values, and descriptions         attributes: the attributes on a class or module. Includes type             information and descriptions         gathered_types: list of non-standard types in the parameters and attributes         imports: list of non-standard types imported by the class or module         exports: list of non-standard types exported by the module         properties: list of boolean properties about the module         example: any code examples for the class, function, or module         references: list of any non-standard types used in the example code         returns: the return type and description         yields: the yield type and description         bases: list of base types inherited by the class         implemented_by: list of types that implement the a base class</p> PARAMETER DESCRIPTION <code>package_name</code> <p>The name of the package to convert.</p> <p> TYPE: <code>str</code> </p> <code>search_paths</code> <p>The paths to search for the package.</p> <p> TYPE: <code>list[str]</code> </p> <code>docstring_parser</code> <p>The docstring parser to use.</p> <p> TYPE: <code>DocstringStyle</code> </p> <code>output_path</code> <p>The path to save the JSONL file.</p> <p> TYPE: <code>str</code> </p> <p>Examples:</p> <p>from graph_rag_example_helpers.examples.code_generation.converter import convert convert(\"astrapy\", [\".venv/lib/python3.12/site-packages\"], \"google\", \"data\")</p> Notes <ul> <li>This code was written the <code>code-generation</code> example and <code>astrapy==1.5.2</code>. It will   probably need tweaking for use with other python packages. Use at your own risk.</li> </ul> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/converter.py</code> <pre><code>def convert(\n    package_name: str,\n    search_paths: list[str],\n    docstring_parser: griffe.DocstringStyle,\n    output_path: str,\n) -&gt; None:\n    \"\"\"\n    Load and convert a package's objects and documentation into a JSONL file.\n\n    This method converts the internal documentation of modules, classes, functions, and\n    attributes of a package into a format that is better suited for RAG (and GraphRAG\n    in particular).\n\n    The code uses the `griffe` library, which is a Python code analysis tool that\n    extracts information from Python code and docstrings.\n\n    The JSONL file contains one JSON object per line, with the following structure:\n        id: the path to the object in the package\n        text: the description of the object (if any, can be empty)\n        metadata: Always includes `name`, `path`, `kind` keys.\n                  The remaining keys below are included when available.\n            name: the name of the object\n            path: the path to the object in the package\n            kind: either `module`, `class`, `function`, or `attribute`\n            parameters: the parameters for a class or function. Includes type\n                information, default values, and descriptions\n            attributes: the attributes on a class or module. Includes type\n                information and descriptions\n            gathered_types: list of non-standard types in the parameters and attributes\n            imports: list of non-standard types imported by the class or module\n            exports: list of non-standard types exported by the module\n            properties: list of boolean properties about the module\n            example: any code examples for the class, function, or module\n            references: list of any non-standard types used in the example code\n            returns: the return type and description\n            yields: the yield type and description\n            bases: list of base types inherited by the class\n            implemented_by: list of types that implement the a base class\n\n\n    Parameters\n    ----------\n    package_name :\n        The name of the package to convert.\n    search_paths :\n        The paths to search for the package.\n    docstring_parser :\n        The docstring parser to use.\n    output_path :\n        The path to save the JSONL file.\n\n\n    Examples\n    --------\n    from graph_rag_example_helpers.examples.code_generation.converter import convert\n    convert(\"astrapy\", [\".venv/lib/python3.12/site-packages\"], \"google\", \"data\")\n\n\n    Notes\n    -----\n    - This code was written the `code-generation` example and `astrapy==1.5.2`. It will\n      probably need tweaking for use with other python packages. Use at your own risk.\n    \"\"\"\n    my_package = griffe.load(\n        package_name, search_paths=search_paths, docstring_parser=docstring_parser\n    )\n\n    converter = _Converter()\n    items = converter._convert(package_name, my_package)\n\n    with open(os.path.join(output_path, f\"{package_name}.jsonl\"), \"w\") as f:\n        for item in items:\n            text = item.pop(\"text\", \"\")\n            id = item.get(\"path\")\n            metadata = item\n            for key, value in metadata.items():\n                if isinstance(value, set):\n                    metadata[key] = list(value)\n            f.write(json.dumps({\"id\": id, \"text\": text, \"metadata\": metadata}))\n            f.write(\"\\n\")\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.format","title":"format","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.format.format_docs","title":"format_docs","text":"<pre><code>format_docs(docs: list[Document]) -&gt; str\n</code></pre> <p>Format documents as documentation for including as context in a LLM query.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/format.py</code> <pre><code>def format_docs(docs: list[Document]) -&gt; str:\n    \"\"\"Format documents as documentation for including as context in a LLM query.\"\"\"\n    return \"\\n---\\n\".join(format_document(doc) for doc in docs)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.examples.code_generation.format.format_document","title":"format_document","text":"<pre><code>format_document(doc: Document, debug: bool = False) -&gt; str\n</code></pre> <p>Format a document as documentation for including as context in a LLM query.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/examples/code_generation/format.py</code> <pre><code>def format_document(doc: Document, debug: bool = False) -&gt; str:\n    \"\"\"Format a document as documentation for including as context in a LLM query.\"\"\"\n    metadata = doc.metadata\n    text = f\"{metadata['name']} ({metadata['kind']})\\n\\n\"\n\n    text += f\"path: \\n\\t{metadata['path']}\\n\\n\"\n\n    for key in [\"bases\", \"exports\", \"implemented_by\"]:\n        if key in metadata:\n            values = \"\\n\".join(metadata[key])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    if \"properties\" in metadata:\n        props = [f\"{k}: {v}\" for k, v in metadata[\"properties\"].items()]\n        values = \"\\n\".join(props)\n        text += f\"properties: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    if doc.page_content != \"\":\n        text += f\"description: \\n\\t{_add_tabs(doc.page_content)}\\n\\n\"\n    elif \"value\" in metadata:\n        text += f\"{metadata['value']}\\n\\n\"\n\n    for key in [\"attributes\", \"parameters\"]:\n        if key in metadata:\n            values = \"\\n\\n\".join([_format_parameter(v) for v in metadata[key]])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    for key in [\"returns\", \"yields\"]:\n        if key in metadata:\n            values = \"\\n\\n\".join([_format_return(v) for v in metadata[key]])\n            text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n    for key in [\"note\", \"example\"]:\n        if key in metadata:\n            text += f\"{key}: \\n\\t{_add_tabs(metadata[key])}\\n\\n\"\n\n    if debug:\n        if \"imports\" in metadata:\n            imports = []\n            for as_name, real_name in metadata[\"imports\"].items():\n                if real_name == as_name:\n                    imports.append(real_name)\n                else:\n                    imports.append(f\"{real_name} as {as_name}\")\n            values = \"\\n\".join(imports)\n            text += f\"imports: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n        for key in [\"references\", \"gathered_types\"]:\n            if key in metadata:\n                values = \"\\n\".join(metadata[key])\n                text += f\"{key}: \\n\\t{_add_tabs(values)}\\n\\n\"\n\n        if \"parent\" in metadata:\n            text += f\"parent: {metadata['parent']}\\n\\n\"\n\n    return text\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration","title":"persistent_iteration","text":""},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.Offset","title":"Offset  <code>dataclass</code>","text":"<pre><code>Offset(index: int)\n</code></pre> <p>Class for tracking a position in the iteraiton.</p>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration","title":"PersistentIteration","text":"<pre><code>PersistentIteration(\n    journal_name: str, iterator: Iterator[T]\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Create a persistent iteration.</p> <p>This creates a journal file with the name <code>journal_name</code> containing the indices of completed items. When resuming iteration, the already processed indices will be skipped.</p> PARAMETER DESCRIPTION <code>journal_name</code> <p>Name of the journal file to use. If it doesn't exist it will be created. The indices of completed items will be written to the journal.</p> <p> TYPE: <code>str</code> </p> <code>iterator</code> <p>The iterator to process persistently. It must be deterministic -- elements should always be returned in the same order on restarts.</p> <p> TYPE: <code>Iterator[T]</code> </p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def __init__(self, journal_name: str, iterator: Iterator[T]) -&gt; None:\n    self.iterator = enumerate(iterator)\n    self.pending: dict[Offset, T] = {}\n\n    self._completed = set()\n    try:\n        read_journal = open(journal_name)\n        for line in read_journal:\n            self._completed.add(Offset(index=int(line)))\n    except FileNotFoundError:\n        pass\n\n    self._write_journal = open(journal_name, \"a\")\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[tuple[Offset, T]]\n</code></pre> <p>Iterate over pairs of offsets and elements.</p> RETURNS DESCRIPTION <code>Iterator[tuple[Offset, T]]</code> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def __iter__(self) -&gt; Iterator[tuple[Offset, T]]:\n    \"\"\"\n    Iterate over pairs of offsets and elements.\n\n    Returns\n    -------\n    :\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration.__next__","title":"__next__","text":"<pre><code>__next__() -&gt; tuple[Offset, T]\n</code></pre> <p>Return the next offset and item.</p> RETURNS DESCRIPTION <code>offset</code> <p>The offset of the next item. Should be acknowledge after the item is finished processing.</p> <p> TYPE: <code>Offset</code> </p> <code>item</code> <p>The next item.</p> <p> TYPE: <code>T</code> </p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def __next__(self) -&gt; tuple[Offset, T]:\n    \"\"\"\n    Return the next offset and item.\n\n    Returns\n    -------\n    offset :\n        The offset of the next item. Should be acknowledge after the item\n        is finished processing.\n    item :\n        The next item.\n    \"\"\"\n    index, item = next(self.iterator)\n    offset = Offset(index)\n\n    while offset in self._completed:\n        index, item = next(self.iterator)\n        offset = Offset(index)\n\n    self.pending[offset] = item\n    return (offset, item)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration.ack","title":"ack","text":"<pre><code>ack(offset: Offset) -&gt; int\n</code></pre> <p>Acknowledge the given offset.</p> <p>This should only be called after the elements in that offset have been persisted.</p> PARAMETER DESCRIPTION <code>offset</code> <p>The offset to acknowledge.</p> <p> TYPE: <code>Offset</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The numebr of pending elements.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def ack(self, offset: Offset) -&gt; int:\n    \"\"\"\n    Acknowledge the given offset.\n\n    This should only be called after the elements in that offset have been\n    persisted.\n\n    Parameters\n    ----------\n    offset :\n        The offset to acknowledge.\n\n    Returns\n    -------\n    :\n        The numebr of pending elements.\n    \"\"\"\n    self._write_journal.write(f\"{offset.index}\\n\")\n    self._write_journal.flush()\n    self._completed.add(offset)\n\n    self.pending.pop(offset)\n    return len(self.pending)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration.completed_count","title":"completed_count","text":"<pre><code>completed_count() -&gt; int\n</code></pre> <p>Return the numebr of completed elements.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of completed elements.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def completed_count(self) -&gt; int:\n    \"\"\"\n    Return the numebr of completed elements.\n\n    Returns\n    -------\n    :\n        The number of completed elements.\n    \"\"\"\n    return len(self._completed)\n</code></pre>"},{"location":"reference/graph_rag_example_helpers/#graph_rag_example_helpers.persistent_iteration.PersistentIteration.pending_count","title":"pending_count","text":"<pre><code>pending_count() -&gt; int\n</code></pre> <p>Return the number of pending (not processed) elements.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of pending elements.</p> Source code in <code>packages/graph-rag-example-helpers/src/graph_rag_example_helpers/persistent_iteration.py</code> <pre><code>def pending_count(self) -&gt; int:\n    \"\"\"\n    Return the number of pending (not processed) elements.\n\n    Returns\n    -------\n    :\n        The number of pending elements.\n    \"\"\"\n    return len(self.pending)\n</code></pre>"},{"location":"reference/graph_retriever/","title":"graph_retriever","text":"<p>Provides retrieval functions combining vector and graph traversal.</p> <p>The main methods are <code>traverse</code> and <code>atraverse</code> which provide synchronous and asynchronous traversals.</p>"},{"location":"reference/graph_retriever/#graph_retriever.Content","title":"Content  <code>dataclass</code>","text":"<pre><code>Content(\n    id: str,\n    content: str,\n    embedding: list[float],\n    metadata: dict[str, Any] = dict(),\n    mime_type: str = \"text/plain\",\n)\n</code></pre> <p>Model representing retrieved content.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the content.</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>The content.</p> <p> TYPE: <code>str</code> </p> <code>embedding</code> <p>The embedding of the content.</p> <p> TYPE: <code>list[float]</code> </p> <code>metadata</code> <p>The metadata associated with the content.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p> <code>mime_type</code> <p>The MIME type of the content.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'text/plain'</code> </p>"},{"location":"reference/graph_retriever/#graph_retriever.Content.new","title":"new  <code>staticmethod</code>","text":"<pre><code>new(\n    id: str,\n    content: str,\n    embedding: list[float] | Callable[[str], list[float]],\n    *,\n    metadata: dict[str, Any] | None = None,\n    mime_type: str = \"text/plain\",\n) -&gt; Content\n</code></pre> <p>Create a new content.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the content.</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>The content.</p> <p> TYPE: <code>str</code> </p> <code>embedding</code> <p>The embedding, or a function to apply to the content to compute the embedding.</p> <p> TYPE: <code>list[float] | Callable[[str], list[float]]</code> </p> <code>metadata</code> <p>The metadata associated with the content.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>mime_type</code> <p>The MIME type of the content.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'text/plain'</code> </p> RETURNS DESCRIPTION <code>Content</code> <p>The created content.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/content.py</code> <pre><code>@staticmethod\ndef new(\n    id: str,\n    content: str,\n    embedding: list[float] | Callable[[str], list[float]],\n    *,\n    metadata: dict[str, Any] | None = None,\n    mime_type: str = \"text/plain\",\n) -&gt; Content:\n    \"\"\"\n    Create a new content.\n\n    Parameters\n    ----------\n    id :\n        The ID of the content.\n    content :\n        The content.\n    embedding :\n        The embedding, or a function to apply to the content to compute the\n        embedding.\n    metadata :\n        The metadata associated with the content.\n    mime_type :\n        The MIME type of the content.\n\n    Returns\n    -------\n    :\n        The created content.\n    \"\"\"\n    return Content(\n        id=id,\n        content=content,\n        embedding=embedding(content) if callable(embedding) else embedding,\n        metadata=metadata or {},\n        mime_type=mime_type,\n    )\n</code></pre>"},{"location":"reference/graph_retriever/#graph_retriever.Node","title":"Node  <code>dataclass</code>","text":"<pre><code>Node(\n    id: str,\n    content: str,\n    depth: int,\n    similarity_score: float,\n    embedding: list[float],\n    metadata: dict[str, Any] = dict(),\n    incoming_edges: set[Edge] = set(),\n    outgoing_edges: set[Edge] = set(),\n    extra_metadata: dict[str, Any] = dict(),\n)\n</code></pre> <p>Represents a node in the traversal graph.</p> <p>The Node class contains information about a document during graph traversal, including its depth, embedding, edges, and metadata.</p> PARAMETER DESCRIPTION <code>id</code> <p>The unique identifier of the document represented by this node.</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>The content.</p> <p> TYPE: <code>str</code> </p> <code>depth</code> <p>The depth (number of edges) through which this node was discovered. This depth may not reflect the true depth in the full graph if only a subset of edges is retrieved.</p> <p> TYPE: <code>int</code> </p> <code>embedding</code> <p>The embedding vector of the document, used for similarity calculations.</p> <p> TYPE: <code>list[float]</code> </p> <code>metadata</code> <p>Metadata from the original document. This is a reference to the original document metadata and should not be modified directly. Any updates to metadata should be made to <code>extra_metadata</code>.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p> <code>extra_metadata</code> <p>Additional metadata to override or augment the original document metadata during traversal.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>dict()</code> </p>"},{"location":"reference/graph_retriever/#graph_retriever.atraverse","title":"atraverse  <code>async</code>","text":"<pre><code>atraverse(\n    query: str,\n    *,\n    edges: list[EdgeSpec] | EdgeFunction,\n    strategy: Strategy,\n    store: Adapter,\n    metadata_filter: dict[str, Any] | None = None,\n    initial_root_ids: Sequence[str] = (),\n    store_kwargs: dict[str, Any] = {},\n) -&gt; list[Node]\n</code></pre> <p>Asynchronously perform a graph traversal to retrieve nodes for a specific query.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query string for the traversal.</p> <p> TYPE: <code>str</code> </p> <code>edges</code> <p>A list of EdgeSpec for use in creating a MetadataEdgeFunction, or an EdgeFunction.</p> <p> TYPE: <code>list[EdgeSpec] | EdgeFunction</code> </p> <code>strategy</code> <p>The traversal strategy that defines how nodes are discovered, selected, and finalized.</p> <p> TYPE: <code>Strategy</code> </p> <code>store</code> <p>The vector store adapter used for similarity searches and document retrieval.</p> <p> TYPE: <code>Adapter</code> </p> <code>metadata_filter</code> <p>Optional filter for metadata during traversal.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>initial_root_ids</code> <p>IDs of the initial root nodes for the traversal.</p> <p> TYPE: <code>Sequence[str]</code> DEFAULT: <code>()</code> </p> <code>store_kwargs</code> <p>Additional arguments passed to the store adapter.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Node]</code> <p>Nodes returned by the traversal.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/traversal.py</code> <pre><code>async def atraverse(\n    query: str,\n    *,\n    edges: list[EdgeSpec] | EdgeFunction,\n    strategy: Strategy,\n    store: Adapter,\n    metadata_filter: dict[str, Any] | None = None,\n    initial_root_ids: Sequence[str] = (),\n    store_kwargs: dict[str, Any] = {},\n) -&gt; list[Node]:\n    \"\"\"\n    Asynchronously perform a graph traversal to retrieve nodes for a specific query.\n\n    Parameters\n    ----------\n    query :\n        The query string for the traversal.\n    edges :\n        A list of [EdgeSpec][graph_retriever.edges.EdgeSpec] for use in creating a\n        [MetadataEdgeFunction][graph_retriever.edges.MetadataEdgeFunction],\n        or an [EdgeFunction][graph_retriever.edges.EdgeFunction].\n    strategy :\n        The traversal strategy that defines how nodes are discovered, selected,\n        and finalized.\n    store :\n        The vector store adapter used for similarity searches and document\n        retrieval.\n    metadata_filter :\n        Optional filter for metadata during traversal.\n    initial_root_ids :\n        IDs of the initial root nodes for the traversal.\n    store_kwargs :\n        Additional arguments passed to the store adapter.\n\n    Returns\n    -------\n    :\n        Nodes returned by the traversal.\n    \"\"\"\n    traversal = _Traversal(\n        query=query,\n        edges=edges,\n        strategy=copy.deepcopy(strategy),\n        store=store,\n        metadata_filter=metadata_filter,\n        initial_root_ids=initial_root_ids,\n        store_kwargs=store_kwargs,\n    )\n    return await traversal.atraverse()\n</code></pre>"},{"location":"reference/graph_retriever/#graph_retriever.traverse","title":"traverse","text":"<pre><code>traverse(\n    query: str,\n    *,\n    edges: list[EdgeSpec] | EdgeFunction,\n    strategy: Strategy,\n    store: Adapter,\n    metadata_filter: dict[str, Any] | None = None,\n    initial_root_ids: Sequence[str] = (),\n    store_kwargs: dict[str, Any] = {},\n) -&gt; list[Node]\n</code></pre> <p>Perform a graph traversal to retrieve nodes for a specific query.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query string for the traversal.</p> <p> TYPE: <code>str</code> </p> <code>edges</code> <p>A list of EdgeSpec for use in creating a MetadataEdgeFunction, or an EdgeFunction.</p> <p> TYPE: <code>list[EdgeSpec] | EdgeFunction</code> </p> <code>strategy</code> <p>The traversal strategy that defines how nodes are discovered, selected, and finalized.</p> <p> TYPE: <code>Strategy</code> </p> <code>store</code> <p>The vector store adapter used for similarity searches and document retrieval.</p> <p> TYPE: <code>Adapter</code> </p> <code>metadata_filter</code> <p>Optional filter for metadata during traversal.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>initial_root_ids</code> <p>IDs of the initial root nodes for the traversal.</p> <p> TYPE: <code>Sequence[str]</code> DEFAULT: <code>()</code> </p> <code>store_kwargs</code> <p>Additional arguments passed to the store adapter.</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Node]</code> <p>Nodes returned by the traversal.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/traversal.py</code> <pre><code>def traverse(\n    query: str,\n    *,\n    edges: list[EdgeSpec] | EdgeFunction,\n    strategy: Strategy,\n    store: Adapter,\n    metadata_filter: dict[str, Any] | None = None,\n    initial_root_ids: Sequence[str] = (),\n    store_kwargs: dict[str, Any] = {},\n) -&gt; list[Node]:\n    \"\"\"\n    Perform a graph traversal to retrieve nodes for a specific query.\n\n    Parameters\n    ----------\n    query :\n        The query string for the traversal.\n    edges :\n        A list of [EdgeSpec][graph_retriever.edges.EdgeSpec] for use in creating a\n        [MetadataEdgeFunction][graph_retriever.edges.MetadataEdgeFunction],\n        or an [EdgeFunction][graph_retriever.edges.EdgeFunction].\n    strategy :\n        The traversal strategy that defines how nodes are discovered, selected,\n        and finalized.\n    store :\n        The vector store adapter used for similarity searches and document\n        retrieval.\n    metadata_filter :\n        Optional filter for metadata during traversal.\n    initial_root_ids :\n        IDs of the initial root nodes for the traversal.\n    store_kwargs :\n        Additional arguments passed to the store adapter.\n\n    Returns\n    -------\n    :\n        Nodes returned by the traversal.\n    \"\"\"\n    traversal = _Traversal(\n        query=query,\n        edges=edges,\n        strategy=copy.deepcopy(strategy),\n        store=store,\n        metadata_filter=metadata_filter,\n        initial_root_ids=initial_root_ids,\n        store_kwargs=store_kwargs,\n    )\n    return traversal.traverse()\n</code></pre>"},{"location":"reference/graph_retriever/adapters/","title":"graph_retriever.adapters","text":""},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter","title":"Adapter","text":"<pre><code>Adapter()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base adapter for integrating vector stores with the graph retriever system.</p> <p>This class provides a foundation for custom adapters, enabling consistent interaction with various vector store implementations.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def __init__(self) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Asynchronously get content items by ID.\n\n    Fewer content items may be returned than requested if some IDs are\n    not found or if there are duplicated IDs. This method should **NOT**\n    raise exceptions if no content items are found for some IDs.\n\n    Users should not assume that the order of the returned content items\n    matches  the order of the input IDs. Instead, users should rely on\n    the ID field of the returned content items.\n\n    Parameters\n    ----------\n    ids :\n        List of IDs to get.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments. These are up to the implementation.\n\n    Returns\n    -------\n    :\n        List of content items that were found.\n    \"\"\"\n    return await run_in_executor(\n        None,\n        self.get,\n        ids,\n        filter,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Asynchronously return content items most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        Number of content items to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of content items most similar to the query vector.\n    \"\"\"\n    return await run_in_executor(\n        None,\n        self.search,\n        embedding,\n        k,\n        filter,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    \"\"\"\n    Asynchronously return content items most similar to the query.\n\n    Also returns the embedded query vector.\n\n    Parameters\n    ----------\n    query :\n        Input text.\n    k :\n        Number of content items to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    contents :\n        List of up to `k` content items most similar to the query\n        vector.\n    \"\"\"\n    return await run_in_executor(\n        None, self.search_with_embedding, query, k, filter, **kwargs\n    )\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.get","title":"get  <code>abstractmethod</code>","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>@abc.abstractmethod\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Get content items by ID.\n\n    Fewer content items may be returned than requested if some IDs are\n    not found or if there are duplicated IDs. This method should **NOT**\n    raise exceptions if no content items are found for some IDs.\n\n    Users should not assume that the order of the returned content items\n    matches  the order of the input IDs. Instead, users should rely on\n    the ID field of the returned content items.\n\n    Parameters\n    ----------\n    ids :\n        List of IDs to get.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments. These are up to the implementation.\n\n    Returns\n    -------\n    :\n        List of content items that were found.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.search","title":"search  <code>abstractmethod</code>","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>@abc.abstractmethod\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return content items most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        Number of content items to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of content items most similar to the query vector.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/graph_retriever/adapters/#graph_retriever.adapters.Adapter.search_with_embedding","title":"search_with_embedding  <code>abstractmethod</code>","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>@abc.abstractmethod\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    \"\"\"\n    Return content items most similar to the query.\n\n    Also returns the embedded query vector.\n\n    Parameters\n    ----------\n    query :\n        Input text.\n    k :\n        Number of content items to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    contents :\n        List of up to `k` content items most similar to the query vector.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/graph_retriever/edges/","title":"graph_retriever.edges","text":"<p>Specification and implementation of edges functions.</p> <p>These are responsible for extracting edges from nodes and expressing them in way that the adapters can implement.</p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.EdgeFunction","title":"EdgeFunction  <code>module-attribute</code>","text":"<pre><code>EdgeFunction: TypeAlias = Callable[[Content], Edges]\n</code></pre> <p>A function for extracting edges from nodes.</p> <p>Implementations should be deterministic.</p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.EdgeSpec","title":"EdgeSpec  <code>module-attribute</code>","text":"<pre><code>EdgeSpec: TypeAlias = tuple[str | Id, str | Id]\n</code></pre> <p>The definition of an edge for traversal, represented as a pair of fields representing the source and target of the edge. Each may be:</p> <ul> <li>A string, <code>key</code>, indicating <code>doc.metadata[key]</code> as the value.</li> <li>The magic string <code>\"$id\"</code>, indicating <code>doc.id</code> as the value.</li> </ul> <p>Examples:</p> <pre><code>url_to_href_edge          = (\"url\", \"href\")\nkeywords_to_keywords_edge = (\"keywords\", \"keywords\")\nmentions_to_id_edge       = (\"mentions\", \"$id\")\nid_to_mentions_edge       = (\"$id\", \"mentions)\n</code></pre>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.Edge","title":"Edge","text":"<p>               Bases: <code>ABC</code></p> <p>An edge identifies properties necessary for finding matching nodes.</p> <p>Sub-classes should be hashable.</p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.Edges","title":"Edges  <code>dataclass</code>","text":"<pre><code>Edges(incoming: set[Edge], outgoing: set[Edge])\n</code></pre> <p>Information about the incoming and outgoing edges.</p> PARAMETER DESCRIPTION <code>incoming</code> <p>Incoming edges that link to this node.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>outgoing</code> <p>Edges that this node link to. These edges should be defined in terms of the incoming <code>Edge</code> they match. For instance, a link from \"mentions\" to \"id\" would link to <code>IdEdge(...)</code>.</p> <p> TYPE: <code>set[Edge]</code> </p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.Id","title":"Id","text":"<p>Place-holder type indicating that the ID should be used.</p> <p>Deprecated: Use \"$id\" instead.</p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.IdEdge","title":"IdEdge  <code>dataclass</code>","text":"<pre><code>IdEdge(id: str)\n</code></pre> <p>               Bases: <code>Edge</code></p> <p>An <code>IdEdge</code> connects to nodes with <code>node.id == id</code>.</p> PARAMETER DESCRIPTION <code>id</code> <p>The ID of the node to link to.</p> <p> TYPE: <code>str</code> </p>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.MetadataEdge","title":"MetadataEdge  <code>dataclass</code>","text":"<pre><code>MetadataEdge(incoming_field: str, value: Any)\n</code></pre> <p>               Bases: <code>Edge</code></p> <p>Link to nodes with specific metadata.</p> <p>A <code>MetadataEdge</code> connects to nodes with either:</p> <ul> <li><code>node.metadata[field] == value</code></li> <li><code>node.metadata[field] CONTAINS value</code> (if the metadata is a collection).</li> </ul> PARAMETER DESCRIPTION <code>incoming_field</code> <p>The name of the metadata field storing incoming edges.</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>The value associated with the key for this edge</p> <p> TYPE: <code>Any</code> </p> Source code in <code>packages/graph-retriever/src/graph_retriever/edges/_base.py</code> <pre><code>def __init__(self, incoming_field: str, value: Any) -&gt; None:\n    # `self.field = value` and `setattr(self, \"field\", value)` -- don't work\n    # because of frozen. we need to call `__setattr__` directly (as the\n    # default `__init__` would do) to initialize the fields of the frozen\n    # dataclass.\n    object.__setattr__(self, \"incoming_field\", incoming_field)\n\n    if isinstance(value, dict):\n        value = immutabledict(value)\n    object.__setattr__(self, \"value\", value)\n</code></pre>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.MetadataEdgeFunction","title":"MetadataEdgeFunction","text":"<pre><code>MetadataEdgeFunction(edges: list[EdgeSpec])\n</code></pre> <p>Helper for extracting and encoding edges in metadata.</p> <p>This class provides tools to extract incoming and outgoing edges from document metadata. Both incoming and outgoing edges use the same target name, enabling equality matching for keys.</p> PARAMETER DESCRIPTION <code>edges</code> <p>Definitions of edges for traversal, represented as a pair of fields representing the source and target of the edges.</p> <p> TYPE: <code>list[EdgeSpec]</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If an invalid edge definition is provided.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/edges/metadata.py</code> <pre><code>def __init__(\n    self,\n    edges: list[EdgeSpec],\n) -&gt; None:\n    self.edges = edges\n    for source, target in edges:\n        if not isinstance(source, str | Id):\n            raise ValueError(f\"Expected 'str | Id' but got: {source}\")\n        if not isinstance(target, str | Id):\n            raise ValueError(f\"Expected 'str | Id' but got: {target}\")\n</code></pre>"},{"location":"reference/graph_retriever/edges/#graph_retriever.edges.MetadataEdgeFunction.__call__","title":"__call__","text":"<pre><code>__call__(content: Content) -&gt; Edges\n</code></pre> <p>Extract incoming and outgoing edges for a piece of content.</p> <p>This method retrieves edges based on the declared edge definitions, taking into account whether nested metadata is used.</p> PARAMETER DESCRIPTION <code>content</code> <p>The content to extract edges from.</p> <p> TYPE: <code>Content</code> </p> RETURNS DESCRIPTION <code>Edges</code> <p>the incoming and outgoing edges of the node</p> Source code in <code>packages/graph-retriever/src/graph_retriever/edges/metadata.py</code> <pre><code>def __call__(self, content: Content) -&gt; Edges:\n    \"\"\"\n    Extract incoming and outgoing edges for a piece of content.\n\n    This method retrieves edges based on the declared edge definitions, taking\n    into account whether nested metadata is used.\n\n    Parameters\n    ----------\n    content :\n        The content to extract edges from.\n\n    Returns\n    -------\n    :\n        the incoming and outgoing edges of the node\n    \"\"\"\n    outgoing_edges = self._edges_from_dict(content.id, content.metadata)\n    incoming_edges = self._edges_from_dict(\n        content.id, content.metadata, incoming=True\n    )\n\n    return Edges(incoming=incoming_edges, outgoing=outgoing_edges)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/","title":"graph_retriever.strategies","text":"<p>Strategies determine which nodes are selected during traversal.</p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Eager","title":"Eager  <code>dataclass</code>","text":"<pre><code>Eager(\n    *,\n    select_k: int = DEFAULT_SELECT_K,\n    start_k: int = 4,\n    adjacent_k: int = 10,\n    max_traverse: int | None = None,\n    max_depth: int | None = None,\n    k: int = DEFAULT_SELECT_K,\n    _query_embedding: list[float] = list(),\n)\n</code></pre> <p>               Bases: <code>Strategy</code></p> <p>Eager traversal strategy (breadth-first).</p> <p>This strategy selects all discovered nodes at each traversal step. It ensures breadth-first traversal by processing nodes layer by layer, which is useful for scenarios where all nodes at the current depth should be explored before proceeding to the next depth.</p> PARAMETER DESCRIPTION <code>select_k</code> <p>Maximum number of nodes to retrieve during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p> <code>start_k</code> <p>Number of documents to fetch via similarity for starting the traversal. Added to any initial roots provided to the traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>adjacent_k</code> <p>Number of documents to fetch for each outgoing edge.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_depth</code> <p>Maximum traversal depth. If <code>None</code>, there is no limit.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>k</code> <p>Deprecated: Use <code>select_k</code> instead. Maximum number of nodes to select and return during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Eager.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Allow passing the deprecated 'k' value instead of 'select_k'.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Allow passing the deprecated 'k' value instead of 'select_k'.\"\"\"\n    if self.select_k == DEFAULT_SELECT_K and self.k != DEFAULT_SELECT_K:\n        self.select_k = self.k\n    else:\n        self.k = self.select_k\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Eager.build","title":"build  <code>staticmethod</code>","text":"<pre><code>build(base_strategy: Strategy, **kwargs: Any) -&gt; Strategy\n</code></pre> <p>Build a strategy for a retrieval operation.</p> <p>Combines a base strategy with any provided keyword arguments to create a customized traversal strategy.</p> PARAMETER DESCRIPTION <code>base_strategy</code> <p>The base strategy to start with.</p> <p> TYPE: <code>Strategy</code> </p> <code>kwargs</code> <p>Additional configuration options for the strategy.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Strategy</code> <p>A configured strategy instance.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If 'strategy' is set incorrectly or extra arguments are invalid.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>@staticmethod\ndef build(\n    base_strategy: Strategy,\n    **kwargs: Any,\n) -&gt; Strategy:\n    \"\"\"\n    Build a strategy for a retrieval operation.\n\n    Combines a base strategy with any provided keyword arguments to\n    create a customized traversal strategy.\n\n    Parameters\n    ----------\n    base_strategy :\n        The base strategy to start with.\n    kwargs :\n        Additional configuration options for the strategy.\n\n    Returns\n    -------\n    :\n        A configured strategy instance.\n\n    Raises\n    ------\n    ValueError\n        If 'strategy' is set incorrectly or extra arguments are invalid.\n    \"\"\"\n    # Check if there is a new strategy to use. Otherwise, use the base.\n    strategy: Strategy\n    if \"strategy\" in kwargs:\n        if next(iter(kwargs.keys())) != \"strategy\":\n            raise ValueError(\"Error: 'strategy' must be set before other args.\")\n        strategy = kwargs.pop(\"strategy\")\n        if not isinstance(strategy, Strategy):\n            raise ValueError(\n                f\"Unsupported 'strategy' type {type(strategy).__name__}.\"\n                \" Must be a sub-class of Strategy\"\n            )\n    elif base_strategy is not None:\n        strategy = base_strategy\n    else:\n        raise ValueError(\"'strategy' must be set in `__init__` or invocation\")\n\n    # Apply the kwargs to update the strategy.\n    assert strategy is not None\n    if \"k\" in kwargs:\n        kwargs[\"select_k\"] = kwargs.pop(\"k\")\n    strategy = dataclasses.replace(strategy, **kwargs)\n\n    return strategy\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Eager.finalize_nodes","title":"finalize_nodes","text":"<pre><code>finalize_nodes(selected: Iterable[Node]) -&gt; Iterable[Node]\n</code></pre> <p>Finalize the selected nodes.</p> <p>This method is called before returning the final set of nodes. It allows the strategy to perform any final processing or re-ranking of the selected nodes.</p> PARAMETER DESCRIPTION <code>selected</code> <p>The selected nodes to be finalized</p> <p> TYPE: <code>Iterable[Node]</code> </p> RETURNS DESCRIPTION <code>Iterable[Node]</code> <p>Finalized nodes.</p> Notes <ul> <li>The default implementation returns the first <code>self.select_k</code> selected nodes without any additional processing.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def finalize_nodes(self, selected: Iterable[Node]) -&gt; Iterable[Node]:\n    \"\"\"\n    Finalize the selected nodes.\n\n    This method is called before returning the final set of nodes. It allows\n    the strategy to perform any final processing or re-ranking of the selected\n    nodes.\n\n    Parameters\n    ----------\n    selected :\n        The selected nodes to be finalized\n\n    Returns\n    -------\n    :\n        Finalized nodes.\n\n    Notes\n    -----\n    - The default implementation returns the first `self.select_k` selected nodes\n    without any additional processing.\n    \"\"\"\n    return list(selected)[: self.select_k]\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Eager.iteration","title":"iteration","text":"<pre><code>iteration(\n    nodes: Iterable[Node], tracker: NodeTracker\n) -&gt; None\n</code></pre> <p>Process the newly discovered nodes on each iteration.</p> <p>This method should call <code>tracker.traverse()</code> and/or <code>tracker.select()</code> as appropriate to update the nodes that need to be traversed in this iteration or selected at the end of the retrieval, respectively.</p> PARAMETER DESCRIPTION <code>nodes</code> <p>The newly discovered nodes found from either: - the initial vector store retrieval - incoming edges from nodes chosen for traversal in the previous iteration</p> <p> TYPE: <code>Iterable[Node]</code> </p> <code>tracker</code> <p>The tracker object to manage the traversal and selection of nodes.</p> <p> TYPE: <code>NodeTracker</code> </p> Notes <ul> <li>This method is called once for each iteration of the traversal.</li> <li>In order to stop iterating either choose to not traverse any additional nodes or don't select any additional nodes for output.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/eager.py</code> <pre><code>@override\ndef iteration(self, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:\n    tracker.select_and_traverse(nodes)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr","title":"Mmr  <code>dataclass</code>","text":"<pre><code>Mmr(\n    lambda_mult: float = 0.5,\n    min_mmr_score: float = NEG_INF,\n    _selected_ids: list[str] = list(),\n    _candidate_id_to_index: dict[str, int] = dict(),\n    _candidates: list[_MmrCandidate] = list(),\n    _best_score: float = NEG_INF,\n    _best_id: str | None = None,\n    *,\n    select_k: int = DEFAULT_SELECT_K,\n    start_k: int = 4,\n    adjacent_k: int = 10,\n    max_traverse: int | None = None,\n    max_depth: int | None = None,\n    k: int = DEFAULT_SELECT_K,\n    _query_embedding: list[float] = list(),\n)\n</code></pre> <p>               Bases: <code>Strategy</code></p> <p>Maximal Marginal Relevance (MMR) traversal strategy.</p> <p>This strategy selects nodes by balancing relevance to the query and diversity among the results. It uses a <code>lambda_mult</code> parameter to control the trade-off between relevance and redundancy. Nodes are scored based on their similarity to the query and their distance from already selected nodes.</p> PARAMETER DESCRIPTION <code>select_k</code> <p>Maximum number of nodes to retrieve during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p> <code>start_k</code> <p>Number of documents to fetch via similarity for starting the traversal. Added to any initial roots provided to the traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>adjacent_k</code> <p>Number of documents to fetch for each outgoing edge.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_depth</code> <p>Maximum traversal depth. If <code>None</code>, there is no limit.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>lambda_mult</code> <p>Controls the trade-off between relevance and diversity. A value closer to 1 prioritizes relevance, while a value closer to 0 prioritizes diversity. Must be between 0 and 1 (inclusive).</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.5</code> </p> <code>min_mmr_score</code> <p>Only nodes with a score greater than or equal to this value will be selected.</p> <p> TYPE: <code>float</code> DEFAULT: <code>NEG_INF</code> </p> <code>k</code> <p>Deprecated: Use <code>select_k</code> instead. Maximum number of nodes to select and return during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Allow passing the deprecated 'k' value instead of 'select_k'.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Allow passing the deprecated 'k' value instead of 'select_k'.\"\"\"\n    if self.select_k == DEFAULT_SELECT_K and self.k != DEFAULT_SELECT_K:\n        self.select_k = self.k\n    else:\n        self.k = self.select_k\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr.build","title":"build  <code>staticmethod</code>","text":"<pre><code>build(base_strategy: Strategy, **kwargs: Any) -&gt; Strategy\n</code></pre> <p>Build a strategy for a retrieval operation.</p> <p>Combines a base strategy with any provided keyword arguments to create a customized traversal strategy.</p> PARAMETER DESCRIPTION <code>base_strategy</code> <p>The base strategy to start with.</p> <p> TYPE: <code>Strategy</code> </p> <code>kwargs</code> <p>Additional configuration options for the strategy.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Strategy</code> <p>A configured strategy instance.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If 'strategy' is set incorrectly or extra arguments are invalid.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>@staticmethod\ndef build(\n    base_strategy: Strategy,\n    **kwargs: Any,\n) -&gt; Strategy:\n    \"\"\"\n    Build a strategy for a retrieval operation.\n\n    Combines a base strategy with any provided keyword arguments to\n    create a customized traversal strategy.\n\n    Parameters\n    ----------\n    base_strategy :\n        The base strategy to start with.\n    kwargs :\n        Additional configuration options for the strategy.\n\n    Returns\n    -------\n    :\n        A configured strategy instance.\n\n    Raises\n    ------\n    ValueError\n        If 'strategy' is set incorrectly or extra arguments are invalid.\n    \"\"\"\n    # Check if there is a new strategy to use. Otherwise, use the base.\n    strategy: Strategy\n    if \"strategy\" in kwargs:\n        if next(iter(kwargs.keys())) != \"strategy\":\n            raise ValueError(\"Error: 'strategy' must be set before other args.\")\n        strategy = kwargs.pop(\"strategy\")\n        if not isinstance(strategy, Strategy):\n            raise ValueError(\n                f\"Unsupported 'strategy' type {type(strategy).__name__}.\"\n                \" Must be a sub-class of Strategy\"\n            )\n    elif base_strategy is not None:\n        strategy = base_strategy\n    else:\n        raise ValueError(\"'strategy' must be set in `__init__` or invocation\")\n\n    # Apply the kwargs to update the strategy.\n    assert strategy is not None\n    if \"k\" in kwargs:\n        kwargs[\"select_k\"] = kwargs.pop(\"k\")\n    strategy = dataclasses.replace(strategy, **kwargs)\n\n    return strategy\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr.candidate_ids","title":"candidate_ids","text":"<pre><code>candidate_ids() -&gt; Iterable[str]\n</code></pre> <p>Return the IDs of the candidates.</p> RETURNS DESCRIPTION <code>Iterable[str]</code> <p>The IDs of the candidates.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/mmr.py</code> <pre><code>def candidate_ids(self) -&gt; Iterable[str]:\n    \"\"\"\n    Return the IDs of the candidates.\n\n    Returns\n    -------\n    Iterable[str]\n        The IDs of the candidates.\n    \"\"\"\n    return self._candidate_id_to_index.keys()\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr.finalize_nodes","title":"finalize_nodes","text":"<pre><code>finalize_nodes(selected: Iterable[Node]) -&gt; Iterable[Node]\n</code></pre> <p>Finalize the selected nodes.</p> <p>This method is called before returning the final set of nodes. It allows the strategy to perform any final processing or re-ranking of the selected nodes.</p> PARAMETER DESCRIPTION <code>selected</code> <p>The selected nodes to be finalized</p> <p> TYPE: <code>Iterable[Node]</code> </p> RETURNS DESCRIPTION <code>Iterable[Node]</code> <p>Finalized nodes.</p> Notes <ul> <li>The default implementation returns the first <code>self.select_k</code> selected nodes without any additional processing.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def finalize_nodes(self, selected: Iterable[Node]) -&gt; Iterable[Node]:\n    \"\"\"\n    Finalize the selected nodes.\n\n    This method is called before returning the final set of nodes. It allows\n    the strategy to perform any final processing or re-ranking of the selected\n    nodes.\n\n    Parameters\n    ----------\n    selected :\n        The selected nodes to be finalized\n\n    Returns\n    -------\n    :\n        Finalized nodes.\n\n    Notes\n    -----\n    - The default implementation returns the first `self.select_k` selected nodes\n    without any additional processing.\n    \"\"\"\n    return list(selected)[: self.select_k]\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Mmr.iteration","title":"iteration","text":"<pre><code>iteration(\n    nodes: Iterable[Node], tracker: NodeTracker\n) -&gt; None\n</code></pre> <p>Add candidates to the consideration set.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/mmr.py</code> <pre><code>@override\ndef iteration(self, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:\n    \"\"\"Add candidates to the consideration set.\"\"\"\n    nodes = list(nodes)\n    node_count = len(nodes)\n    if node_count &gt; 0:\n        # Build up a matrix of the remaining candidate embeddings.\n        # And add them to the candidate set\n        new_embeddings: NDArray[np.float32] = np.ndarray(\n            (\n                node_count,\n                self._dimensions,\n            )\n        )\n        offset = self._candidate_embeddings.shape[0]\n        for index, candidate_node in enumerate(nodes):\n            self._candidate_id_to_index[candidate_node.id] = offset + index\n            new_embeddings[index] = candidate_node.embedding\n\n        # Compute the similarity to the query.\n        similarity = cosine_similarity(new_embeddings, self._nd_query_embedding)\n\n        # Compute the distance metrics of all of pairs in the selected set with\n        # the new candidates.\n        redundancy = cosine_similarity(\n            new_embeddings, self._already_selected_embeddings()\n        )\n        for index, candidate_node in enumerate(nodes):\n            max_redundancy = 0.0\n            if redundancy.shape[0] &gt; 0:\n                max_redundancy = redundancy[index].max()\n            candidate = _MmrCandidate(\n                node=candidate_node,\n                similarity=similarity[index][0],\n                weighted_similarity=self.lambda_mult * similarity[index][0],\n                weighted_redundancy=self._lambda_mult_complement * max_redundancy,\n            )\n            self._candidates.append(candidate)\n\n            if candidate.score &gt;= self._best_score:\n                self._best_score = candidate.score\n                self._best_id = candidate.node.id\n\n        # Add the new embeddings to the candidate set.\n        self._candidate_embeddings = np.vstack(\n            (\n                self._candidate_embeddings,\n                new_embeddings,\n            )\n        )\n\n    while tracker.num_remaining &gt; 0:\n        next = self._next()\n\n        if next is None:\n            break\n\n        num_traversing = tracker.select_and_traverse([next])\n        if num_traversing == 1:\n            break\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.NodeTracker","title":"NodeTracker","text":"<pre><code>NodeTracker(select_k: int, max_depth: int | None)\n</code></pre> <p>Helper class initiating node selection and traversal.</p> <p>Call .select(nodes) to add nodes to the result set. Call .traverse(nodes) to add nodes to the next traversal. Call .select_and_traverse(nodes) to add nodes to the result set and the next     traversal.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def __init__(self, select_k: int, max_depth: int | None) -&gt; None:\n    self._select_k: int = select_k\n    self._max_depth: int | None = max_depth\n    self._visited_node_ids: set[str] = set()\n    # use a dict to preserve order\n    self.to_traverse: dict[str, Node] = dict()\n    self.selected: list[Node] = []\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.NodeTracker.num_remaining","title":"num_remaining  <code>property</code>","text":"<pre><code>num_remaining\n</code></pre> <p>The remaining number of nodes to be selected.</p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.NodeTracker.select","title":"select","text":"<pre><code>select(nodes: Iterable[Node]) -&gt; None\n</code></pre> <p>Select nodes to be included in the result set.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def select(self, nodes: Iterable[Node]) -&gt; None:\n    \"\"\"Select nodes to be included in the result set.\"\"\"\n    for node in nodes:\n        node.extra_metadata[\"_depth\"] = node.depth\n        node.extra_metadata[\"_similarity_score\"] = node.similarity_score\n    self.selected.extend(nodes)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.NodeTracker.select_and_traverse","title":"select_and_traverse","text":"<pre><code>select_and_traverse(nodes: Iterable[Node]) -&gt; int\n</code></pre> <p>Select nodes to be included in the result set and the next traversal.</p> RETURNS DESCRIPTION <code>Number of nodes added for traversal.</code> Notes <ul> <li>Nodes are only added for traversal if they have not been visited before.</li> <li>Nodes are only added for traversal if they do not exceed the maximum depth.</li> <li>If no new nodes are chosen for traversal, or selected for output, then     the traversal will stop.</li> <li>Traversal will also stop if the number of selected nodes reaches the select_k     limit.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def select_and_traverse(self, nodes: Iterable[Node]) -&gt; int:\n    \"\"\"\n    Select nodes to be included in the result set and the next traversal.\n\n    Returns\n    -------\n    Number of nodes added for traversal.\n\n    Notes\n    -----\n    - Nodes are only added for traversal if they have not been visited before.\n    - Nodes are only added for traversal if they do not exceed the maximum depth.\n    - If no new nodes are chosen for traversal, or selected for output, then\n        the traversal will stop.\n    - Traversal will also stop if the number of selected nodes reaches the select_k\n        limit.\n    \"\"\"\n    self.select(nodes)\n    return self.traverse(nodes)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.NodeTracker.traverse","title":"traverse","text":"<pre><code>traverse(nodes: Iterable[Node]) -&gt; int\n</code></pre> <p>Select nodes to be included in the next traversal.</p> RETURNS DESCRIPTION <code>Number of nodes added for traversal.</code> Notes <ul> <li>Nodes are only added if they have not been visited before.</li> <li>Nodes are only added if they do not exceed the maximum depth.</li> <li>If no new nodes are chosen for traversal, or selected for output, then     the traversal will stop.</li> <li>Traversal will also stop if the number of selected nodes reaches the select_k     limit.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def traverse(self, nodes: Iterable[Node]) -&gt; int:\n    \"\"\"\n    Select nodes to be included in the next traversal.\n\n    Returns\n    -------\n    Number of nodes added for traversal.\n\n    Notes\n    -----\n    - Nodes are only added if they have not been visited before.\n    - Nodes are only added if they do not exceed the maximum depth.\n    - If no new nodes are chosen for traversal, or selected for output, then\n        the traversal will stop.\n    - Traversal will also stop if the number of selected nodes reaches the select_k\n        limit.\n    \"\"\"\n    new_nodes = {\n        n.id: n\n        for n in nodes\n        if self._not_visited(n.id)\n        if self._max_depth is None or n.depth &lt; self._max_depth\n    }\n    self.to_traverse.update(new_nodes)\n    self._visited_node_ids.update(new_nodes.keys())\n    return len(new_nodes)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Scored","title":"Scored  <code>dataclass</code>","text":"<pre><code>Scored(\n    scorer: Callable[[Node], float],\n    _nodes: list[_ScoredNode] = list(),\n    per_iteration_limit: int | None = None,\n    *,\n    select_k: int = DEFAULT_SELECT_K,\n    start_k: int = 4,\n    adjacent_k: int = 10,\n    max_traverse: int | None = None,\n    max_depth: int | None = None,\n    k: int = DEFAULT_SELECT_K,\n    _query_embedding: list[float] = list(),\n)\n</code></pre> <p>               Bases: <code>Strategy</code></p> <p>Scored traversal strategy.</p> <p>This strategy uses a scoring function to select nodes using a local maximum approach. In each iteration, it chooses the top scoring nodes available and then traverses the connected nodes.</p> PARAMETER DESCRIPTION <code>scorer</code> <p>A callable function that returns the score of a node.</p> <p> TYPE: <code>Callable[[Node], float]</code> </p> <code>select_k</code> <p>Maximum number of nodes to retrieve during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p> <code>start_k</code> <p>Number of documents to fetch via similarity for starting the traversal. Added to any initial roots provided to the traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>adjacent_k</code> <p>Number of documents to fetch for each outgoing edge.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_depth</code> <p>Maximum traversal depth. If <code>None</code>, there is no limit.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>per_iteration_limit</code> <p>Maximum number of nodes to select and traverse during a single iteration.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>k</code> <p>Deprecated: Use <code>select_k</code> instead. Maximum number of nodes to select and return during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Scored.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Allow passing the deprecated 'k' value instead of 'select_k'.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Allow passing the deprecated 'k' value instead of 'select_k'.\"\"\"\n    if self.select_k == DEFAULT_SELECT_K and self.k != DEFAULT_SELECT_K:\n        self.select_k = self.k\n    else:\n        self.k = self.select_k\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Scored.build","title":"build  <code>staticmethod</code>","text":"<pre><code>build(base_strategy: Strategy, **kwargs: Any) -&gt; Strategy\n</code></pre> <p>Build a strategy for a retrieval operation.</p> <p>Combines a base strategy with any provided keyword arguments to create a customized traversal strategy.</p> PARAMETER DESCRIPTION <code>base_strategy</code> <p>The base strategy to start with.</p> <p> TYPE: <code>Strategy</code> </p> <code>kwargs</code> <p>Additional configuration options for the strategy.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Strategy</code> <p>A configured strategy instance.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If 'strategy' is set incorrectly or extra arguments are invalid.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>@staticmethod\ndef build(\n    base_strategy: Strategy,\n    **kwargs: Any,\n) -&gt; Strategy:\n    \"\"\"\n    Build a strategy for a retrieval operation.\n\n    Combines a base strategy with any provided keyword arguments to\n    create a customized traversal strategy.\n\n    Parameters\n    ----------\n    base_strategy :\n        The base strategy to start with.\n    kwargs :\n        Additional configuration options for the strategy.\n\n    Returns\n    -------\n    :\n        A configured strategy instance.\n\n    Raises\n    ------\n    ValueError\n        If 'strategy' is set incorrectly or extra arguments are invalid.\n    \"\"\"\n    # Check if there is a new strategy to use. Otherwise, use the base.\n    strategy: Strategy\n    if \"strategy\" in kwargs:\n        if next(iter(kwargs.keys())) != \"strategy\":\n            raise ValueError(\"Error: 'strategy' must be set before other args.\")\n        strategy = kwargs.pop(\"strategy\")\n        if not isinstance(strategy, Strategy):\n            raise ValueError(\n                f\"Unsupported 'strategy' type {type(strategy).__name__}.\"\n                \" Must be a sub-class of Strategy\"\n            )\n    elif base_strategy is not None:\n        strategy = base_strategy\n    else:\n        raise ValueError(\"'strategy' must be set in `__init__` or invocation\")\n\n    # Apply the kwargs to update the strategy.\n    assert strategy is not None\n    if \"k\" in kwargs:\n        kwargs[\"select_k\"] = kwargs.pop(\"k\")\n    strategy = dataclasses.replace(strategy, **kwargs)\n\n    return strategy\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Scored.finalize_nodes","title":"finalize_nodes","text":"<pre><code>finalize_nodes(selected)\n</code></pre> <p>Finalize the selected nodes.</p> <p>This method is called before returning the final set of nodes. It allows the strategy to perform any final processing or re-ranking of the selected nodes.</p> PARAMETER DESCRIPTION <code>selected</code> <p>The selected nodes to be finalized</p> <p> TYPE: <code>Iterable[Node]</code> </p> RETURNS DESCRIPTION <code>Iterable[Node]</code> <p>Finalized nodes.</p> Notes <ul> <li>The default implementation returns the first <code>self.select_k</code> selected nodes without any additional processing.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/scored.py</code> <pre><code>@override\ndef finalize_nodes(self, selected):\n    selected = sorted(\n        selected, key=lambda node: node.extra_metadata[\"_score\"], reverse=True\n    )\n    return super().finalize_nodes(selected)\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Scored.iteration","title":"iteration","text":"<pre><code>iteration(\n    nodes: Iterable[Node], tracker: NodeTracker\n) -&gt; None\n</code></pre> <p>Process the newly discovered nodes on each iteration.</p> <p>This method should call <code>tracker.traverse()</code> and/or <code>tracker.select()</code> as appropriate to update the nodes that need to be traversed in this iteration or selected at the end of the retrieval, respectively.</p> PARAMETER DESCRIPTION <code>nodes</code> <p>The newly discovered nodes found from either: - the initial vector store retrieval - incoming edges from nodes chosen for traversal in the previous iteration</p> <p> TYPE: <code>Iterable[Node]</code> </p> <code>tracker</code> <p>The tracker object to manage the traversal and selection of nodes.</p> <p> TYPE: <code>NodeTracker</code> </p> Notes <ul> <li>This method is called once for each iteration of the traversal.</li> <li>In order to stop iterating either choose to not traverse any additional nodes or don't select any additional nodes for output.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/scored.py</code> <pre><code>@override\ndef iteration(self, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:\n    for node in nodes:\n        heapq.heappush(self._nodes, _ScoredNode(self.scorer(node), node))\n\n    limit = tracker.num_remaining\n    if self.per_iteration_limit:\n        limit = min(limit, self.per_iteration_limit)\n\n    while limit &gt; 0 and self._nodes:\n        highest = heapq.heappop(self._nodes)\n        node = highest.node\n        node.extra_metadata[\"_score\"] = highest.score\n        limit -= tracker.select_and_traverse([node])\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy","title":"Strategy  <code>dataclass</code>","text":"<pre><code>Strategy(\n    *,\n    select_k: int = DEFAULT_SELECT_K,\n    start_k: int = 4,\n    adjacent_k: int = 10,\n    max_traverse: int | None = None,\n    max_depth: int | None = None,\n    k: int = DEFAULT_SELECT_K,\n    _query_embedding: list[float] = list(),\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Interface for configuring node selection and traversal strategies.</p> <p>This base class defines how nodes are selected, traversed, and finalized during a graph traversal. Implementations can customize behaviors like limiting the depth of traversal, scoring nodes, or selecting the next set of nodes for exploration.</p> PARAMETER DESCRIPTION <code>select_k</code> <p>Maximum number of nodes to select and return during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p> <code>start_k</code> <p>Number of nodes to fetch via similarity for starting the traversal. Added to any initial roots provided to the traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>adjacent_k</code> <p>Number of nodes to fetch for each outgoing edge.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_traverse</code> <p>Maximum number of nodes to traverse outgoing edges from before returning. If <code>None</code>, there is no limit.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>max_depth</code> <p>Maximum traversal depth. If <code>None</code>, there is no limit.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>k</code> <p>Deprecated: Use <code>select_k</code> instead. Maximum number of nodes to select and return during traversal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_SELECT_K</code> </p>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Allow passing the deprecated 'k' value instead of 'select_k'.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Allow passing the deprecated 'k' value instead of 'select_k'.\"\"\"\n    if self.select_k == DEFAULT_SELECT_K and self.k != DEFAULT_SELECT_K:\n        self.select_k = self.k\n    else:\n        self.k = self.select_k\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy.build","title":"build  <code>staticmethod</code>","text":"<pre><code>build(base_strategy: Strategy, **kwargs: Any) -&gt; Strategy\n</code></pre> <p>Build a strategy for a retrieval operation.</p> <p>Combines a base strategy with any provided keyword arguments to create a customized traversal strategy.</p> PARAMETER DESCRIPTION <code>base_strategy</code> <p>The base strategy to start with.</p> <p> TYPE: <code>Strategy</code> </p> <code>kwargs</code> <p>Additional configuration options for the strategy.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Strategy</code> <p>A configured strategy instance.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If 'strategy' is set incorrectly or extra arguments are invalid.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>@staticmethod\ndef build(\n    base_strategy: Strategy,\n    **kwargs: Any,\n) -&gt; Strategy:\n    \"\"\"\n    Build a strategy for a retrieval operation.\n\n    Combines a base strategy with any provided keyword arguments to\n    create a customized traversal strategy.\n\n    Parameters\n    ----------\n    base_strategy :\n        The base strategy to start with.\n    kwargs :\n        Additional configuration options for the strategy.\n\n    Returns\n    -------\n    :\n        A configured strategy instance.\n\n    Raises\n    ------\n    ValueError\n        If 'strategy' is set incorrectly or extra arguments are invalid.\n    \"\"\"\n    # Check if there is a new strategy to use. Otherwise, use the base.\n    strategy: Strategy\n    if \"strategy\" in kwargs:\n        if next(iter(kwargs.keys())) != \"strategy\":\n            raise ValueError(\"Error: 'strategy' must be set before other args.\")\n        strategy = kwargs.pop(\"strategy\")\n        if not isinstance(strategy, Strategy):\n            raise ValueError(\n                f\"Unsupported 'strategy' type {type(strategy).__name__}.\"\n                \" Must be a sub-class of Strategy\"\n            )\n    elif base_strategy is not None:\n        strategy = base_strategy\n    else:\n        raise ValueError(\"'strategy' must be set in `__init__` or invocation\")\n\n    # Apply the kwargs to update the strategy.\n    assert strategy is not None\n    if \"k\" in kwargs:\n        kwargs[\"select_k\"] = kwargs.pop(\"k\")\n    strategy = dataclasses.replace(strategy, **kwargs)\n\n    return strategy\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy.finalize_nodes","title":"finalize_nodes","text":"<pre><code>finalize_nodes(selected: Iterable[Node]) -&gt; Iterable[Node]\n</code></pre> <p>Finalize the selected nodes.</p> <p>This method is called before returning the final set of nodes. It allows the strategy to perform any final processing or re-ranking of the selected nodes.</p> PARAMETER DESCRIPTION <code>selected</code> <p>The selected nodes to be finalized</p> <p> TYPE: <code>Iterable[Node]</code> </p> RETURNS DESCRIPTION <code>Iterable[Node]</code> <p>Finalized nodes.</p> Notes <ul> <li>The default implementation returns the first <code>self.select_k</code> selected nodes without any additional processing.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>def finalize_nodes(self, selected: Iterable[Node]) -&gt; Iterable[Node]:\n    \"\"\"\n    Finalize the selected nodes.\n\n    This method is called before returning the final set of nodes. It allows\n    the strategy to perform any final processing or re-ranking of the selected\n    nodes.\n\n    Parameters\n    ----------\n    selected :\n        The selected nodes to be finalized\n\n    Returns\n    -------\n    :\n        Finalized nodes.\n\n    Notes\n    -----\n    - The default implementation returns the first `self.select_k` selected nodes\n    without any additional processing.\n    \"\"\"\n    return list(selected)[: self.select_k]\n</code></pre>"},{"location":"reference/graph_retriever/strategies/#graph_retriever.strategies.Strategy.iteration","title":"iteration  <code>abstractmethod</code>","text":"<pre><code>iteration(\n    *, nodes: Iterable[Node], tracker: NodeTracker\n) -&gt; None\n</code></pre> <p>Process the newly discovered nodes on each iteration.</p> <p>This method should call <code>tracker.traverse()</code> and/or <code>tracker.select()</code> as appropriate to update the nodes that need to be traversed in this iteration or selected at the end of the retrieval, respectively.</p> PARAMETER DESCRIPTION <code>nodes</code> <p>The newly discovered nodes found from either: - the initial vector store retrieval - incoming edges from nodes chosen for traversal in the previous iteration</p> <p> TYPE: <code>Iterable[Node]</code> </p> <code>tracker</code> <p>The tracker object to manage the traversal and selection of nodes.</p> <p> TYPE: <code>NodeTracker</code> </p> Notes <ul> <li>This method is called once for each iteration of the traversal.</li> <li>In order to stop iterating either choose to not traverse any additional nodes or don't select any additional nodes for output.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/strategies/base.py</code> <pre><code>@abc.abstractmethod\ndef iteration(self, *, nodes: Iterable[Node], tracker: NodeTracker) -&gt; None:\n    \"\"\"\n    Process the newly discovered nodes on each iteration.\n\n    This method should call `tracker.traverse()` and/or `tracker.select()`\n    as appropriate to update the nodes that need to be traversed in this iteration\n    or selected at the end of the retrieval, respectively.\n\n    Parameters\n    ----------\n    nodes :\n        The newly discovered nodes found from either:\n        - the initial vector store retrieval\n        - incoming edges from nodes chosen for traversal in the previous iteration\n    tracker :\n        The tracker object to manage the traversal and selection of nodes.\n\n    Notes\n    -----\n    - This method is called once for each iteration of the traversal.\n    - In order to stop iterating either choose to not traverse any additional nodes\n    or don't select any additional nodes for output.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/graph_retriever/testing/","title":"graph_retriever.testing","text":"<p>Helpers for testing Graph Retriever implementations.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests","title":"adapter_tests","text":""},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceCase","title":"AdapterComplianceCase  <code>dataclass</code>","text":"<pre><code>AdapterComplianceCase(\n    *,\n    id: str,\n    expected: list[str],\n    requires_nested: bool = False,\n    requires_dict_in_list: bool = False,\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base dataclass for test cases.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>The ID of the test case.</p> <p> TYPE: <code>str</code> </p> <code>expected</code> <p>The expected results of the case.</p> <p> TYPE: <code>list[str]</code> </p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite","title":"AdapterComplianceSuite","text":"<p>               Bases: <code>ABC</code></p> <p>Test suite for adapter compliance.</p> <p>To use this, create a sub-class containing a <code>@pytest.fixture</code> named <code>adapter</code> which returns an <code>Adapter</code> with the documents from <code>animals.jsonl</code> loaded.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.adjacent_case","title":"adjacent_case","text":"<pre><code>adjacent_case(request) -&gt; AdjacentCase\n</code></pre> <p>Fixture providing the <code>get_adjacent</code> and <code>aget_adjacent</code> test cases.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>@pytest.fixture(params=ADJACENT_CASES, ids=lambda c: c.id)\ndef adjacent_case(self, request) -&gt; AdjacentCase:\n    \"\"\"Fixture providing the `get_adjacent` and `aget_adjacent` test cases.\"\"\"\n    return request.param\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.expected","title":"expected","text":"<pre><code>expected(\n    method: str, case: AdapterComplianceCase\n) -&gt; list[str]\n</code></pre> <p>Override to change the expected behavior of a case.</p> <p>If the test is expected to fail, call <code>pytest.xfail(reason)</code>, or <code>pytest.skip(reason)</code> if it can't be executed.</p> <p>Generally, this should not change the expected results, unless the the adapter being tested uses wildly different distance metrics or a different embedding. The <code>AnimalsEmbedding</code> is deterministic and the results across vector stores should generally be deterministic and consistent.</p> PARAMETER DESCRIPTION <code>method</code> <p>The method being tested. For instance, <code>get</code>, <code>aget</code>, or <code>similarity_search_with_embedding</code>, etc.</p> <p> TYPE: <code>str</code> </p> <code>case</code> <p>The case being tested.</p> <p> TYPE: <code>AdapterComplianceCase</code> </p> RETURNS DESCRIPTION <code>list[str]</code> <p>The expected animals.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def expected(self, method: str, case: AdapterComplianceCase) -&gt; list[str]:\n    \"\"\"\n    Override to change the expected behavior of a case.\n\n    If the test is expected to fail, call `pytest.xfail(reason)`, or\n    `pytest.skip(reason)` if it can't be executed.\n\n    Generally, this should *not* change the expected results, unless the the\n    adapter being tested uses wildly different distance metrics or a\n    different embedding. The `AnimalsEmbedding` is deterministic and the\n    results across vector stores should generally be deterministic and\n    consistent.\n\n    Parameters\n    ----------\n    method :\n        The method being tested. For instance, `get`, `aget`, or\n        `similarity_search_with_embedding`, etc.\n    case :\n        The case being tested.\n\n    Returns\n    -------\n    :\n        The expected animals.\n    \"\"\"\n    if not self.supports_nested_metadata() and case.requires_nested:\n        pytest.xfail(\"nested metadata not supported\")\n    if not self.supports_dict_in_list() and case.requires_dict_in_list:\n        pytest.xfail(\"dict-in-list fields is not supported\")\n    return case.expected\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.get_case","title":"get_case","text":"<pre><code>get_case(request) -&gt; GetCase\n</code></pre> <p>Fixture providing the <code>get</code> and <code>aget</code> test cases.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>@pytest.fixture(params=GET_CASES, ids=lambda c: c.id)\ndef get_case(self, request) -&gt; GetCase:\n    \"\"\"Fixture providing the `get` and `aget` test cases.\"\"\"\n    return request.param\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.search_case","title":"search_case","text":"<pre><code>search_case(request) -&gt; SearchCase\n</code></pre> <p>Fixture providing the <code>(a)?similarity_search_*</code> test cases.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>@pytest.fixture(params=SEARCH_CASES, ids=lambda c: c.id)\ndef search_case(self, request) -&gt; SearchCase:\n    \"\"\"Fixture providing the `(a)?similarity_search_*` test cases.\"\"\"\n    return request.param\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.supports_dict_in_list","title":"supports_dict_in_list","text":"<pre><code>supports_dict_in_list() -&gt; bool\n</code></pre> <p>Return whether dicts can appear in list fields in metadata.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def supports_dict_in_list(self) -&gt; bool:\n    \"\"\"Return whether dicts can appear in list fields in metadata.\"\"\"\n    return True\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.supports_nested_metadata","title":"supports_nested_metadata","text":"<pre><code>supports_nested_metadata() -&gt; bool\n</code></pre> <p>Return whether nested metadata is expected to work.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def supports_nested_metadata(self) -&gt; bool:\n    \"\"\"Return whether nested metadata is expected to work.\"\"\"\n    return True\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_aadjacent","title":"test_aadjacent  <code>async</code>","text":"<pre><code>test_aadjacent(\n    adapter: Adapter, adjacent_case: AdjacentCase\n) -&gt; None\n</code></pre> <p>Run tests for `aadjacent.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>async def test_aadjacent(\n    self, adapter: Adapter, adjacent_case: AdjacentCase\n) -&gt; None:\n    \"\"\"Run tests for `aadjacent.\"\"\"\n    expected = self.expected(\"aadjacent\", adjacent_case)\n    embedding, _ = await adapter.asearch_with_embedding(adjacent_case.query, k=0)\n    results = await adapter.aadjacent(\n        edges=adjacent_case.edges,\n        query_embedding=embedding,\n        k=adjacent_case.k,\n        filter=adjacent_case.filter,\n    )\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_adjacent","title":"test_adjacent","text":"<pre><code>test_adjacent(\n    adapter: Adapter, adjacent_case: AdjacentCase\n) -&gt; None\n</code></pre> <p>Run tests for `adjacent.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def test_adjacent(self, adapter: Adapter, adjacent_case: AdjacentCase) -&gt; None:\n    \"\"\"Run tests for `adjacent.\"\"\"\n    expected = self.expected(\"adjacent\", adjacent_case)\n    embedding, _ = adapter.search_with_embedding(adjacent_case.query, k=0)\n    results = adapter.adjacent(\n        edges=adjacent_case.edges,\n        query_embedding=embedding,\n        k=adjacent_case.k,\n        filter=adjacent_case.filter,\n    )\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_aget","title":"test_aget  <code>async</code>","text":"<pre><code>test_aget(adapter: Adapter, get_case: GetCase) -&gt; None\n</code></pre> <p>Run tests for <code>aget</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>async def test_aget(self, adapter: Adapter, get_case: GetCase) -&gt; None:\n    \"\"\"Run tests for `aget`.\"\"\"\n    expected = self.expected(\"aget\", get_case)\n    results = await adapter.aget(get_case.request, filter=get_case.filter)\n    assert_ids_any_order(results, expected)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_asearch","title":"test_asearch  <code>async</code>","text":"<pre><code>test_asearch(\n    adapter: Adapter, search_case: SearchCase\n) -&gt; None\n</code></pre> <p>Run tests for <code>asearch</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>async def test_asearch(self, adapter: Adapter, search_case: SearchCase) -&gt; None:\n    \"\"\"Run tests for `asearch`.\"\"\"\n    expected = self.expected(\"asearch\", search_case)\n    embedding, _ = await adapter.asearch_with_embedding(search_case.query, k=0)\n    results = await adapter.asearch(embedding, **search_case.kwargs)\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_asearch_with_embedding","title":"test_asearch_with_embedding  <code>async</code>","text":"<pre><code>test_asearch_with_embedding(\n    adapter: Adapter, search_case: SearchCase\n) -&gt; None\n</code></pre> <p>Run tests for <code>asearch_with_embedding</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>async def test_asearch_with_embedding(\n    self, adapter: Adapter, search_case: SearchCase\n) -&gt; None:\n    \"\"\"Run tests for `asearch_with_embedding`.\"\"\"\n    expected = self.expected(\"asearch_with_embedding\", search_case)\n    embedding, results = await adapter.asearch_with_embedding(\n        search_case.query, **search_case.kwargs\n    )\n    assert_is_embedding(embedding)\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_get","title":"test_get","text":"<pre><code>test_get(adapter: Adapter, get_case: GetCase) -&gt; None\n</code></pre> <p>Run tests for <code>get</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def test_get(self, adapter: Adapter, get_case: GetCase) -&gt; None:\n    \"\"\"Run tests for `get`.\"\"\"\n    expected = self.expected(\"get\", get_case)\n    results = adapter.get(get_case.request, filter=get_case.filter)\n    assert_ids_any_order(results, expected)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_search","title":"test_search","text":"<pre><code>test_search(\n    adapter: Adapter, search_case: SearchCase\n) -&gt; None\n</code></pre> <p>Run tests for <code>search</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def test_search(self, adapter: Adapter, search_case: SearchCase) -&gt; None:\n    \"\"\"Run tests for `search`.\"\"\"\n    expected = self.expected(\"search\", search_case)\n    embedding, _ = adapter.search_with_embedding(search_case.query, k=0)\n    results = adapter.search(embedding, **search_case.kwargs)\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdapterComplianceSuite.test_search_with_embedding","title":"test_search_with_embedding","text":"<pre><code>test_search_with_embedding(\n    adapter: Adapter, search_case: SearchCase\n) -&gt; None\n</code></pre> <p>Run tests for <code>search_with_embedding</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def test_search_with_embedding(\n    self, adapter: Adapter, search_case: SearchCase\n) -&gt; None:\n    \"\"\"Run tests for `search_with_embedding`.\"\"\"\n    expected = self.expected(\"search_with_embedding\", search_case)\n    embedding, results = adapter.search_with_embedding(\n        search_case.query, **search_case.kwargs\n    )\n    assert_is_embedding(embedding)\n    assert_ids_in_cosine_similarity_order(results, expected, embedding, adapter)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.AdjacentCase","title":"AdjacentCase  <code>dataclass</code>","text":"<pre><code>AdjacentCase(\n    query: str,\n    edges: set[Edge],\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    *,\n    id: str,\n    expected: list[str],\n    requires_nested: bool = False,\n    requires_dict_in_list: bool = False,\n)\n</code></pre> <p>               Bases: <code>AdapterComplianceCase</code></p> <p>A test case for <code>get_adjacent</code> and <code>aget_adjacent</code>.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.GetCase","title":"GetCase  <code>dataclass</code>","text":"<pre><code>GetCase(\n    request: list[str],\n    filter: dict[str, Any] | None = None,\n    *,\n    id: str,\n    expected: list[str],\n    requires_nested: bool = False,\n    requires_dict_in_list: bool = False,\n)\n</code></pre> <p>               Bases: <code>AdapterComplianceCase</code></p> <p>A test case for <code>get</code> and <code>aget</code>.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.SearchCase","title":"SearchCase  <code>dataclass</code>","text":"<pre><code>SearchCase(\n    query: str,\n    k: int | None = None,\n    filter: dict[str, str] | None = None,\n    *,\n    id: str,\n    expected: list[str],\n    requires_nested: bool = False,\n    requires_dict_in_list: bool = False,\n)\n</code></pre> <p>               Bases: <code>AdapterComplianceCase</code></p> <p>A test case for <code>similarity_search_*</code> and <code>asimilarity_search_*</code> methods.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.SearchCase.kwargs","title":"kwargs  <code>property</code>","text":"<pre><code>kwargs\n</code></pre> <p>Return keyword arguments for the test invocation.</p>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.assert_ids_any_order","title":"assert_ids_any_order","text":"<pre><code>assert_ids_any_order(\n    results: Iterable[Content], expected: list[str]\n) -&gt; None\n</code></pre> <p>Assert the results are valid and match the IDs.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def assert_ids_any_order(\n    results: Iterable[Content],\n    expected: list[str],\n) -&gt; None:\n    \"\"\"Assert the results are valid and match the IDs.\"\"\"\n    assert_valid_results(results)\n\n    result_ids = [r.id for r in results]\n    assert set(result_ids) == set(expected), \"should contain exactly expected IDs\"\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.assert_ids_in_cosine_similarity_order","title":"assert_ids_in_cosine_similarity_order","text":"<pre><code>assert_ids_in_cosine_similarity_order(\n    results: Iterable[Content],\n    expected: list[str],\n    query_embedding: list[float],\n    adapter: Adapter,\n) -&gt; None\n</code></pre> <p>Assert the results are valid and in cosine similarity order.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def assert_ids_in_cosine_similarity_order(\n    results: Iterable[Content],\n    expected: list[str],\n    query_embedding: list[float],\n    adapter: Adapter,\n) -&gt; None:\n    \"\"\"Assert the results are valid and in cosine similarity order.\"\"\"\n    assert_valid_results(results)\n    result_ids = [r.id for r in results]\n\n    similarity_scores = cosine_similarity_scores(adapter, query_embedding, expected)\n    expected = sorted(expected, key=lambda id: similarity_scores[id], reverse=True)\n\n    assert result_ids == expected, (\n        \"should contain expected IDs in cosine similarity order\"\n    )\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.assert_is_embedding","title":"assert_is_embedding","text":"<pre><code>assert_is_embedding(value: Any)\n</code></pre> <p>Assert the value is an embedding.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def assert_is_embedding(value: Any):\n    \"\"\"Assert the value is an embedding.\"\"\"\n    assert isinstance(value, list)\n    for item in value:\n        assert isinstance(item, float)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.assert_valid_result","title":"assert_valid_result","text":"<pre><code>assert_valid_result(content: Content)\n</code></pre> <p>Assert the content is valid.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def assert_valid_result(content: Content):\n    \"\"\"Assert the content is valid.\"\"\"\n    assert isinstance(content.id, str)\n    assert_is_embedding(content.embedding)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.assert_valid_results","title":"assert_valid_results","text":"<pre><code>assert_valid_results(docs: Iterable[Content])\n</code></pre> <p>Assert all of the contents are valid results.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def assert_valid_results(docs: Iterable[Content]):\n    \"\"\"Assert all of the contents are valid results.\"\"\"\n    for doc in docs:\n        assert_valid_result(doc)\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.adapter_tests.cosine_similarity_scores","title":"cosine_similarity_scores","text":"<pre><code>cosine_similarity_scores(\n    adapter: Adapter,\n    query_or_embedding: str | list[float],\n    ids: list[str],\n) -&gt; dict[str, float]\n</code></pre> <p>Return the cosine similarity scores for the given IDs and query embedding.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/adapter_tests.py</code> <pre><code>def cosine_similarity_scores(\n    adapter: Adapter, query_or_embedding: str | list[float], ids: list[str]\n) -&gt; dict[str, float]:\n    \"\"\"Return the cosine similarity scores for the given IDs and query embedding.\"\"\"\n    if len(ids) == 0:\n        return {}\n\n    docs = adapter.get(ids)\n    found_ids = (d.id for d in docs)\n    assert set(ids) == set(found_ids), \"can't find all IDs\"\n\n    if isinstance(query_or_embedding, str):\n        query_embedding = adapter.search_with_embedding(query_or_embedding, k=0)[0]\n    else:\n        query_embedding = query_or_embedding\n\n    scores: list[float] = cosine_similarity(\n        [query_embedding],\n        [d.embedding for d in docs],\n    )[0]\n\n    return {doc.id: score for doc, score in zip(docs, scores)}\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings","title":"embeddings","text":""},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.AnimalEmbeddings","title":"AnimalEmbeddings","text":"<pre><code>AnimalEmbeddings()\n</code></pre> <p>               Bases: <code>WordEmbeddings</code></p> <p>Embeddings for animal test-case.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __init__(self):\n    super().__init__(\n        words=\"\"\"\n        alli alpa amer amph ante ante antl appe aqua arct arma aust babo\n        badg barr bask bear beav beet beha bird biso bite blac blue boar\n        bobc brig buff bugl burr bush butt came cani capy cari carn cass\n        cate cham chee chic chim chin chir clim coas coat cobr cock colo\n        colo comm comp cour coyo crab cran croa croc crow crus wing wool\n        cult cunn curi curl damb danc deer defe defe deme dese digg ding\n        dise dist dive dolp dome dome donk dove drag drag duck ecos effo\n        eigh elab eleg elev elon euca extr eyes falc famo famo fast fast\n        feat feet ferr fier figh finc fish flam flig flig food fore foun\n        fres frie frog gaze geck gees gent gill gira goat gori grac gras\n        gras graz grou grou grou guin hams hard hawk hedg herb herd hero\n        high hipp honk horn hors hove howl huma humm hump hunt hyen iden\n        igua inde inse inte jack jagu jell jump jung kang koal komo lark\n        larv lemu leop life lion liza lobs long loud loya mada magp mamm\n        mana mari mars mass mati meat medi melo meta migr milk mimi moos\n        mosq moth narw nati natu neck newt noct nort ocea octo ostr pack\n        pain patt peac pest pinc pink play plum poll post pouc powe prec\n        pred prey prid prim prob prot prow quac quil rais rapi reac rega\n        rege regi rego rein rept resi rive roam rode sava scav seab seaf\n        seas semi shar shed shel skil smal snak soci soft soli song song\n        soun sout spec spee spik spor spot stag stic stin stin stor stre\n        stre stre stro surv surv sust symb tail tall talo team teet tent\n        term terr thou tiny tong toug tree agil tuft tund tusk umbr unic\n        uniq vast vege veno vibr vita vora wadi wasp wate webb wetl wild\n        ant bat bee cat cow dog eel elk emu fox pet pig\"\"\".split()\n    )\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.AnimalEmbeddings.__call__","title":"__call__","text":"<pre><code>__call__(text: str) -&gt; list[float]\n</code></pre> <p>Return the embedding.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __call__(self, text: str) -&gt; list[float]:\n    \"\"\"Return the embedding.\"\"\"\n    return [\n        1.0 + (100 / self._offsets[i]) if word in text else 0.2 / (i + 1)\n        for i, word in enumerate(self._words)\n    ]\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.ParserEmbeddings","title":"ParserEmbeddings","text":"<pre><code>ParserEmbeddings(dimension: int = 10)\n</code></pre> <p>Parse the tuext as a list of floats, otherwise return zeros.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __init__(self, dimension: int = 10) -&gt; None:\n    self.dimension = dimension\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.ParserEmbeddings.__call__","title":"__call__","text":"<pre><code>__call__(text: str) -&gt; list[float]\n</code></pre> <p>Return the embedding.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __call__(self, text: str) -&gt; list[float]:\n    \"\"\"Return the embedding.\"\"\"\n    try:\n        vals = json.loads(text)\n        assert len(vals) == self.dimension\n        return vals\n    except json.JSONDecodeError:\n        return [0.0] * self.dimension\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.WordEmbeddings","title":"WordEmbeddings","text":"<pre><code>WordEmbeddings(words: list[str])\n</code></pre> <p>Embeddings based on a word list.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __init__(self, words: list[str]):\n    self._words = words\n    self._offsets = [\n        _string_to_number(w) * ((-1) ** i) for i, w in enumerate(words)\n    ]\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.WordEmbeddings.__call__","title":"__call__","text":"<pre><code>__call__(text: str) -&gt; list[float]\n</code></pre> <p>Return the embedding.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def __call__(self, text: str) -&gt; list[float]:\n    \"\"\"Return the embedding.\"\"\"\n    return [\n        1.0 + (100 / self._offsets[i]) if word in text else 0.2 / (i + 1)\n        for i, word in enumerate(self._words)\n    ]\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.angular_2d_embedding","title":"angular_2d_embedding","text":"<pre><code>angular_2d_embedding(text: str) -&gt; list[float]\n</code></pre> <p>Convert input text to a 'vector' (list of floats).</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to embed.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[float]</code> <p>If the text is a number, use it as the angle for the unit vector in units of pi.</p> <p>Any other input text becomes the singular result <code>[0, 0]</code>.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def angular_2d_embedding(text: str) -&gt; list[float]:\n    \"\"\"\n    Convert input text to a 'vector' (list of floats).\n\n    Parameters\n    ----------\n    text: str\n        The text to embed.\n\n    Returns\n    -------\n    :\n        If the text is a number, use it as the angle for the unit vector in\n        units of pi.\n\n        Any other input text becomes the singular result `[0, 0]`.\n    \"\"\"\n    try:\n        angle = float(text)\n        return [math.cos(angle * math.pi), math.sin(angle * math.pi)]\n    except ValueError:\n        # Assume: just test string, no attention is paid to values.\n        return [0.0, 0.0]\n</code></pre>"},{"location":"reference/graph_retriever/testing/#graph_retriever.testing.embeddings.earth_embeddings","title":"earth_embeddings","text":"<pre><code>earth_embeddings(text: str) -&gt; list[float]\n</code></pre> <p>Split words and return a vector based on that.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/testing/embeddings.py</code> <pre><code>def earth_embeddings(text: str) -&gt; list[float]:\n    \"\"\"Split words and return a vector based on that.\"\"\"\n\n    def vector_near(value: float) -&gt; list[float]:\n        base_point = [value, (1 - value**2) ** 0.5]\n        fluctuation = random.random() / 100.0\n        return [base_point[0] + fluctuation, base_point[1] - fluctuation]\n\n    words = set(text.lower().split())\n    if \"earth\" in words:\n        return vector_near(0.9)\n    elif {\"planet\", \"world\", \"globe\", \"sphere\"}.intersection(words):\n        return vector_near(0.8)\n    else:\n        return vector_near(0.1)\n</code></pre>"},{"location":"reference/graph_retriever/utils/","title":"graph_retriever.utils","text":"<p>Utilities used in graph_retriever and related packages.</p>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.math","title":"math","text":"<p>Math utility functions for vector operations.</p>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.math.cosine_similarity","title":"cosine_similarity","text":"<pre><code>cosine_similarity(X: Matrix, Y: Matrix) -&gt; ndarray\n</code></pre> <p>Compute row-wise cosine similarity between two equal-width matrices.</p> PARAMETER DESCRIPTION <code>X</code> <p>A matrix of shape (m, n), where <code>m</code> is the number of rows and <code>n</code> is the number of columns (features).</p> <p> TYPE: <code>Matrix</code> </p> <code>Y</code> <p>A matrix of shape (p, n), where <code>p</code> is the number of rows and <code>n</code> is the number of columns (features).</p> <p> TYPE: <code>Matrix</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>A matrix of shape (m, p) containing the cosine similarity scores between each row of <code>X</code> and each row of <code>Y</code>.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the number of columns in <code>X</code> and <code>Y</code> are not equal.</p> Notes <ul> <li>If the <code>simsimd</code> library is available, it will be used for performance   optimization. Otherwise, the function falls back to a NumPy implementation.</li> <li>Divide-by-zero and invalid values in similarity calculations are replaced   with 0.0 in the output.</li> </ul> Source code in <code>packages/graph-retriever/src/graph_retriever/utils/math.py</code> <pre><code>def cosine_similarity(X: Matrix, Y: Matrix) -&gt; np.ndarray:\n    \"\"\"\n    Compute row-wise cosine similarity between two equal-width matrices.\n\n    Parameters\n    ----------\n    X :\n        A matrix of shape (m, n), where `m` is the number of rows and `n` is the\n        number of columns (features).\n    Y :\n        A matrix of shape (p, n), where `p` is the number of rows and `n` is the\n        number of columns (features).\n\n    Returns\n    -------\n    :\n        A matrix of shape (m, p) containing the cosine similarity scores\n        between each row of `X` and each row of `Y`.\n\n    Raises\n    ------\n    ValueError\n        If the number of columns in `X` and `Y` are not equal.\n\n    Notes\n    -----\n    - If the `simsimd` library is available, it will be used for performance\n      optimization. Otherwise, the function falls back to a NumPy implementation.\n    - Divide-by-zero and invalid values in similarity calculations are replaced\n      with 0.0 in the output.\n    \"\"\"\n    if len(X) == 0 or len(Y) == 0:\n        return np.array([])\n\n    X = np.array(X)\n    Y = np.array(Y)\n    if X.shape[1] != Y.shape[1]:\n        raise ValueError(\n            f\"Number of columns in X and Y must be the same. X has shape {X.shape} \"\n            f\"and Y has shape {Y.shape}.\"\n        )\n    try:\n        import simsimd as simd\n\n        X = np.array(X, dtype=np.float32)\n        Y = np.array(Y, dtype=np.float32)\n        Z = 1 - np.array(simd.cdist(X, Y, metric=\"cosine\"))\n        return Z\n    except ImportError:\n        logger.debug(\n            \"Unable to import simsimd, defaulting to NumPy implementation. If you want \"\n            \"to use simsimd please install with `pip install simsimd`.\"\n        )\n        X_norm = np.linalg.norm(X, axis=1)\n        Y_norm = np.linalg.norm(Y, axis=1)\n        # Ignore divide by zero errors run time warnings as those are handled below.\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            similarity = np.dot(X, Y.T) / np.outer(X_norm, Y_norm)\n        similarity[np.isnan(similarity) | np.isinf(similarity)] = 0.0\n        return similarity\n</code></pre>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.math.cosine_similarity_top_k","title":"cosine_similarity_top_k","text":"<pre><code>cosine_similarity_top_k(\n    X: Matrix,\n    Y: Matrix,\n    top_k: int | None,\n    score_threshold: float | None = None,\n) -&gt; tuple[list[tuple[int, int]], list[float]]\n</code></pre> <p>Row-wise cosine similarity with optional top-k and score threshold filtering.</p> PARAMETER DESCRIPTION <code>X</code> <p>A matrix of shape (m, n), where <code>m</code> is the number of rows and <code>n</code> is the number of columns (features).</p> <p> TYPE: <code>Matrix</code> </p> <code>Y</code> <p>A matrix of shape (p, n), where <code>p</code> is the number of rows and <code>n</code> is the number of columns (features).</p> <p> TYPE: <code>Matrix</code> </p> <code>top_k</code> <p>Max number of results to return.</p> <p> TYPE: <code>int | None</code> </p> <code>score_threshold</code> <p>Minimum score to return.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[tuple[int, int]]</code> <p>Two-tuples of indices <code>(X_idx, Y_idx)</code> indicating the respective rows in <code>X</code> and <code>Y</code>.</p> <code>list[float]</code> <p>The corresponding cosine similarities.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/utils/math.py</code> <pre><code>def cosine_similarity_top_k(\n    X: Matrix,\n    Y: Matrix,\n    top_k: int | None,\n    score_threshold: float | None = None,\n) -&gt; tuple[list[tuple[int, int]], list[float]]:\n    \"\"\"\n    Row-wise cosine similarity with optional top-k and score threshold filtering.\n\n    Parameters\n    ----------\n    X :\n        A matrix of shape (m, n), where `m` is the number of rows and `n` is the\n        number of columns (features).\n    Y :\n        A matrix of shape (p, n), where `p` is the number of rows and `n` is the\n        number of columns (features).\n    top_k :\n        Max number of results to return.\n    score_threshold:\n        Minimum score to return.\n\n    Returns\n    -------\n    list[tuple[int, int]]\n        Two-tuples of indices `(X_idx, Y_idx)` indicating the respective rows in\n        `X` and `Y`.\n    list[float]\n        The corresponding cosine similarities.\n    \"\"\"\n    if len(X) == 0 or len(Y) == 0:\n        return [], []\n    score_array = cosine_similarity(X, Y)\n    score_threshold = score_threshold or -1.0\n    score_array[score_array &lt; score_threshold] = 0\n    top_k = min(top_k or len(score_array), np.count_nonzero(score_array))\n    top_k_idxs = np.argpartition(score_array, -top_k, axis=None)[-top_k:]\n    top_k_idxs = top_k_idxs[np.argsort(score_array.ravel()[top_k_idxs])][::-1]\n    ret_idxs = np.unravel_index(top_k_idxs, score_array.shape)\n    scores = score_array.ravel()[top_k_idxs].tolist()\n    return list(zip(*ret_idxs)), scores  # type: ignore\n</code></pre>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.merge","title":"merge","text":""},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.merge.amerge","title":"amerge  <code>async</code>","text":"<pre><code>amerge(\n    *async_iterables: AsyncIterator[T],\n    queue_size: int = 10,\n) -&gt; AsyncIterator[T]\n</code></pre> <p>Merge async iterables into a single async iterator.</p> <p>Elements are yielded in the order they become available.</p> PARAMETER DESCRIPTION <code>async_iterables</code> <p>The async iterators to merge.</p> <p> TYPE: <code>AsyncIterator[T]</code> DEFAULT: <code>()</code> </p> <code>queue_size</code> <p>Number of elements to buffer in the queue.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> YIELDS DESCRIPTION <code>AsyncIterator[T]</code> <p>The elements of the iterators as they become available.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/utils/merge.py</code> <pre><code>async def amerge(\n    *async_iterables: AsyncIterator[T],\n    queue_size: int = 10,\n) -&gt; AsyncIterator[T]:\n    \"\"\"\n    Merge async iterables into a single async iterator.\n\n    Elements are yielded in the order they become available.\n\n    Parameters\n    ----------\n    async_iterables :\n        The async iterators to merge.\n    queue_size :\n        Number of elements to buffer in the queue.\n\n    Yields\n    ------\n    :\n        The elements of the iterators as they become available.\n    \"\"\"\n    queue: asyncio.Queue[T | _Done] = asyncio.Queue(queue_size)\n\n    async def pump(aiter: AsyncIterator[T]) -&gt; None:\n        try:\n            async for item in aiter:\n                await queue.put(item)\n            await queue.put(_Done(exception=False))\n        except:\n            await queue.put(_Done(exception=True))\n            raise\n\n    tasks = [asyncio.create_task(pump(aiter)) for aiter in async_iterables]\n\n    try:\n        pending_count = len(async_iterables)\n        while pending_count &gt; 0:\n            item = await queue.get()\n            if isinstance(item, _Done):\n                if item.exception:\n                    # If there has been an exception, end early.\n                    break\n                else:\n                    pending_count -= 1\n            else:\n                yield item\n            queue.task_done()\n    finally:\n        for task in tasks:\n            if not task.done():\n                task.cancel()\n        await asyncio.gather(*tasks)\n</code></pre>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.run_in_executor","title":"run_in_executor","text":""},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.run_in_executor.run_in_executor","title":"run_in_executor  <code>async</code>","text":"<pre><code>run_in_executor(\n    executor: Executor | None,\n    func: Callable[P, T],\n    *args: args,\n    **kwargs: kwargs,\n) -&gt; T\n</code></pre> <p>Run a function in an executor.</p> PARAMETER DESCRIPTION <code>executor</code> <p>The executor to run in.</p> <p> TYPE: <code>Executor | None</code> </p> <code>func</code> <p>The function.</p> <p> TYPE: <code>Callable[P, T]</code> </p> <code>*args</code> <p>The positional arguments to the function.</p> <p> TYPE: <code>args</code> DEFAULT: <code>()</code> </p> <code>kwargs</code> <p>The keyword arguments to the function.</p> <p> TYPE: <code>kwargs</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The output of the function.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If the function raises a StopIteration.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/utils/run_in_executor.py</code> <pre><code>async def run_in_executor(\n    executor: Executor | None,\n    func: Callable[P, T],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; T:  # noqa: DOC502\n    \"\"\"\n    Run a function in an executor.\n\n    Parameters\n    ----------\n    executor :\n        The executor to run in.\n    func :\n        The function.\n    *args :\n        The positional arguments to the function.\n    kwargs :\n        The keyword arguments to the function.\n\n    Returns\n    -------\n    :\n        The output of the function.\n\n    Raises\n    ------\n    RuntimeError\n        If the function raises a StopIteration.\n    \"\"\"  # noqa: DOC502\n\n    def wrapper() -&gt; T:\n        try:\n            return func(*args, **kwargs)\n        except StopIteration as exc:\n            # StopIteration can't be set on an asyncio.Future\n            # it raises a TypeError and leaves the Future pending forever\n            # so we need to convert it to a RuntimeError\n            raise RuntimeError from exc\n\n    if executor is None or isinstance(executor, dict):\n        # Use default executor with context copied from current context\n        return await asyncio.get_running_loop().run_in_executor(\n            None,\n            cast(Callable[..., T], partial(copy_context().run, wrapper)),\n        )\n\n    return await asyncio.get_running_loop().run_in_executor(executor, wrapper)\n</code></pre>"},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.top_k","title":"top_k","text":""},{"location":"reference/graph_retriever/utils/#graph_retriever.utils.top_k.top_k","title":"top_k","text":"<pre><code>top_k(\n    contents: Iterable[Content],\n    *,\n    embedding: list[float],\n    k: int,\n) -&gt; list[Content]\n</code></pre> <p>Select the top-k contents from the given content.</p> PARAMETER DESCRIPTION <code>contents</code> <p>The content from which to select the top-K.</p> <p> TYPE: <code>Iterable[Content]</code> </p> <code>embedding</code> <p>The embedding we're looking for.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of items to select.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>Top-K by similarity.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/utils/top_k.py</code> <pre><code>def top_k(\n    contents: Iterable[Content],\n    *,\n    embedding: list[float],\n    k: int,\n) -&gt; list[Content]:\n    \"\"\"\n    Select the top-k contents from the given content.\n\n    Parameters\n    ----------\n    contents :\n        The content from which to select the top-K.\n    embedding: list[float]\n        The embedding we're looking for.\n    k :\n        The number of items to select.\n\n    Returns\n    -------\n    list[Content]\n        Top-K by similarity.\n    \"\"\"\n    # TODO: Consider handling specially cases of already-sorted batches (merge).\n    # TODO: Consider passing threshold here to limit results.\n\n    # Use dicts to de-duplicate by ID. This ensures we choose the top K distinct\n    # content (rather than K copies of the same content).\n    unscored = {c.id: c for c in contents}\n\n    top_scored = _similarity_sort_top_k(\n        list(unscored.values()), embedding=embedding, k=k\n    )\n\n    sorted = list(top_scored.values())\n    sorted.sort(key=_score, reverse=True)\n\n    return [c[0] for c in sorted]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/","title":"langchain_graph_retriever","text":""},{"location":"reference/langchain_graph_retriever/#langchain_graph_retriever.GraphRetriever","title":"GraphRetriever","text":"<p>               Bases: <code>BaseRetriever</code></p> <p>Retriever combining vector search and graph traversal.</p> <p>The GraphRetriever class retrieves documents by first performing a vector search to identify relevant documents, followed by graph traversal to explore their connections. It supports multiple traversal strategies and integrates seamlessly with LangChain's retriever framework.</p> ATTRIBUTE DESCRIPTION <code>store</code> <p>The adapter or vector store used for document retrieval.</p> <p> TYPE: <code>Adapter | VectorStore</code> </p> <code>edges</code> <p>A list of EdgeSpec for use in creating a MetadataEdgeFunction, or an EdgeFunction.</p> <p> TYPE: <code>list[EdgeSpec] | EdgeFunction</code> </p> <code>strategy</code> <p>The traversal strategy to use.</p> <p> TYPE: <code>Strategy</code> </p>"},{"location":"reference/langchain_graph_retriever/#langchain_graph_retriever.GraphRetriever.adapter","title":"adapter  <code>cached</code> <code>property</code>","text":"<pre><code>adapter: Adapter\n</code></pre> <p>The adapter to use during traversals.</p>"},{"location":"reference/langchain_graph_retriever/#langchain_graph_retriever.GraphRetriever.apply_extra","title":"apply_extra","text":"<pre><code>apply_extra() -&gt; Self\n</code></pre> <p>Apply extra configuration to the traversal strategy.</p> <p>This method captures additional fields provided in the <code>model_extra</code> argument and applies them to the current traversal strategy. Any extra fields are cleared after they are applied.</p> RETURNS DESCRIPTION <code>Self</code> <p>The updated GraphRetriever instance.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/graph_retriever.py</code> <pre><code>@model_validator(mode=\"after\")\ndef apply_extra(self) -&gt; Self:\n    \"\"\"\n    Apply extra configuration to the traversal strategy.\n\n    This method captures additional fields provided in the `model_extra` argument\n    and applies them to the current traversal strategy. Any extra fields are\n    cleared after they are applied.\n\n    Returns\n    -------\n    :\n        The updated GraphRetriever instance.\n    \"\"\"\n    if self.model_extra:\n        if \"k\" in self.model_extra:\n            self.model_extra[\"select_k\"] = self.model_extra.pop(\"k\")\n        self.strategy = dataclasses.replace(self.strategy, **self.model_extra)\n        self.model_extra.clear()\n    return self\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/","title":"langchain_graph_retriever.adapters","text":""},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra","title":"astra","text":"<p>Provides an adapter for AstraDB vector store integration.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter","title":"AstraAdapter","text":"<pre><code>AstraAdapter(vector_store: AstraDBVectorStore)\n</code></pre> <p>               Bases: <code>Adapter</code></p> <p>Adapter for the AstraDB vector store.</p> <p>This class integrates the LangChain AstraDB vector store with the graph retriever system, providing functionality for similarity search and document retrieval.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The AstraDB vector store instance.</p> <p> TYPE: <code>AstraDBVectorStore</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>def __init__(self, vector_store: AstraDBVectorStore) -&gt; None:\n    self.vector_store = vector_store.copy(\n        component_name=\"langchain_graph_retriever\"\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\nasync def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    sort = self._vector_sort_from_embedding(query_embedding)\n    metadata, ids = _extract_queries(edges)\n\n    metadata_queries = _metadata_queries(user_filters=filter, metadata=metadata)\n\n    iterables = []\n    for metadata_query in metadata_queries:\n        iterables.append(\n            await self._arun_query(n=k, filter=metadata_query, sort=sort)\n        )\n    for id_batch in batched(ids, 100):\n        iterables.append(\n            await self._arun_query(\n                n=k, ids=list(id_batch), filter=filter, sort=sort\n            )\n        )\n\n    iterators: list[AsyncIterator[Content]] = [it.__aiter__() for it in iterables]\n\n    results: dict[str, Content] = {}\n    async for result in merge.amerge(*iterators):\n        results[result.id] = result\n\n    return top_k(results.values(), embedding=query_embedding, k=k)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\ndef adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    sort = self._vector_sort_from_embedding(query_embedding)\n    metadata, ids = _extract_queries(edges)\n\n    metadata_queries = _metadata_queries(user_filters=filter, metadata=metadata)\n\n    results: dict[str, Content] = {}\n    for metadata_query in metadata_queries:\n        # TODO: Look at a thread-pool for this.\n        for result in self._run_query(n=k, filter=metadata_query, sort=sort):\n            results[result.id] = result\n\n    for id_batch in batched(ids, 100):\n        for result in self._run_query(\n            n=k, ids=list(id_batch), filter=filter, sort=sort\n        ):\n            results[result.id] = result\n\n    return top_k(results.values(), embedding=query_embedding, k=k)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\nasync def aget(\n    self, ids: Sequence[str], filter: dict[str, Any] | None = None, **kwargs: Any\n) -&gt; list[Content]:\n    results = await self._arun_query(n=len(ids), ids=list(ids), filter=filter)\n    return [r async for r in results]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n    sort = self._vector_sort_from_embedding(embedding)\n    results = await self._arun_query(n=k, filter=filter, sort=sort)\n    return [r async for r in results]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding, sort = self._get_sort_and_optional_embedding(query, k)\n    if sort is None and query_embedding is not None:\n        return query_embedding, []\n\n    query_embedding, results = await self._arun_query(\n        n=k, filter=filter, sort=sort, include_sort_vector=True\n    )\n    return query_embedding, [r async for r in results]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\ndef get(\n    self, ids: Sequence[str], filter: dict[str, Any] | None = None, **kwargs: Any\n) -&gt; list[Content]:\n    results = self._run_query(n=len(ids), ids=list(ids), filter=filter)\n    return list(results)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n    sort = self._vector_sort_from_embedding(embedding)\n    results = self._run_query(n=k, filter=filter, sort=sort)\n    return list(results)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.AstraAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding, sort = self._get_sort_and_optional_embedding(query, k)\n    if sort is None and query_embedding is not None:\n        return query_embedding, []\n\n    query_embedding, results = self._run_query(\n        n=k, filter=filter, sort=sort, include_sort_vector=True\n    )\n    return query_embedding, list(results)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.astra.empty_async_iterable","title":"empty_async_iterable  <code>async</code>","text":"<pre><code>empty_async_iterable() -&gt; AsyncIterable[AstraDBQueryResult]\n</code></pre> <p>Create an empty async iterable.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/astra.py</code> <pre><code>async def empty_async_iterable() -&gt; AsyncIterable[AstraDBQueryResult]:\n    \"\"\"Create an empty async iterable.\"\"\"\n    if False:\n        yield\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra","title":"cassandra","text":"<p>Provides an adapter for Cassandra vector store integration.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter","title":"CassandraAdapter","text":"<pre><code>CassandraAdapter(\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n)\n</code></pre> <p>               Bases: <code>ShreddedLangchainAdapter[Cassandra]</code></p> <p>Adapter for the Apache Cassandra vector store.</p> <p>This class integrates the LangChain Cassandra vector store with the graph retriever system, providing functionality for similarity search and document retrieval.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The Cassandra vector store instance.</p> <p> TYPE: <code>StoreT</code> </p> <code>shredder</code> <p>An instance of the ShreddingTransformer used for doc insertion. If not passed then a default instance of ShreddingTransformer is used.</p> <p> TYPE: <code>ShreddingTransformer | None</code> DEFAULT: <code>None</code> </p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def __init__(\n    self,\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n):\n    \"\"\"Initialize the base adapter.\"\"\"\n    super().__init__(vector_store=vector_store)\n    self.shredder = ShreddingTransformer() if shredder is None else shredder\n    self.nested_metadata_fields = nested_metadata_fields\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    restored = list(self.shredder.restore_documents(documents=docs))\n    return super().format_documents_hook(restored)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.cassandra.CassandraAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, str] | None,\n) -&gt; dict[str, str] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef update_filter_hook(\n    self, filter: dict[str, str] | None\n) -&gt; dict[str, str] | None:\n    if filter is None:\n        return None\n\n    shredded_filter = {}\n    for key, value in filter.items():\n        if key in self.nested_metadata_fields:\n            shredded_filter[self.shredder.shredded_key(key, value)] = (\n                self.shredder.shredded_value()\n            )\n        else:\n            shredded_filter[key] = value\n    return shredded_filter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma","title":"chroma","text":"<p>Provides an adapter for Chroma vector store integration.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter","title":"ChromaAdapter","text":"<pre><code>ChromaAdapter(\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n)\n</code></pre> <p>               Bases: <code>ShreddedLangchainAdapter[Chroma]</code></p> <p>Adapter for Chroma vector store.</p> <p>This adapter integrates the LangChain Chroma vector store with the graph retriever system, allowing for similarity search and document retrieval.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The Chroma vector store instance.</p> <p> TYPE: <code>StoreT</code> </p> <code>shredder</code> <p>An instance of the ShreddingTransformer used for doc insertion. If not passed then a default instance of ShreddingTransformer is used.</p> <p> TYPE: <code>ShreddingTransformer | None</code> DEFAULT: <code>None</code> </p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def __init__(\n    self,\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n):\n    \"\"\"Initialize the base adapter.\"\"\"\n    super().__init__(vector_store=vector_store)\n    self.shredder = ShreddingTransformer() if shredder is None else shredder\n    self.nested_metadata_fields = nested_metadata_fields\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    restored = list(self.shredder.restore_documents(documents=docs))\n    return super().format_documents_hook(restored)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.chroma.ChromaAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, Any] | None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/chroma.py</code> <pre><code>@override\ndef update_filter_hook(\n    self, filter: dict[str, Any] | None\n) -&gt; dict[str, Any] | None:\n    filter = super().update_filter_hook(filter)\n    if not filter or len(filter) &lt;= 1:\n        return filter\n\n    conjoined = [{k: v} for k, v in filter.items()]\n    return {\"$and\": conjoined}\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory","title":"in_memory","text":"<p>Provides an adapter for the InMemoryVectorStore integration.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter","title":"InMemoryAdapter","text":"<pre><code>InMemoryAdapter(vector_store: StoreT)\n</code></pre> <p>               Bases: <code>LangchainAdapter[InMemoryVectorStore]</code></p> <p>Adapter for InMemoryVectorStore vector store.</p> <p>This adapter integrates the LangChain In-Memory vector store with the graph retriever system, enabling similarity search and document retrieval.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The in-memory vector store instance.</p> <p> TYPE: <code>StoreT</code> </p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def __init__(\n    self,\n    vector_store: StoreT,\n):\n    \"\"\"Initialize the base adapter.\"\"\"\n    self.vector_store = vector_store\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    \"\"\"\n    Format the documents as content after executing the query.\n\n    Parameters\n    ----------\n    docs :\n        The documents returned from the vector store\n\n    Returns\n    -------\n    :\n        The formatted content.\n    \"\"\"\n    return [doc_to_content(doc) for doc in docs]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.in_memory.InMemoryAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, Any] | None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def update_filter_hook(\n    self, filter: dict[str, Any] | None\n) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Update the metadata filter before executing the query.\n\n    Parameters\n    ----------\n    filter :\n        Filter on the metadata to update.\n\n    Returns\n    -------\n    :\n        The updated filter on the metadata to apply.\n    \"\"\"\n    return filter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.inference","title":"inference","text":"<p>Infers the appropriate adapter for a given vector store.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.inference.infer_adapter","title":"infer_adapter","text":"<pre><code>infer_adapter(store: Adapter | VectorStore) -&gt; Adapter\n</code></pre> <p>Dynamically infer the adapter for a given vector store.</p> <p>This function identifies the correct adapter based on the vector store type and instantiates it with the provided arguments.</p> PARAMETER DESCRIPTION <code>store</code> <p>The vector store instance.</p> <p> TYPE: <code>Adapter | VectorStore</code> </p> RETURNS DESCRIPTION <code>Adapter</code> <p>The initialized adapter for the given vector store.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/inference.py</code> <pre><code>def infer_adapter(store: Adapter | VectorStore) -&gt; Adapter:\n    \"\"\"\n    Dynamically infer the adapter for a given vector store.\n\n    This function identifies the correct adapter based on the vector store type\n    and instantiates it with the provided arguments.\n\n    Parameters\n    ----------\n    store :\n        The vector store instance.\n\n    Returns\n    -------\n    :\n        The initialized adapter for the given vector store.\n    \"\"\"\n    if isinstance(store, Adapter):\n        return store\n\n    module_name, class_name = _infer_adapter_name(store.__class__)\n    adapter_module = importlib.import_module(module_name)\n    adapter_class = getattr(adapter_module, class_name)\n    return adapter_class(store)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain","title":"langchain","text":"<p>Defines the base class for vector store adapters.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter","title":"LangchainAdapter","text":"<pre><code>LangchainAdapter(vector_store: StoreT)\n</code></pre> <p>               Bases: <code>Generic[StoreT]</code>, <code>Adapter</code></p> <p>Base adapter for integrating vector stores with the graph retriever system.</p> <p>This class provides a foundation for custom adapters, enabling consistent interaction with various vector store implementations.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The vector store instance.</p> <p> TYPE: <code>StoreT</code> </p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def __init__(\n    self,\n    vector_store: StoreT,\n):\n    \"\"\"Initialize the base adapter.\"\"\"\n    self.vector_store = vector_store\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    \"\"\"\n    Format the documents as content after executing the query.\n\n    Parameters\n    ----------\n    docs :\n        The documents returned from the vector store\n\n    Returns\n    -------\n    :\n        The formatted content.\n    \"\"\"\n    return [doc_to_content(doc) for doc in docs]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.LangchainAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, Any] | None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def update_filter_hook(\n    self, filter: dict[str, Any] | None\n) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Update the metadata filter before executing the query.\n\n    Parameters\n    ----------\n    filter :\n        Filter on the metadata to update.\n\n    Returns\n    -------\n    :\n        The updated filter on the metadata to apply.\n    \"\"\"\n    return filter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter","title":"ShreddedLangchainAdapter","text":"<pre><code>ShreddedLangchainAdapter(\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n)\n</code></pre> <p>               Bases: <code>LangchainAdapter[StoreT]</code></p> <p>Base adapter for integrating vector stores with the graph retriever system.</p> <p>This class provides a foundation for custom adapters, enabling consistent interaction with various vector store implementations that do not support searching on list-based metadata values.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The vector store instance.</p> <p> TYPE: <code>StoreT</code> </p> <code>shredder</code> <p>An instance of the ShreddingTransformer used for doc insertion. If not passed then a default instance of ShreddingTransformer is used.</p> <p> TYPE: <code>ShreddingTransformer | None</code> DEFAULT: <code>None</code> </p> <code>nested_metadata_fields</code> <p>The set of metadata fields that contain nested values.</p> <p> TYPE: <code>set[str]</code> DEFAULT: <code>set()</code> </p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def __init__(\n    self,\n    vector_store: StoreT,\n    shredder: ShreddingTransformer | None = None,\n    nested_metadata_fields: set[str] = set(),\n):\n    \"\"\"Initialize the base adapter.\"\"\"\n    super().__init__(vector_store=vector_store)\n    self.shredder = ShreddingTransformer() if shredder is None else shredder\n    self.nested_metadata_fields = nested_metadata_fields\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    restored = list(self.shredder.restore_documents(documents=docs))\n    return super().format_documents_hook(restored)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.langchain.ShreddedLangchainAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, str] | None,\n) -&gt; dict[str, str] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef update_filter_hook(\n    self, filter: dict[str, str] | None\n) -&gt; dict[str, str] | None:\n    if filter is None:\n        return None\n\n    shredded_filter = {}\n    for key, value in filter.items():\n        if key in self.nested_metadata_fields:\n            shredded_filter[self.shredder.shredded_key(key, value)] = (\n                self.shredder.shredded_value()\n            )\n        else:\n            shredded_filter[key] = value\n    return shredded_filter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search","title":"open_search","text":"<p>Provides an adapter for OpenSearch vector store integration.</p>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter","title":"OpenSearchAdapter","text":"<pre><code>OpenSearchAdapter(vector_store: OpenSearchVectorSearch)\n</code></pre> <p>               Bases: <code>LangchainAdapter[OpenSearchVectorSearch]</code></p> <p>Adapter to traverse OpenSearch vector stores.</p> <p>This adapter enables similarity search and document retrieval using an OpenSearch vector store.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The OpenSearch vector store instance.</p> <p> TYPE: <code>OpenSearchVectorSearch</code> </p> Notes <p>Graph Traversal is only supported when using either the <code>\"lucene\"</code> or <code>\"faiss\"</code> engine.</p> <p>For more info, see the OpenSearch Documentation</p> <p>Initialize the base adapter.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/open_search.py</code> <pre><code>def __init__(self, vector_store: OpenSearchVectorSearch):\n    if vector_store.engine not in [\"lucene\", \"faiss\"]:\n        msg = (\n            f\"Invalid engine for Traversal: '{self.vector_store.engine}'\"\n            \" please instantiate the Open Search Vector Store with\"\n            \" either the 'lucene' or 'faiss' engine\"\n        )\n        raise ValueError(msg)\n    super().__init__(vector_store)\n\n    if vector_store.is_aoss:\n        self._id_field = \"id\"\n    else:\n        self._id_field = \"_id\"\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.aadjacent","title":"aadjacent  <code>async</code>","text":"<pre><code>aadjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Asynchronously return the content items with at least one matching edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select for the edges.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>async def aadjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Asynchronously return the content items with at least one matching edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select for the edges.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    tasks = []\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            tasks.append(\n                self.asearch(\n                    embedding=query_embedding,\n                    k=k,\n                    filter=self._metadata_filter(base_filter=filter, edge=edge),\n                    **kwargs,\n                )\n            )\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        tasks.append(self.aget(ids, filter))\n\n    results: list[Content] = [\n        c\n        for completed_task in asyncio.as_completed(tasks)\n        for c in await completed_task\n    ]\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.adjacent","title":"adjacent","text":"<pre><code>adjacent(\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]\n</code></pre> <p>Return the content items with at least one matching incoming edge.</p> PARAMETER DESCRIPTION <code>edges</code> <p>The edges to look for.</p> <p> TYPE: <code>set[Edge]</code> </p> <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>The number of relevant content items to select.</p> <p> TYPE: <code>int</code> </p> <code>filter</code> <p>Optional metadata to filter the results.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the similarity search.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Iterable[Content]</code> <p>Iterable of adjacent content items.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported edge types are encountered.</p> Source code in <code>packages/graph-retriever/src/graph_retriever/adapters/base.py</code> <pre><code>def adjacent(\n    self,\n    edges: set[Edge],\n    query_embedding: list[float],\n    k: int,\n    filter: dict[str, Any] | None,\n    **kwargs: Any,\n) -&gt; Iterable[Content]:\n    \"\"\"\n    Return the content items with at least one matching incoming edge.\n\n    Parameters\n    ----------\n    edges :\n        The edges to look for.\n    query_embedding :\n        The query embedding used for selecting the most relevant content.\n    k :\n        The number of relevant content items to select.\n    filter :\n        Optional metadata to filter the results.\n    kwargs :\n        Keyword arguments to pass to the similarity search.\n\n    Returns\n    -------\n    :\n        Iterable of adjacent content items.\n\n    Raises\n    ------\n    ValueError\n        If unsupported edge types are encountered.\n    \"\"\"\n    results: list[Content] = []\n\n    ids = []\n    for edge in edges:\n        if isinstance(edge, MetadataEdge):\n            docs = self.search(\n                embedding=query_embedding,\n                k=k,\n                filter=self._metadata_filter(base_filter=filter, edge=edge),\n                **kwargs,\n            )\n            results.extend(docs)\n        elif isinstance(edge, IdEdge):\n            ids.append(edge.id)\n        else:\n            raise ValueError(f\"Unsupported edge: {edge}\")\n\n    if ids:\n        results.extend(self.get(ids, filter=filter))\n\n    return top_k(\n        results,\n        embedding=query_embedding,\n        k=k,\n    )\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.aembed_query","title":"aembed_query  <code>async</code>","text":"<pre><code>aembed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>async def aembed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return await self._safe_embedding.aembed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.aget","title":"aget  <code>async</code>","text":"<pre><code>aget(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def aget(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = await self._aget(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.asearch","title":"asearch  <code>async</code>","text":"<pre><code>asearch(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Asynchronously return content items most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    if k == 0:\n        return []\n\n    docs = await self._asearch(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.asearch_with_embedding","title":"asearch_with_embedding  <code>async</code>","text":"<pre><code>asearch_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Asynchronously return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\nasync def asearch_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = await self.aembed_query(query)\n    docs = await self.asearch(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.embed_query","title":"embed_query","text":"<pre><code>embed_query(query: str)\n</code></pre> <p>Return the embedding of the query.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def embed_query(self, query: str):\n    \"\"\"Return the embedding of the query.\"\"\"\n    return self._safe_embedding.embed_query(query)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.format_documents_hook","title":"format_documents_hook","text":"<pre><code>format_documents_hook(\n    docs: list[Document],\n) -&gt; list[Content]\n</code></pre> <p>Format the documents as content after executing the query.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The documents returned from the vector store</p> <p> TYPE: <code>list[Document]</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>The formatted content.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def format_documents_hook(self, docs: list[Document]) -&gt; list[Content]:\n    \"\"\"\n    Format the documents as content after executing the query.\n\n    Parameters\n    ----------\n    docs :\n        The documents returned from the vector store\n\n    Returns\n    -------\n    :\n        The formatted content.\n    \"\"\"\n    return [doc_to_content(doc) for doc in docs]\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.get","title":"get","text":"<pre><code>get(\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Get content items by ID.</p> <p>Fewer content items may be returned than requested if some IDs are not found or if there are duplicated IDs. This method should NOT raise exceptions if no content items are found for some IDs.</p> <p>Users should not assume that the order of the returned content items matches  the order of the input IDs. Instead, users should rely on the ID field of the returned content items.</p> PARAMETER DESCRIPTION <code>ids</code> <p>List of IDs to get.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments. These are up to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of content items that were found.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef get(\n    self,\n    ids: Sequence[str],\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    docs = self._get(self._remove_duplicates(ids), filter, **kwargs)\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.search","title":"search","text":"<pre><code>search(\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]\n</code></pre> <p>Return contents most similar to the query vector.</p> PARAMETER DESCRIPTION <code>embedding</code> <p>Embedding to look up documents similar to.</p> <p> TYPE: <code>list[float]</code> </p> <code>k</code> <p>Number of Documents to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>list[Content]</code> <p>List of Contents most similar to the query vector.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search(\n    self,\n    embedding: list[float],\n    k: int = 4,\n    filter: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; list[Content]:\n    \"\"\"\n    Return contents most similar to the query vector.\n\n    Parameters\n    ----------\n    embedding :\n        Embedding to look up documents similar to.\n    k :\n        Number of Documents to return.\n    filter :\n        Filter on the metadata to apply.\n    kwargs :\n        Additional keyword arguments.\n\n    Returns\n    -------\n    :\n        List of Contents most similar to the query vector.\n    \"\"\"\n    if k == 0:\n        return []\n\n    docs = self._search(\n        embedding=embedding,\n        k=k,\n        filter=self.update_filter_hook(filter),\n        **kwargs,\n    )\n    return self.format_documents_hook(docs)\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.search_with_embedding","title":"search_with_embedding","text":"<pre><code>search_with_embedding(\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]\n</code></pre> <p>Return content items most similar to the query.</p> <p>Also returns the embedded query vector.</p> PARAMETER DESCRIPTION <code>query</code> <p>Input text.</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of content items to return.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>filter</code> <p>Filter on the metadata to apply.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Additional keyword arguments.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>query_embedding</code> <p>The query embedding used for selecting the most relevant content.</p> <p> TYPE: <code>list[float]</code> </p> <code>contents</code> <p>List of up to <code>k</code> content items most similar to the query vector.</p> <p> TYPE: <code>list[Content]</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>@override\ndef search_with_embedding(\n    self,\n    query: str,\n    k: int = 4,\n    filter: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; tuple[list[float], list[Content]]:\n    query_embedding = self.embed_query(query)\n    docs = self.search(\n        embedding=query_embedding,\n        k=k,\n        filter=filter,\n        **kwargs,\n    )\n    return query_embedding, docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/adapters/#langchain_graph_retriever.adapters.open_search.OpenSearchAdapter.update_filter_hook","title":"update_filter_hook","text":"<pre><code>update_filter_hook(\n    filter: dict[str, Any] | None,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Update the metadata filter before executing the query.</p> PARAMETER DESCRIPTION <code>filter</code> <p>Filter on the metadata to update.</p> <p> TYPE: <code>dict[str, Any] | None</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>The updated filter on the metadata to apply.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/adapters/langchain.py</code> <pre><code>def update_filter_hook(\n    self, filter: dict[str, Any] | None\n) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Update the metadata filter before executing the query.\n\n    Parameters\n    ----------\n    filter :\n        Filter on the metadata to update.\n\n    Returns\n    -------\n    :\n        The updated filter on the metadata to apply.\n    \"\"\"\n    return filter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/","title":"langchain_graph_retriever.transformers","text":"<p>Package containing useful Document Transformers.</p> <p>Many of these add metadata that could be useful for linking content, such as extracting named entities or keywords from the page content.</p> <p>Also includes a transformer for shredding metadata, for use with stores that do not support querying on elements of lists.</p>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.ParentTransformer","title":"ParentTransformer","text":"<pre><code>ParentTransformer(\n    *,\n    path_metadata_key: str = \"path\",\n    parent_metadata_key: str = \"parent\",\n    path_delimiter: str = \"\\\\\",\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Adds the hierarchal Parent path to the document metadata.</p> PARAMETER DESCRIPTION <code>path_metadata_key</code> <p>Metadata key containing the path. This may correspond to paths in a file system, hierarchy in a document, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'path'</code> </p> <code>parent_metadata_key</code> <p>Metadata key for the added parent path</p> <p> TYPE: <code>str</code> DEFAULT: <code>'parent'</code> </p> <code>path_delimiter</code> <p>Delimiter of items in the path.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'\\\\'</code> </p> Example <p>An example of how to use this transformer exists HERE in the guide.</p> Notes <p>Expects each document to contain its path in its metadata.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/parent.py</code> <pre><code>def __init__(\n    self,\n    *,\n    path_metadata_key: str = \"path\",\n    parent_metadata_key: str = \"parent\",\n    path_delimiter: str = \"\\\\\",\n):\n    self._path_metadata_key = path_metadata_key\n    self._parent_metadata_key = parent_metadata_key\n    self._path_delimiter = path_delimiter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.ShreddingTransformer","title":"ShreddingTransformer","text":"<pre><code>ShreddingTransformer(\n    *,\n    keys: set[str] = set(),\n    path_delimiter: str = DEFAULT_PATH_DELIMITER,\n    static_value: Any = DEFAULT_STATIC_VALUE,\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Shreds sequence-based metadata fields.</p> <p>Certain vector stores do not support storing or searching on metadata fields with sequence-based values. This transformer converts sequence-based fields into simple metadata values.</p> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>keys</code> <p>A set of metadata keys to shred. If empty, all sequence-based fields will be shredded.</p> <p> TYPE: <code>set[str]</code> DEFAULT: <code>set()</code> </p> <code>path_delimiter</code> <p>The path delimiter to use when building shredded keys.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_PATH_DELIMITER</code> </p> <code>static_value</code> <p>The value to set on each shredded key.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>DEFAULT_STATIC_VALUE</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def __init__(\n    self,\n    *,\n    keys: set[str] = set(),\n    path_delimiter: str = DEFAULT_PATH_DELIMITER,\n    static_value: Any = DEFAULT_STATIC_VALUE,\n):\n    self.keys = keys\n    self.path_delimiter = path_delimiter\n    self.static_value = static_value\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.ShreddingTransformer.restore_documents","title":"restore_documents","text":"<pre><code>restore_documents(\n    documents: Sequence[Document], **kwargs: Any\n) -&gt; Sequence[Document]\n</code></pre> <p>Restore documents transformed by the ShreddingTransformer.</p> <p>Restore documents transformed by the ShreddingTransformer back to their original state before shredding.</p> <p>Note that any non-string values inside lists will be converted to strings after restoring.</p> <p>Args:     documents: A sequence of Documents to be transformed.</p> RETURNS DESCRIPTION <code>Sequence[Document]</code> <p>A sequence of transformed Documents.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def restore_documents(\n    self, documents: Sequence[Document], **kwargs: Any\n) -&gt; Sequence[Document]:\n    \"\"\"\n    Restore documents transformed by the ShreddingTransformer.\n\n    Restore documents transformed by the ShreddingTransformer back to\n    their original state before shredding.\n\n    Note that any non-string values inside lists will be converted to strings\n    after restoring.\n\n    Args:\n        documents: A sequence of Documents to be transformed.\n\n    Returns\n    -------\n    Sequence[Document]\n        A sequence of transformed Documents.\n    \"\"\"\n    restored_docs = []\n    for document in documents:\n        new_doc = Document(id=document.id, page_content=document.page_content)\n        shredded_keys = set(\n            json.loads(document.metadata.pop(SHREDDED_KEYS_KEY, \"[]\"))\n        )\n\n        for key, value in document.metadata.items():\n            # Check if the key belongs to a shredded group\n            split_key = key.split(self.path_delimiter, 1)\n            if (\n                len(split_key) == 2\n                and split_key[0] in shredded_keys\n                and value == self.static_value\n            ):\n                original_key, original_value = split_key\n                value = json.loads(original_value)\n                if original_key not in new_doc.metadata:\n                    new_doc.metadata[original_key] = []\n                new_doc.metadata[original_key].append(value)\n            else:\n                # Retain non-shredded metadata as is\n                new_doc.metadata[key] = value\n\n        restored_docs.append(new_doc)\n\n    return restored_docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.ShreddingTransformer.shredded_key","title":"shredded_key","text":"<pre><code>shredded_key(key: str, value: Any) -&gt; str\n</code></pre> <p>Get the shredded key for a key/value pair.</p> PARAMETER DESCRIPTION <code>key</code> <p>The metadata key to shred</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>The metadata value to shred</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the shredded key</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def shredded_key(self, key: str, value: Any) -&gt; str:\n    \"\"\"\n    Get the shredded key for a key/value pair.\n\n    Parameters\n    ----------\n    key :\n        The metadata key to shred\n    value :\n        The metadata value to shred\n\n    Returns\n    -------\n    str\n        the shredded key\n    \"\"\"\n    return f\"{key}{self.path_delimiter}{json.dumps(value)}\"\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.ShreddingTransformer.shredded_value","title":"shredded_value","text":"<pre><code>shredded_value() -&gt; str\n</code></pre> <p>Get the shredded value for a key/value pair.</p> RETURNS DESCRIPTION <code>str</code> <p>the shredded value</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def shredded_value(self) -&gt; str:\n    \"\"\"\n    Get the shredded value for a key/value pair.\n\n    Returns\n    -------\n    str\n        the shredded value\n    \"\"\"\n    return self.static_value\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.gliner","title":"gliner","text":""},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.gliner.GLiNERTransformer","title":"GLiNERTransformer","text":"<pre><code>GLiNERTransformer(\n    labels: list[str],\n    *,\n    batch_size: int = 8,\n    metadata_key_prefix: str = \"\",\n    model: str | GLiNER = \"urchade/gliner_mediumv2.1\",\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Add metadata to documents about named entities using GLiNER.</p> <p>Extracts structured entity labels from text, identifying key attributes and categories to enrich document metadata with semantic information.</p> <p>GLiNER is a Named Entity Recognition (NER) model capable of identifying any entity type using a bidirectional transformer encoder (BERT-like).</p> Prerequisites <p>This transformer requires the <code>gliner</code> extra to be installed.</p> <pre><code>pip install -qU langchain_graph_retriever[gliner]\n</code></pre> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>labels</code> <p>List of entity kinds to extract.</p> <p> TYPE: <code>list[str]</code> </p> <code>batch_size</code> <p>The number of documents to process in each batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>8</code> </p> <code>metadata_key_prefix</code> <p>A prefix to add to metadata keys outputted by the extractor. This will be prepended to the label, with the value (or values) holding the generated keywords for that entity kind.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>model</code> <p>The GLiNER model to use. Pass the name of a model to load or pass an instantiated GLiNER model instance.</p> <p> TYPE: <code>str | GLiNER</code> DEFAULT: <code>'urchade/gliner_mediumv2.1'</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/gliner.py</code> <pre><code>def __init__(\n    self,\n    labels: list[str],\n    *,\n    batch_size: int = 8,\n    metadata_key_prefix: str = \"\",\n    model: str | GLiNER = \"urchade/gliner_mediumv2.1\",\n):\n    if isinstance(model, GLiNER):\n        self._model = model\n    elif isinstance(model, str):\n        self._model = GLiNER.from_pretrained(model)\n    else:\n        raise ValueError(f\"Invalid model: {model}\")\n\n    self._batch_size = batch_size\n    self._labels = labels\n    self.metadata_key_prefix = metadata_key_prefix\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.html","title":"html","text":""},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.html.HyperlinkTransformer","title":"HyperlinkTransformer","text":"<pre><code>HyperlinkTransformer(\n    *,\n    url_metadata_key: str = \"url\",\n    metadata_key: str = \"hyperlink\",\n    drop_fragments: bool = True,\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Extracts hyperlinks from HTML content and stores them in document metadata.</p> Prerequisites <p>This transformer requires the <code>html</code> extra to be installed.</p> <pre><code>pip install -qU langchain_graph_retriever[html]\n</code></pre> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>url_metadata_key</code> <p>The metadata field containing the URL of the document. Must be set before transforming. Needed to resolve relative paths.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'url'</code> </p> <code>metadata_key</code> <p>The metadata field to populate with documents linked from this content.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'hyperlink'</code> </p> <code>drop_fragments</code> <p>Whether fragments in URLs and links should be dropped.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Notes <p>Expects each document to contain its URL in its metadata.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/html.py</code> <pre><code>def __init__(\n    self,\n    *,\n    url_metadata_key: str = \"url\",\n    metadata_key: str = \"hyperlink\",\n    drop_fragments: bool = True,\n):\n    self._url_metadata_key = url_metadata_key\n    self._metadata_key = metadata_key\n    self._drop_fragments = drop_fragments\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.keybert","title":"keybert","text":""},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.keybert.KeyBERTTransformer","title":"KeyBERTTransformer","text":"<pre><code>KeyBERTTransformer(\n    *,\n    batch_size: int = 8,\n    metadata_key: str = \"keywords\",\n    model: str | KeyBERT = \"all-MiniLM-L6-v2\",\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Add metadata to documents about keywords using KeyBERT.</p> <p>Extracts key topics and concepts from text, generating metadata that highlights the most relevant terms to describe the content.</p> <p>KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords and keyphrases that are most similar to a document.</p> Prerequisites <p>This transformer requires the <code>keybert</code> extra to be installed.</p> <pre><code>pip install -qU langchain_graph_retriever[keybert]\n</code></pre> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>The number of documents to process in each batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>8</code> </p> <code>metadata_key</code> <p>The name of the key used in the metadata output.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'keywords'</code> </p> <code>model</code> <p>The KeyBERT model to use. Pass the name of a model to load or pass an instantiated KeyBERT model instance.</p> <p> TYPE: <code>str | KeyBERT</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/keybert.py</code> <pre><code>def __init__(\n    self,\n    *,\n    batch_size: int = 8,\n    metadata_key: str = \"keywords\",\n    model: str | KeyBERT = \"all-MiniLM-L6-v2\",\n):\n    if isinstance(model, KeyBERT):\n        self._kw_model = model\n    elif isinstance(model, str):\n        self._kw_model = KeyBERT(model=model)\n    else:\n        raise ValueError(f\"Invalid model: {model}\")\n    self._batch_size = batch_size\n    self._metadata_key = metadata_key\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.parent","title":"parent","text":""},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.parent.ParentTransformer","title":"ParentTransformer","text":"<pre><code>ParentTransformer(\n    *,\n    path_metadata_key: str = \"path\",\n    parent_metadata_key: str = \"parent\",\n    path_delimiter: str = \"\\\\\",\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Adds the hierarchal Parent path to the document metadata.</p> PARAMETER DESCRIPTION <code>path_metadata_key</code> <p>Metadata key containing the path. This may correspond to paths in a file system, hierarchy in a document, etc.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'path'</code> </p> <code>parent_metadata_key</code> <p>Metadata key for the added parent path</p> <p> TYPE: <code>str</code> DEFAULT: <code>'parent'</code> </p> <code>path_delimiter</code> <p>Delimiter of items in the path.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'\\\\'</code> </p> Example <p>An example of how to use this transformer exists HERE in the guide.</p> Notes <p>Expects each document to contain its path in its metadata.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/parent.py</code> <pre><code>def __init__(\n    self,\n    *,\n    path_metadata_key: str = \"path\",\n    parent_metadata_key: str = \"parent\",\n    path_delimiter: str = \"\\\\\",\n):\n    self._path_metadata_key = path_metadata_key\n    self._parent_metadata_key = parent_metadata_key\n    self._path_delimiter = path_delimiter\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding","title":"shredding","text":"<p>Shredding Transformer for sequence-based metadata fields.</p>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer","title":"ShreddingTransformer","text":"<pre><code>ShreddingTransformer(\n    *,\n    keys: set[str] = set(),\n    path_delimiter: str = DEFAULT_PATH_DELIMITER,\n    static_value: Any = DEFAULT_STATIC_VALUE,\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Shreds sequence-based metadata fields.</p> <p>Certain vector stores do not support storing or searching on metadata fields with sequence-based values. This transformer converts sequence-based fields into simple metadata values.</p> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>keys</code> <p>A set of metadata keys to shred. If empty, all sequence-based fields will be shredded.</p> <p> TYPE: <code>set[str]</code> DEFAULT: <code>set()</code> </p> <code>path_delimiter</code> <p>The path delimiter to use when building shredded keys.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_PATH_DELIMITER</code> </p> <code>static_value</code> <p>The value to set on each shredded key.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>DEFAULT_STATIC_VALUE</code> </p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def __init__(\n    self,\n    *,\n    keys: set[str] = set(),\n    path_delimiter: str = DEFAULT_PATH_DELIMITER,\n    static_value: Any = DEFAULT_STATIC_VALUE,\n):\n    self.keys = keys\n    self.path_delimiter = path_delimiter\n    self.static_value = static_value\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer.restore_documents","title":"restore_documents","text":"<pre><code>restore_documents(\n    documents: Sequence[Document], **kwargs: Any\n) -&gt; Sequence[Document]\n</code></pre> <p>Restore documents transformed by the ShreddingTransformer.</p> <p>Restore documents transformed by the ShreddingTransformer back to their original state before shredding.</p> <p>Note that any non-string values inside lists will be converted to strings after restoring.</p> <p>Args:     documents: A sequence of Documents to be transformed.</p> RETURNS DESCRIPTION <code>Sequence[Document]</code> <p>A sequence of transformed Documents.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def restore_documents(\n    self, documents: Sequence[Document], **kwargs: Any\n) -&gt; Sequence[Document]:\n    \"\"\"\n    Restore documents transformed by the ShreddingTransformer.\n\n    Restore documents transformed by the ShreddingTransformer back to\n    their original state before shredding.\n\n    Note that any non-string values inside lists will be converted to strings\n    after restoring.\n\n    Args:\n        documents: A sequence of Documents to be transformed.\n\n    Returns\n    -------\n    Sequence[Document]\n        A sequence of transformed Documents.\n    \"\"\"\n    restored_docs = []\n    for document in documents:\n        new_doc = Document(id=document.id, page_content=document.page_content)\n        shredded_keys = set(\n            json.loads(document.metadata.pop(SHREDDED_KEYS_KEY, \"[]\"))\n        )\n\n        for key, value in document.metadata.items():\n            # Check if the key belongs to a shredded group\n            split_key = key.split(self.path_delimiter, 1)\n            if (\n                len(split_key) == 2\n                and split_key[0] in shredded_keys\n                and value == self.static_value\n            ):\n                original_key, original_value = split_key\n                value = json.loads(original_value)\n                if original_key not in new_doc.metadata:\n                    new_doc.metadata[original_key] = []\n                new_doc.metadata[original_key].append(value)\n            else:\n                # Retain non-shredded metadata as is\n                new_doc.metadata[key] = value\n\n        restored_docs.append(new_doc)\n\n    return restored_docs\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer.shredded_key","title":"shredded_key","text":"<pre><code>shredded_key(key: str, value: Any) -&gt; str\n</code></pre> <p>Get the shredded key for a key/value pair.</p> PARAMETER DESCRIPTION <code>key</code> <p>The metadata key to shred</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>The metadata value to shred</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the shredded key</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def shredded_key(self, key: str, value: Any) -&gt; str:\n    \"\"\"\n    Get the shredded key for a key/value pair.\n\n    Parameters\n    ----------\n    key :\n        The metadata key to shred\n    value :\n        The metadata value to shred\n\n    Returns\n    -------\n    str\n        the shredded key\n    \"\"\"\n    return f\"{key}{self.path_delimiter}{json.dumps(value)}\"\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer.shredded_value","title":"shredded_value","text":"<pre><code>shredded_value() -&gt; str\n</code></pre> <p>Get the shredded value for a key/value pair.</p> RETURNS DESCRIPTION <code>str</code> <p>the shredded value</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/shredding.py</code> <pre><code>def shredded_value(self) -&gt; str:\n    \"\"\"\n    Get the shredded value for a key/value pair.\n\n    Returns\n    -------\n    str\n        the shredded value\n    \"\"\"\n    return self.static_value\n</code></pre>"},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.spacy","title":"spacy","text":""},{"location":"reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.spacy.SpacyNERTransformer","title":"SpacyNERTransformer","text":"<pre><code>SpacyNERTransformer(\n    *,\n    include_labels: set[str] = set(),\n    exclude_labels: set[str] = set(),\n    limit: int | None = None,\n    metadata_key: str = \"entities\",\n    model: str | Language = \"en_core_web_sm\",\n)\n</code></pre> <p>               Bases: <code>BaseDocumentTransformer</code></p> <p>Add metadata to documents about named entities using spaCy.</p> <p>Identifies and labels named entities in text, extracting structured metadata such as organizations, locations, dates, and other key entity types.</p> <p>spaCy is a library for Natural Language Processing in Python. Here it is used for Named Entity Recognition (NER) to extract values from document content.</p> Prerequisites <p>This transformer requires the <code>spacy</code> extra to be installed.</p> <pre><code>pip install -qU langchain_graph_retriever[spacy]\n</code></pre> Example <p>An example of how to use this transformer exists HERE in the guide.</p> PARAMETER DESCRIPTION <code>include_labels</code> <p>Set of entity labels to include. Will include all labels if empty.</p> <p> TYPE: <code>set[str]</code> DEFAULT: <code>set()</code> </p> <code>exclude_labels</code> <p>Set of entity labels to exclude. Will not exclude anything if empty.</p> <p> TYPE: <code>set[str]</code> DEFAULT: <code>set()</code> </p> <code>metadata_key</code> <p>The metadata key to store the extracted entities in.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'entities'</code> </p> <code>model</code> <p>The spaCy model to use. Pass the name of a model to load or pass an instantiated spaCy model instance.</p> <p> TYPE: <code>str | Language</code> DEFAULT: <code>'en_core_web_sm'</code> </p> Notes <p>See spaCy docs for the selected model to determine what NER labels will be  used. The default model en_core_web_sm produces: CARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL, ORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART.</p> Source code in <code>packages/langchain-graph-retriever/src/langchain_graph_retriever/transformers/spacy.py</code> <pre><code>def __init__(\n    self,\n    *,\n    include_labels: set[str] = set(),\n    exclude_labels: set[str] = set(),\n    limit: int | None = None,\n    metadata_key: str = \"entities\",\n    model: str | Language = \"en_core_web_sm\",\n):\n    self.include_labels = include_labels\n    self.exclude_labels = exclude_labels\n    self.limit = limit\n    self.metadata_key = metadata_key\n\n    if isinstance(model, str):\n        if not spacy.util.is_package(model):\n            spacy.cli.download(model)  # type: ignore\n        self.model = spacy.load(model)\n    elif isinstance(model, Language):\n        self.model = model\n    else:\n        raise ValueError(f\"Invalid model: {model}\")\n</code></pre>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/langchain/","title":"langchain","text":""},{"location":"blog/category/news/","title":"news","text":""}]}